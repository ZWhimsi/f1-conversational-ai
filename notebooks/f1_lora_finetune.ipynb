{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef4acd5",
   "metadata": {},
   "source": [
    "# F1 LoRA Fine-Tuning and Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6cdef",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This notebook is my end-to-end pipeline for fine-tuning small open models on a Formula 1 QA dataset using LoRA, then evaluating them on a large multiple-choice benchmark.\n",
    "\n",
    "I wrote this for my CS6220 final project, so the explanations are in my own words and assume I run everything locally on my machine.\n",
    "\n",
    "---\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Fine-tune two base models on F1 question–answer pairs:\n",
    "  - `mistralai/Mistral-7B-v0.3`\n",
    "  - `meta-llama/Meta-Llama-3.1-8B-Instruct` (referred to here as LLaMA 3.1 8B)\n",
    "- Teach them to answer F1 questions correctly and consistently.\n",
    "- Evaluate them on a big multiple-choice dataset and measure accuracy.\n",
    "\n",
    "The notebook should:\n",
    "\n",
    "1. Build the training data from my processed QA JSON files.\n",
    "2. Run LoRA fine-tuning for Mistral and LLaMA.\n",
    "3. Evaluate both models on the same MC dataset using a robust scoring method (no fragile JSON parsing).\n",
    "4. Save all logs, metrics, and plots so I can compare models later, even if I reset the kernel between runs.\n",
    "\n",
    "---\n",
    "\n",
    "## Folder structure, inputs and outputs\n",
    "\n",
    "The notebook assumes the project is laid out like this:\n",
    "\n",
    "- **Project root and notebook**\n",
    "  - `PROJECT_ROOT` is inferred from the notebook path.\n",
    "  - The notebook itself lives under  \n",
    "    `PROJECT_ROOT/notebooks/`  \n",
    "    (for me it is something like  \n",
    "    `D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\notebooks\\f1_lora_finetune.ipynb`).\n",
    "\n",
    "- **Training QA data (for SFT)**\n",
    "  - `F1_QA_INPUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"f1_qa\"`\n",
    "  - This folder contains files like `qa_1.json`, `qa_2.json`, …  \n",
    "    Each file has:\n",
    "    - `article_number`, `source`, `title`, `summary`\n",
    "    - `qa_pairs`, where each pair has:\n",
    "      - `question`\n",
    "      - `correct_answer`\n",
    "      - `wrong_options` (three distractors)\n",
    "      - `rephrased_question`\n",
    "      - `options` dict with A, B, C, D\n",
    "      - `ground_truth_correct_option` (the letter)\n",
    "      - `prompt` (original MC prompt used earlier)\n",
    "\n",
    "  - In this notebook I **do not** reuse the old MC prompt.  \n",
    "    Instead I build my own SFT text:\n",
    "    > You are a knowledgeable Formula 1 expert.  \n",
    "    > Answer the question briefly and accurately.  \n",
    "    > Question: …  \n",
    "    > Answer: {correct_answer}\n",
    "\n",
    "- **Eval MC data (big dataset for scoring)**\n",
    "  - `BIG_EVAL_DATASET_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"big_data_dataset_evalScripts\" / \"dataset\"`\n",
    "  - Contains about 527 files like `qa_1.json`, `qa_2.json`, … with:\n",
    "    - `qa_pairs` and the same fields as above.\n",
    "  - For evaluation I only use:\n",
    "    - `rephrased_question` (fallback to `question`)\n",
    "    - `options` (A, B, C, D)\n",
    "    - `ground_truth_correct_option`.\n",
    "\n",
    "- **Processed prompts (optional cache)**\n",
    "  - `EVAL_OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"LoRA_Processed_Inputs\"`\n",
    "  - Used to save the processed SFT prompts and metadata so I do not have to recompute them each time.\n",
    "\n",
    "- **Model outputs and logs**\n",
    "  - `RESULTS_DIR = PROJECT_ROOT / \"results\" / \"LoRA_Results\"`\n",
    "    - Per model LoRA weights:\n",
    "      - `RESULTS_DIR / \"mistral_lora\"`  \n",
    "      - `RESULTS_DIR / \"llama_lora\"`\n",
    "    - Training logs:\n",
    "      - `mistral_train_log.json`, `llama_train_log.json`\n",
    "      - `mistral_train_meta.json`, `llama_train_meta.json`\n",
    "  - `EVAL_RESULTS_DIR` (under `RESULTS_DIR`)  \n",
    "    - Evaluation outputs, for example:\n",
    "      - `mistral_bigdata_eval_results_scoring.json`\n",
    "      - `llama_bigdata_eval_results_scoring.json`\n",
    "    - Final CSVs:\n",
    "      - `epoch_results.csv` (epoch-level MC accuracy and times)\n",
    "      - `summary_results.csv` (one row per model, final accuracy, train time, eval time)\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements and environment\n",
    "\n",
    "This notebook expects:\n",
    "\n",
    "- Python environment with:\n",
    "  - `torch` and a working GPU (A100 type is what I used)\n",
    "  - `transformers`\n",
    "  - `peft`\n",
    "  - `accelerate`\n",
    "  - `bitsandbytes` (for 4-bit loading)\n",
    "  - `pandas`, `matplotlib`\n",
    "- Access to the HF model IDs listed in `MODELS`.\n",
    "- Enough GPU memory to fine-tune 7B–8B models with LoRA and gradient checkpointing.\n",
    "\n",
    "The first code cells check GPU details and print:\n",
    "\n",
    "- Device type\n",
    "- GPU name and total memory\n",
    "- Torch and transformers versions\n",
    "\n",
    "If something looks wrong there, the rest of the notebook will probably not behave well.\n",
    "\n",
    "---\n",
    "\n",
    "## What actually happens in each logical section\n",
    "\n",
    "I structured the notebook in blocks. Roughly:\n",
    "\n",
    "1. **Environment and GPU check**\n",
    "   - Import packages.\n",
    "   - Print basic system info, GPU type, memory, and key library versions.\n",
    "\n",
    "2. **Project paths and configuration**\n",
    "   - Infer `NOTEBOOK_DIR` and `PROJECT_ROOT`.\n",
    "   - Define:\n",
    "     - `F1_QA_INPUT_DIR`\n",
    "     - `EVAL_OUTPUT_DIR`\n",
    "     - `BIG_EVAL_DATASET_DIR`\n",
    "     - `RESULTS_DIR` and `EVAL_RESULTS_DIR`\n",
    "   - Define `MODELS` list with Mistral and LLaMA configs.\n",
    "   - Set common hyperparameters:\n",
    "     - `NUM_EPOCHS`, `BATCH_SIZE`, `LEARNING_RATE`, `WARMUP_RATIO`, `MAX_SEQ_LEN`.\n",
    "\n",
    "3. **LoRA configuration utilities**\n",
    "   - Helper function `create_tokenizer(model_id)` that:\n",
    "     - Loads the tokenizer from HF.\n",
    "     - Ensures `pad_token_id` is set (fall back to `eos_token_id` if needed).\n",
    "   - Helper function `create_base_model(model_id)` that:\n",
    "     - Loads the base model in 4-bit with `bitsandbytes`.\n",
    "     - Puts it on the GPU.\n",
    "   - Helper function `apply_lora(model)` that:\n",
    "     - Wraps the base model with LoRA layers using `peft`.\n",
    "   - All LoRA hyperparameters (rank, alpha, dropout) are defined here.\n",
    "\n",
    "4. **Building the SFT training dataset**\n",
    "   - Read all QA JSON files from `F1_QA_INPUT_DIR`.\n",
    "   - For each `qa_pair`, build a simple SFT string:\n",
    "     - Short instruction\n",
    "     - Question\n",
    "     - Correct answer only (no distractors).\n",
    "   - Save everything into a `datasets.Dataset` called `train_dataset`, with fields:\n",
    "     - `\"text\"` (prompt + answer)\n",
    "     - `\"q_id\"` (for tracking).\n",
    "   - Print the first 5 raw examples so I can inspect exactly what the model sees.\n",
    "\n",
    "5. **Tokenization helper**\n",
    "   - `tokenize_sft_function(examples, tokenizer)`:\n",
    "     - Tokenizes the `\"text\"` field.\n",
    "     - Applies truncation and padding to `MAX_SEQ_LEN`.\n",
    "   - This is used for both Mistral and LLaMA to produce model-specific tokenized datasets.\n",
    "\n",
    "6. **Mistral LoRA training**\n",
    "   - Create Mistral tokenizer and tokenized dataset `mistral_ds`.\n",
    "   - Print a few decoded tokenized examples, which show a lot of `<s>` tokens at the end because of padding.\n",
    "     - This is expected: the dataset is padded with `<s>` (BOS/EOS) as pad token.\n",
    "   - Load base Mistral model and wrap it with LoRA.\n",
    "   - Set `pad_token_id` for model and tokenizer.\n",
    "   - Configure `TrainingArguments`:\n",
    "     - Epochs, batch size, gradient accumulation, learning rate, warmup, FP16, no logging to external services.\n",
    "   - Run `Trainer.train()` and print training loss every few steps.\n",
    "   - Save:\n",
    "     - LoRA weights into `RESULTS_DIR / \"mistral_lora\"`\n",
    "     - Training log (`mistral_train_log.json`)\n",
    "     - Training meta (`mistral_train_meta.json`).\n",
    "\n",
    "7. **Mistral evaluation with MC scoring (no generation)**\n",
    "   - Load evaluation questions from `BIG_EVAL_DATASET_DIR` using:\n",
    "     - `load_big_eval_questions_for_scoring`.\n",
    "   - For each question:\n",
    "     - Build a fresh prompt that matches the SFT style:\n",
    "\n",
    "       > You are a knowledgeable Formula 1 expert.  \n",
    "       > Answer the question briefly and accurately.  \n",
    "       > Question: …  \n",
    "       > Options: A: … B: … C: … D: …  \n",
    "       > Answer:\n",
    "\n",
    "     - For each option A, B, C, D:\n",
    "       - Call `score_option_logprob`:\n",
    "         - Concatenate prompt + option text.\n",
    "         - Run the model once.\n",
    "         - Compute average log probability of the answer tokens.\n",
    "     - Choose the option letter with the highest average log-prob.\n",
    "   - The key point is:  \n",
    "     There is **no generation** and **no JSON parsing** here.  \n",
    "     I only ask the model “How likely is it that the answer is this string” four times and pick the best.\n",
    "   - `run_big_mc_eval_scoring`:\n",
    "     - Prints progress every 20 questions:\n",
    "       - `Scoring question i/N...`\n",
    "       - Predicted option and ground truth\n",
    "       - Per-option scores\n",
    "     - At the end it prints:\n",
    "       - Total number of questions\n",
    "       - Number correct\n",
    "       - Overall accuracy\n",
    "       - Evaluation time\n",
    "     - Stores detailed per-question records in a JSON under `EVAL_RESULTS_DIR`.\n",
    "\n",
    "   - Current outcome for Mistral (on my run):  \n",
    "     about **72.3% MC accuracy** on 1581 questions.\n",
    "\n",
    "8. **LLaMA LoRA training**\n",
    "   - Same logic as Mistral, but for `meta-llama/Meta-Llama-3.1-8B-Instruct`:\n",
    "     - Build tokenizer and tokenized dataset `llama_ds` from `train_dataset`.\n",
    "     - Print first raw and tokenized examples for sanity.\n",
    "     - Load base LLaMA model and apply LoRA.\n",
    "     - Train with the same hyperparameters.\n",
    "     - Save:\n",
    "       - `llama_lora` directory\n",
    "       - `llama_train_log.json`\n",
    "       - `llama_train_meta.json`.\n",
    "\n",
    "9. **LLaMA evaluation with MC scoring**\n",
    "   - Reuse the same scoring functions used for Mistral:\n",
    "     - `load_big_eval_questions_for_scoring`\n",
    "     - `build_scoring_prompt`\n",
    "     - `score_option_logprob`\n",
    "     - `run_big_mc_eval_scoring`\n",
    "   - Load the LLaMA LoRA adapter and evaluate on the same MC dataset.\n",
    "   - Save results to:\n",
    "     - `llama_bigdata_eval_results_scoring.json`\n",
    "   - Append a summary row for LLaMA into the in-memory `summary_rows` list.\n",
    "\n",
    "10. **Collecting results and plotting**\n",
    "    - Build:\n",
    "      - `epoch_results_df` from `all_epoch_logs` (epoch-level information, if available).\n",
    "      - `summary_df` from `summary_rows` (one row per model).\n",
    "    - Save:\n",
    "      - `epoch_results.csv`\n",
    "      - `summary_results.csv`\n",
    "    - Plot:\n",
    "      - MC accuracy per epoch by model (if epoch logs exist).\n",
    "      - Training time per model.\n",
    "      - Final MC accuracy per model.\n",
    "      - Evaluation time per model.\n",
    "\n",
    "    Note: because I sometimes reset the kernel between model runs, the notebook also supports reading existing JSONs and CSVs back from disk and reconstructing `summary_df` so that both models (Mistral and LLaMA) appear in the final plots.\n",
    "\n",
    "---\n",
    "\n",
    "## Challenges along the way\n",
    "\n",
    "Some of the main issues I hit and how this notebook addresses them:\n",
    "\n",
    "1. **Generation-based MC evaluation failed**\n",
    "   - When I tried to ask the model to output a JSON like:\n",
    "     ```json\n",
    "     { \"model_correct_option\": \"C\", \"justification\": \"...\" }\n",
    "     ```\n",
    "     the model often replied with just `</s>` or random text.  \n",
    "     The parsing code could not reliably extract the answer, and I ended up with `Parsed: 0, Skipped: 1581`.\n",
    "\n",
    "2. **EOS and padding**\n",
    "   - Mistral and LLaMA use `<s>` and `</s>` tokens, and sometimes the tokenizer reused `<s>` as pad.\n",
    "   - This is why decoded tokenized examples show many `<s>` at the end.\n",
    "   - The notebook explicitly aligns `pad_token_id` with `eos_token_id` so that generation and losses behave more predictably.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Current outcomes\n",
    "\n",
    "Right now, after the scoring-based evaluation is in place:\n",
    "\n",
    "- **Mistral-7B LoRA**\n",
    "  - Successfully trains on my F1 QA SFT dataset.\n",
    "  - Reaches around **72% multiple-choice accuracy** on the 1,581 held-out questions using log-prob scoring.\n",
    "  - Training and eval runtimes are recorded in `summary_results.csv`.\n",
    "\n",
    "- **LLaMA-3.1-8B-Instruct LoRA**\n",
    "  - Fine-tuning and scoring evaluation follow the exact same pipeline.\n",
    "  - Final accuracy and timing are also written into `summary_results.csv` once the evaluation run completes.\n",
    "\n",
    "The notebook is now stable: data loading, training, and evaluation are aligned, and the scoring method is robust to model output quirks. If I want to update anything later (change models, tweak prompts, add epochs), I can do it in a controlled way without breaking the whole pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba618a",
   "metadata": {},
   "source": [
    "## Cell 1 – Environment and GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ea0792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]\n",
      "Platform: Windows-10-10.0.26100-SP0\n",
      "Transformers version: 4.57.1\n",
      "Torch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "GPU count: 1\n",
      "Current GPU: NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "GPU total memory (GB): 15.99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def ensure_package(pkg):\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for p in [\n",
    "    \"torch\", \"transformers\", \"datasets\", \"peft\",\n",
    "    \"accelerate\", \"bitsandbytes\", \"trl\", \"pandas\", \"numpy\", \"matplotlib\",\n",
    "    \"huggingface_hub\"\n",
    "]:\n",
    "    ensure_package(p)\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import login\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "MACHINE_INFO = {}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    gpu_mem_gb = round(props.total_memory / 1024**3, 2)\n",
    "    print(\"Current GPU:\", gpu_name)\n",
    "    print(\"GPU total memory (GB):\", gpu_mem_gb)\n",
    "    MACHINE_INFO[\"device_type\"] = \"cuda\"\n",
    "    MACHINE_INFO[\"gpu_name\"] = gpu_name\n",
    "    MACHINE_INFO[\"gpu_memory_gb\"] = gpu_mem_gb\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available; using CPU\")\n",
    "    MACHINE_INFO[\"device_type\"] = \"cpu\"\n",
    "    MACHINE_INFO[\"gpu_name\"] = None\n",
    "    MACHINE_INFO[\"gpu_memory_gb\"] = None\n",
    "\n",
    "MACHINE_INFO[\"platform\"] = platform.platform()\n",
    "MACHINE_INFO[\"python_version\"] = sys.version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bee4d",
   "metadata": {},
   "source": [
    "## Cell 2 – Paths, config and Hugging Face token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024bec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face login successful.\n",
      "Notebook dir: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\notebooks\n",
      "Project root: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\n",
      "Input QA dir: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\data\\processed\\f1_qa\n",
      "LoRA processed inputs dir: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\data\\processed\\LoRA_Processed_Inputs\n",
      "LoRA outputs dir: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\results\\LoRA Results\\Outputs\n",
      "LoRA eval results dir: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\results\\LoRA Results\\Eval_Results\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Use the notebook folder as base, then go one level up to project root\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "# Input QA JSONs (only these are used as inputs)\n",
    "F1_QA_INPUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"f1_qa\"\n",
    "\n",
    "# Final jsons used for training/testing and tracking correct responses\n",
    "EVAL_OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"LoRA_Processed_Inputs\"\n",
    "EVAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where models and training outputs (LoRA checkpoints, logs, etc.) are saved\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\" / \"LoRA Results\" / \"Outputs\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where evaluation result files (aggregated metrics, etc.) can be saved\n",
    "EVAL_RESULTS_DIR = PROJECT_ROOT / \"results\" / \"LoRA Results\" / \"Eval_Results\"\n",
    "EVAL_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cache directory for base model downloads to avoid re-downloading\n",
    "MODEL_CACHE_DIR = PROJECT_ROOT / \"models\"\n",
    "MODEL_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Hugging Face key (relative to project root)\n",
    "LOCAL_KEY_PATH = PROJECT_ROOT / \"00_KamyarKeys\" / \"key.json\"\n",
    "\n",
    "def load_hf_token():\n",
    "    if \"HF_TOKEN\" in os.environ and os.environ[\"HF_TOKEN\"]:\n",
    "        return os.environ[\"HF_TOKEN\"]\n",
    "    if LOCAL_KEY_PATH.exists():\n",
    "        with open(LOCAL_KEY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            key_data = json.load(f)\n",
    "        token = key_data.get(\"Token\", {}).get(\"value\")\n",
    "        if token:\n",
    "            os.environ[\"HF_TOKEN\"] = token\n",
    "            return token\n",
    "    return None\n",
    "\n",
    "hf_token = load_hf_token()\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"Hugging Face login successful.\")\n",
    "else:\n",
    "    print(\"Warning: Hugging Face token not found. Place key.json correctly or set HF_TOKEN.\")\n",
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "MAX_SEQ_LEN = 1024\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 2e-4\n",
    "WARMUP_RATIO = 0.03\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.05\n",
    "\n",
    "MODELS = [\n",
    "    {\n",
    "        \"id\": \"mistralai/Mistral-7B-v0.1\",\n",
    "        \"name\": \"mistral-7b\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        \"name\": \"llama-3.1-8b-instruct\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Notebook dir:\", NOTEBOOK_DIR)\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Input QA dir:\", F1_QA_INPUT_DIR)\n",
    "print(\"LoRA processed inputs dir:\", EVAL_OUTPUT_DIR)\n",
    "print(\"LoRA outputs dir:\", RESULTS_DIR)\n",
    "print(\"LoRA eval results dir:\", EVAL_RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51ec59",
   "metadata": {},
   "source": [
    "## Cell 3 – Load QA JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51a1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA pairs: 1536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_number</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>q_id</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>wrong_options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Motorsport Magazine</td>\n",
       "      <td>Verstappen nears historic F1 comeback - US GP ...</td>\n",
       "      <td>Verstappen's double win in Austin moved him cl...</td>\n",
       "      <td>https://www.motorsportmagazine.com/articles/si...</td>\n",
       "      <td>1_0</td>\n",
       "      <td>Which driver achieved a double win at the US G...</td>\n",
       "      <td>Max Verstappen</td>\n",
       "      <td>[Lewis Hamilton, Charles Leclerc, Sergio Pérez]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Motorsport Magazine</td>\n",
       "      <td>Verstappen nears historic F1 comeback - US GP ...</td>\n",
       "      <td>Verstappen's double win in Austin moved him cl...</td>\n",
       "      <td>https://www.motorsportmagazine.com/articles/si...</td>\n",
       "      <td>1_1</td>\n",
       "      <td>What challenge did McLaren face during the US ...</td>\n",
       "      <td>Tough questions over its strategy</td>\n",
       "      <td>[Performance issues with the car, Driver penal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Motorsport Magazine</td>\n",
       "      <td>Verstappen nears historic F1 comeback - US GP ...</td>\n",
       "      <td>Verstappen's double win in Austin moved him cl...</td>\n",
       "      <td>https://www.motorsportmagazine.com/articles/si...</td>\n",
       "      <td>1_2</td>\n",
       "      <td>What type of race experience did fans have dur...</td>\n",
       "      <td>Another processional race</td>\n",
       "      <td>[An exciting battle for the lead, Multiple saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Motorsport Magazine</td>\n",
       "      <td>2025 US Grand Prix: Qualifying start time and ...</td>\n",
       "      <td>Start time for qualifying ahead of the 2025 Un...</td>\n",
       "      <td>https://www.motorsportmagazine.com/articles/si...</td>\n",
       "      <td>10_0</td>\n",
       "      <td>What is the typical format of a Formula 1 qual...</td>\n",
       "      <td>Three knockout rounds: Q1, Q2, and Q3.</td>\n",
       "      <td>[Single lap time trial for all drivers., Two 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Motorsport Magazine</td>\n",
       "      <td>2025 US Grand Prix: Qualifying start time and ...</td>\n",
       "      <td>Start time for qualifying ahead of the 2025 Un...</td>\n",
       "      <td>https://www.motorsportmagazine.com/articles/si...</td>\n",
       "      <td>10_1</td>\n",
       "      <td>In which city is the United States Grand Prix ...</td>\n",
       "      <td>Austin, Texas.</td>\n",
       "      <td>[Miami, Florida., Los Angeles, California., Ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_number               source  \\\n",
       "0               1  Motorsport Magazine   \n",
       "1               1  Motorsport Magazine   \n",
       "2               1  Motorsport Magazine   \n",
       "3              10  Motorsport Magazine   \n",
       "4              10  Motorsport Magazine   \n",
       "\n",
       "                                               title  \\\n",
       "0  Verstappen nears historic F1 comeback - US GP ...   \n",
       "1  Verstappen nears historic F1 comeback - US GP ...   \n",
       "2  Verstappen nears historic F1 comeback - US GP ...   \n",
       "3  2025 US Grand Prix: Qualifying start time and ...   \n",
       "4  2025 US Grand Prix: Qualifying start time and ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Verstappen's double win in Austin moved him cl...   \n",
       "1  Verstappen's double win in Austin moved him cl...   \n",
       "2  Verstappen's double win in Austin moved him cl...   \n",
       "3  Start time for qualifying ahead of the 2025 Un...   \n",
       "4  Start time for qualifying ahead of the 2025 Un...   \n",
       "\n",
       "                                                link  q_id  \\\n",
       "0  https://www.motorsportmagazine.com/articles/si...   1_0   \n",
       "1  https://www.motorsportmagazine.com/articles/si...   1_1   \n",
       "2  https://www.motorsportmagazine.com/articles/si...   1_2   \n",
       "3  https://www.motorsportmagazine.com/articles/si...  10_0   \n",
       "4  https://www.motorsportmagazine.com/articles/si...  10_1   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which driver achieved a double win at the US G...   \n",
       "1  What challenge did McLaren face during the US ...   \n",
       "2  What type of race experience did fans have dur...   \n",
       "3  What is the typical format of a Formula 1 qual...   \n",
       "4  In which city is the United States Grand Prix ...   \n",
       "\n",
       "                           correct_answer  \\\n",
       "0                          Max Verstappen   \n",
       "1       Tough questions over its strategy   \n",
       "2               Another processional race   \n",
       "3  Three knockout rounds: Q1, Q2, and Q3.   \n",
       "4                          Austin, Texas.   \n",
       "\n",
       "                                       wrong_options  \n",
       "0    [Lewis Hamilton, Charles Leclerc, Sergio Pérez]  \n",
       "1  [Performance issues with the car, Driver penal...  \n",
       "2  [An exciting battle for the lead, Multiple saf...  \n",
       "3  [Single lap time trial for all drivers., Two 3...  \n",
       "4  [Miami, Florida., Los Angeles, California., Ne...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def load_f1_qa_files(input_dir: Path):\n",
    "    records = []\n",
    "    if not input_dir.exists():\n",
    "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
    "    for path in sorted(input_dir.glob(\"*.json\")):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        article_number = data.get(\"article_number\")\n",
    "        source = data.get(\"source\")\n",
    "        title = data.get(\"title\")\n",
    "        summary = data.get(\"summary\")\n",
    "        link = data.get(\"link\")\n",
    "        qa_pairs = data.get(\"qa_pairs\", [])\n",
    "        for idx, qa in enumerate(qa_pairs):\n",
    "            question = qa[\"question\"]\n",
    "            correct_answer = qa[\"correct_answer\"]\n",
    "            wrong_options = qa.get(\"wrong_options\", [])\n",
    "            records.append(\n",
    "                {\n",
    "                    \"article_number\": article_number,\n",
    "                    \"source\": source,\n",
    "                    \"title\": title,\n",
    "                    \"summary\": summary,\n",
    "                    \"link\": link,\n",
    "                    \"q_id\": f\"{article_number}_{idx}\",\n",
    "                    \"question\": question,\n",
    "                    \"correct_answer\": correct_answer,\n",
    "                    \"wrong_options\": wrong_options,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "df_qa = load_f1_qa_files(F1_QA_INPUT_DIR)\n",
    "print(\"Total QA pairs:\", len(df_qa))\n",
    "display(df_qa.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d248dd0",
   "metadata": {},
   "source": [
    "## Cell 4 – Build multiple-choice prompts and answer key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ae872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC prompts: 1536\n",
      "Saved MC prompts to: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\data\\processed\\LoRA_Processed_Inputs\\mc_prompts.json\n",
      "Saved answer key to: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\data\\processed\\LoRA_Processed_Inputs\\mc_answer_key.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_mc_prompts(df: pd.DataFrame, seed: int = 123):\n",
    "    rng = random.Random(seed)\n",
    "    prompts = []\n",
    "    answer_key = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        qid = row[\"q_id\"]\n",
    "        question = row[\"question\"]\n",
    "        correct = row[\"correct_answer\"]\n",
    "        wrongs = list(row[\"wrong_options\"])\n",
    "        all_options = [correct] + wrongs\n",
    "        if len(all_options) != 4:\n",
    "            continue\n",
    "        rng.shuffle(all_options)\n",
    "        letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "        letter_to_option = {ltr: opt for ltr, opt in zip(letters, all_options)}\n",
    "        correct_letter = next(ltr for ltr, opt in letter_to_option.items() if opt == correct)\n",
    "\n",
    "        prompt_text = (\n",
    "            \"You are a knowledgeable Formula 1 expert.\\n\"\n",
    "            \"Answer the following multiple-choice question.\\n\\n\"\n",
    "            f\"Question: {question}\\n\"\n",
    "            \"Options:\\n\"\n",
    "            f\"A. {letter_to_option['A']}\\n\"\n",
    "            f\"B. {letter_to_option['B']}\\n\"\n",
    "            f\"C. {letter_to_option['C']}\\n\"\n",
    "            f\"D. {letter_to_option['D']}\\n\\n\"\n",
    "            'Respond in JSON with two fields: \"answer\" (one of \"A\",\"B\",\"C\",\"D\") and '\n",
    "            '\"explanation\" (one sentence explaining your choice).'\n",
    "        )\n",
    "\n",
    "        prompts.append(\n",
    "            {\n",
    "                \"q_id\": qid,\n",
    "                \"article_number\": row[\"article_number\"],\n",
    "                \"question\": question,\n",
    "                \"options\": letter_to_option,\n",
    "                \"prompt\": prompt_text,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        answer_key.append(\n",
    "            {\n",
    "                \"q_id\": qid,\n",
    "                \"correct_letter\": correct_letter,\n",
    "                \"correct_answer\": correct,\n",
    "                \"article_number\": row[\"article_number\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return prompts, answer_key\n",
    "\n",
    "mc_prompts, mc_answer_key = build_mc_prompts(df_qa, seed=SEED)\n",
    "print(\"MC prompts:\", len(mc_prompts))\n",
    "\n",
    "mc_prompts_path = EVAL_OUTPUT_DIR / \"mc_prompts.json\"\n",
    "mc_answer_key_path = EVAL_OUTPUT_DIR / \"mc_answer_key.json\"\n",
    "\n",
    "with open(mc_prompts_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mc_prompts, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(mc_answer_key_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mc_answer_key, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved MC prompts to:\", mc_prompts_path)\n",
    "print(\"Saved answer key to:\", mc_answer_key_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc9ecc",
   "metadata": {},
   "source": [
    "## Cell 5 – Build supervised training texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f39ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: Which driver achieved a double win at the US Grand Prix in Austin?\\nAnswer: Max Verstappen', 'q_id': '1_0'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_train_texts(df: pd.DataFrame):\n",
    "    texts = []\n",
    "    for _, row in df.iterrows():\n",
    "        q = row[\"question\"]\n",
    "        a = row[\"correct_answer\"]\n",
    "        text = (\n",
    "            \"You are a knowledgeable Formula 1 expert.\\n\"\n",
    "            \"Answer the question briefly and accurately.\\n\\n\"\n",
    "            f\"Question: {q}\\n\"\n",
    "            f\"Answer: {a}\"\n",
    "        )\n",
    "        texts.append({\"text\": text, \"q_id\": row[\"q_id\"]})\n",
    "    return texts\n",
    "\n",
    "train_records = build_train_texts(df_qa)\n",
    "train_dataset = Dataset.from_list(train_records)\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23331c2d",
   "metadata": {},
   "source": [
    "## Cell 6 – Helper utilities (tokenization, model loading, LoRA, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f777be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_callback import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "def create_tokenizer(model_id: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id,\n",
    "        use_fast=True,\n",
    "        token=hf_token,\n",
    "    )\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer\n",
    "\n",
    "def get_model_cache_subdir(model_id: str):\n",
    "    safe_name = model_id.replace(\"/\", \"_\")\n",
    "    return MODEL_CACHE_DIR / safe_name\n",
    "\n",
    "def create_base_model(model_id: str):\n",
    "    cache_dir = get_model_cache_subdir(model_id)\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        token=hf_token,\n",
    "        trust_remote_code=True,\n",
    "        cache_dir=str(cache_dir),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def apply_lora(model):\n",
    "    lora_config = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=[\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "            \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "        ],\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model\n",
    "\n",
    "def tokenize_sft_function(examples, tokenizer):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQ_LEN,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # Add labels so the model can compute loss\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "def parse_model_json_output(text: str):\n",
    "    try:\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\")\n",
    "        if start == -1 or end == -1 or end <= start:\n",
    "            return None\n",
    "        snippet = text[start : end + 1]\n",
    "        obj = json.loads(snippet)\n",
    "        ans = obj.get(\"answer\")\n",
    "        expl = obj.get(\"explanation\")\n",
    "        if isinstance(ans, str):\n",
    "            ans = ans.strip().upper()\n",
    "        return {\"answer\": ans, \"explanation\": expl}\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def run_mc_evaluation(model, tokenizer, mc_prompts, mc_answer_key, max_new_tokens=64):\n",
    "    model.eval()\n",
    "    id_to_correct = {item[\"q_id\"]: item[\"correct_letter\"] for item in mc_answer_key}\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    details = []\n",
    "\n",
    "    for prompt in mc_prompts:\n",
    "        qid = prompt[\"q_id\"]\n",
    "        text = prompt[\"prompt\"]\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=MAX_SEQ_LEN,\n",
    "        )\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                num_beams=1,\n",
    "            )\n",
    "\n",
    "        full_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        parsed = parse_model_json_output(full_text)\n",
    "        pred = None\n",
    "        if parsed and parsed[\"answer\"] in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            pred = parsed[\"answer\"]\n",
    "        gold = id_to_correct.get(qid)\n",
    "        is_correct = int(pred == gold)\n",
    "        details.append(\n",
    "            {\n",
    "                \"q_id\": qid,\n",
    "                \"pred\": pred,\n",
    "                \"gold\": gold,\n",
    "                \"is_correct\": is_correct,\n",
    "                \"raw_output\": full_text,\n",
    "            }\n",
    "        )\n",
    "        if gold is not None:\n",
    "            total += 1\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return accuracy, details\n",
    "\n",
    "class MCEvalCallback(TrainerCallback):\n",
    "    def __init__(self, model_name: str, tokenizer, mc_prompts, mc_answer_key, results_log: list, output_dir: Path):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mc_prompts = mc_prompts\n",
    "        self.mc_answer_key = mc_answer_key\n",
    "        self.results_log = results_log\n",
    "        self.output_dir = Path(output_dir)\n",
    "\n",
    "    def on_epoch_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        epoch = state.epoch\n",
    "        start = time.perf_counter()\n",
    "        acc, _ = run_mc_evaluation(\n",
    "            kwargs[\"model\"],\n",
    "            self.tokenizer,\n",
    "            self.mc_prompts,\n",
    "            self.mc_answer_key,\n",
    "        )\n",
    "        duration = time.perf_counter() - start\n",
    "        checkpoint_dir = self.output_dir / f\"checkpoint-{state.global_step}\"\n",
    "        record = {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"epoch\": epoch,\n",
    "            \"mc_eval_accuracy\": acc,\n",
    "            \"mc_eval_time_sec\": duration,\n",
    "            \"global_step\": state.global_step,\n",
    "            \"checkpoint_dir\": str(checkpoint_dir),\n",
    "        }\n",
    "        print(f\"[{self.model_name}] Epoch {epoch:.2f} MC accuracy: {acc:.4f}, time: {duration:.2f}s\")\n",
    "        self.results_log.append(record)\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222b9e9",
   "metadata": {},
   "source": [
    "## Cell 7 – Prepare containers for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b59b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_epoch_logs = []\n",
    "summary_rows = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e4616",
   "metadata": {},
   "source": [
    "## Cell 8 - Seperated Train and Test (Mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf12771",
   "metadata": {},
   "source": [
    "### Mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88bb0d",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d46e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First 5 raw training examples from train_dataset ===\n",
      "\n",
      "--- Raw example 0 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: Which driver achieved a double win at the US Grand Prix in Austin?\\nAnswer: Max Verstappen', 'q_id': '1_0'}\n",
      "\n",
      "--- Raw example 1 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: What challenge did McLaren face during the US Grand Prix?\\nAnswer: Tough questions over its strategy', 'q_id': '1_1'}\n",
      "\n",
      "--- Raw example 2 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: What type of race experience did fans have during the US GP?\\nAnswer: Another processional race', 'q_id': '1_2'}\n",
      "\n",
      "--- Raw example 3 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: What is the typical format of a Formula 1 qualifying session?\\nAnswer: Three knockout rounds: Q1, Q2, and Q3.', 'q_id': '10_0'}\n",
      "\n",
      "--- Raw example 4 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: In which city is the United States Grand Prix traditionally held?\\nAnswer: Austin, Texas.', 'q_id': '10_1'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4d1f778262405981a3ac32c7d24d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mistral tokenized dataset size: 1536\n",
      "\n",
      "=== First 3 tokenized Mistral training prompts (decoded) ===\n",
      "\n",
      "--- Tokenized example 0 ---\n",
      "<s> You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which driver achieved a double win at the US Grand Prix in Austin?\n",
      "Answer: Max Verstappen</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></\n",
      "\n",
      "--- Tokenized example 1 ---\n",
      "<s> You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What challenge did McLaren face during the US Grand Prix?\n",
      "Answer: Tough questions over its strategy</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
      "\n",
      "--- Tokenized example 2 ---\n",
      "<s> You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What type of race experience did fans have during the US GP?\n",
      "Answer: Another processional race</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc02d490bcef4f6b96f1c17961191b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamiy\\AppData\\Local\\Temp\\ipykernel_72008\\3560160232.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  mistral_trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,971,520 || all params: 7,262,703,616 || trainable%: 0.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "d:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\.venv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 1:17:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.784200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.031900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\.venv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mistral training runtime (sec): 4690.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46127"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Mistral LoRA training (with debug prints) ===\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Sanity check: show the first 5 *raw* training examples before tokenization\n",
    "print(\"=== First 5 raw training examples from train_dataset ===\")\n",
    "for i in range(min(5, len(train_dataset))):\n",
    "    print(f\"\\n--- Raw example {i} ---\")\n",
    "    print(train_dataset[i])\n",
    "\n",
    "# ---------------- Mistral config & tokenizer ----------------\n",
    "mistral_cfg = next(m for m in MODELS if m[\"name\"] == \"mistral-7b\")\n",
    "MISTRAL_ID = mistral_cfg[\"id\"]\n",
    "MISTRAL_NAME = mistral_cfg[\"name\"]\n",
    "\n",
    "mistral_tokenizer = create_tokenizer(MISTRAL_ID)\n",
    "\n",
    "# Tokenize SFT dataset for Mistral\n",
    "mistral_ds = train_dataset.map(\n",
    "    lambda examples: tokenize_sft_function(examples, mistral_tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    ")\n",
    "print(\"\\nMistral tokenized dataset size:\", len(mistral_ds))\n",
    "\n",
    "# Optional: decode the first 3 tokenized prompts to see what the model actually gets\n",
    "print(\"\\n=== First 3 tokenized Mistral training prompts (decoded) ===\")\n",
    "for i in range(min(3, len(mistral_ds))):\n",
    "    ids = mistral_ds[i][\"input_ids\"]\n",
    "    text = mistral_tokenizer.decode(ids, skip_special_tokens=False)\n",
    "    print(f\"\\n--- Tokenized example {i} ---\")\n",
    "    print(text[:1000])  # truncate just in case\n",
    "\n",
    "# ---------------- Mistral base model + LoRA ----------------\n",
    "mistral_base_model = create_base_model(MISTRAL_ID)\n",
    "mistral_lora_model = apply_lora(mistral_base_model)\n",
    "\n",
    "# Make sure pad_token_id is set (helps both training and later eval)\n",
    "if mistral_tokenizer.pad_token_id is None and mistral_tokenizer.eos_token_id is not None:\n",
    "    mistral_tokenizer.pad_token_id = mistral_tokenizer.eos_token_id\n",
    "if mistral_lora_model.config.pad_token_id is None and mistral_lora_model.config.eos_token_id is not None:\n",
    "    mistral_lora_model.config.pad_token_id = mistral_lora_model.config.eos_token_id\n",
    "\n",
    "mistral_output_dir = RESULTS_DIR / \"mistral_lora\"\n",
    "mistral_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mistral_train_args = TrainingArguments(\n",
    "    output_dir=str(mistral_output_dir),\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "mistral_trainer = Trainer(\n",
    "    model=mistral_lora_model,\n",
    "    args=mistral_train_args,\n",
    "    train_dataset=mistral_ds,\n",
    "    tokenizer=mistral_tokenizer,\n",
    ")\n",
    "\n",
    "mistral_train_start = time.perf_counter()\n",
    "mistral_train_result = mistral_trainer.train()\n",
    "mistral_train_time = time.perf_counter() - mistral_train_start\n",
    "\n",
    "print(\"\\nMistral training runtime (sec):\", round(mistral_train_time, 2))\n",
    "\n",
    "mistral_trainer.save_model()\n",
    "\n",
    "mistral_log_history = mistral_trainer.state.log_history\n",
    "mistral_loss_entries = [e for e in mistral_log_history if \"loss\" in e]\n",
    "mistral_final_train_loss = mistral_loss_entries[-1][\"loss\"] if mistral_loss_entries else None\n",
    "\n",
    "with open(mistral_output_dir / \"mistral_train_log.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mistral_log_history, f, indent=2)\n",
    "\n",
    "mistral_train_meta = {\n",
    "    \"model_name\": MISTRAL_NAME,\n",
    "    \"train_time_sec\": mistral_train_time,\n",
    "    \"final_train_loss\": mistral_final_train_loss,\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"num_steps\": len(mistral_loss_entries),\n",
    "    \"machine_info\": MACHINE_INFO,\n",
    "}\n",
    "with open(mistral_output_dir / \"mistral_train_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mistral_train_meta, f, indent=2)\n",
    "\n",
    "del mistral_trainer\n",
    "del mistral_lora_model\n",
    "del mistral_base_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3d4cc",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd172870",
   "metadata": {},
   "source": [
    "##### Using Dharmics' Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39e5a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation QA from 527 files in D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\data\\processed\\big_data_dataset_evalScripts\\dataset\n",
      "Total evaluation questions: 1581\n",
      "\n",
      "=== First 5 eval examples (question + options + ground truth) ===\n",
      "\n",
      "--- Eval example 0 from qa_1.json (qa_index=0) ---\n",
      "Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
      "Options: {'A': 'Sergio Pérez', 'B': 'Lewis Hamilton', 'C': 'Max Verstappen', 'D': 'Charles Leclerc'}\n",
      "Ground truth: C\n",
      "\n",
      "--- Eval example 1 from qa_1.json (qa_index=1) ---\n",
      "Question: What difficulties did McLaren encounter during the US Grand Prix?\n",
      "Options: {'A': 'Tough questions over its strategy', 'B': 'Pirelli tire failures', 'C': 'Driver penalties', 'D': 'Performance issues with the car'}\n",
      "Ground truth: A\n",
      "\n",
      "--- Eval example 2 from qa_1.json (qa_index=2) ---\n",
      "Question: What kind of race experience did fans encounter at the US GP?\n",
      "Options: {'A': 'An exciting battle for the lead', 'B': 'Another processional race', 'C': 'Multiple safety car periods', 'D': 'Frequent position changes'}\n",
      "Ground truth: B\n",
      "\n",
      "--- Eval example 3 from qa_10.json (qa_index=0) ---\n",
      "Question: What is the usual structure of a Formula 1 qualifying session?\n",
      "Options: {'A': 'Three knockout rounds: Q1, Q2, and Q3.', 'B': 'Single lap time trial for all drivers.', 'C': 'A reverse grid format.', 'D': 'Two 30-minute sessions.'}\n",
      "Ground truth: A\n",
      "\n",
      "--- Eval example 4 from qa_10.json (qa_index=1) ---\n",
      "Question: Which city traditionally hosts the United States Grand Prix?\n",
      "Options: {'A': 'New York City, New York.', 'B': 'Los Angeles, California.', 'C': 'Austin, Texas.', 'D': 'Miami, Florida.'}\n",
      "Ground truth: C\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dc96a80c9c48c182829a1ffa5f71d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring question 1/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.344, B:-0.928, C:-0.319, D:-1.224\n",
      "\n",
      "Scoring question 21/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.250, B:-0.633, C:-0.454, D:-1.601\n",
      "\n",
      "Scoring question 41/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.153, B:-0.355, C:-0.623, D:-1.170\n",
      "\n",
      "Scoring question 61/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-3.799, B:-1.589, C:-1.302, D:-0.021\n",
      "\n",
      "Scoring question 81/1581...\n",
      "  -> predicted: D, gt: C, correct: False\n",
      "  -> scores: A:-0.503, B:-1.182, C:-0.372, D:-0.096\n",
      "\n",
      "Scoring question 101/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.228, B:-1.607, C:-0.815, D:-0.670\n",
      "\n",
      "Scoring question 121/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.031, B:-0.672, C:-0.399, D:-1.194\n",
      "\n",
      "Scoring question 141/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.811, B:-0.130, C:-0.918, D:-1.990\n",
      "\n",
      "Scoring question 161/1581...\n",
      "  -> predicted: A, gt: D, correct: False\n",
      "  -> scores: A:-0.465, B:-4.746, C:-1.295, D:-1.160\n",
      "\n",
      "Scoring question 181/1581...\n",
      "  -> predicted: B, gt: C, correct: False\n",
      "  -> scores: A:-1.204, B:-0.324, C:-0.586, D:-0.687\n",
      "\n",
      "Scoring question 201/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.532, B:-0.919, C:-0.011, D:-0.692\n",
      "\n",
      "Scoring question 221/1581...\n",
      "  -> predicted: C, gt: A, correct: False\n",
      "  -> scores: A:-1.616, B:-2.369, C:-0.097, D:-1.067\n",
      "\n",
      "Scoring question 241/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.010, B:-1.302, C:-1.554, D:-4.488\n",
      "\n",
      "Scoring question 261/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.148, B:-1.135, C:-0.874, D:-1.739\n",
      "\n",
      "Scoring question 281/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.483, B:-4.395, C:-2.451, D:-2.705\n",
      "\n",
      "Scoring question 301/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.663, B:-1.483, C:-0.151, D:-1.230\n",
      "\n",
      "Scoring question 321/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-1.178, B:-1.046, C:-1.886, D:-2.551\n",
      "\n",
      "Scoring question 341/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.065, B:-0.556, C:-0.612, D:-0.428\n",
      "\n",
      "Scoring question 361/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.680, B:-0.011, C:-1.580, D:-1.910\n",
      "\n",
      "Scoring question 381/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.653, B:-2.303, C:-1.242, D:-0.048\n",
      "\n",
      "Scoring question 401/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-1.741, B:-0.009, C:-2.213, D:-5.855\n",
      "\n",
      "Scoring question 421/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.680, B:-0.017, C:-1.117, D:-1.631\n",
      "\n",
      "Scoring question 441/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-2.523, B:-7.688, C:-0.011, D:-2.480\n",
      "\n",
      "Scoring question 461/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.528, B:-1.332, C:-0.839, D:-1.054\n",
      "\n",
      "Scoring question 481/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.280, B:-1.213, C:-1.460, D:-0.234\n",
      "\n",
      "Scoring question 501/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-7.672, B:-6.938, C:-3.426, D:-0.072\n",
      "\n",
      "Scoring question 521/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.459, B:-1.734, C:-1.101, D:-0.165\n",
      "\n",
      "Scoring question 541/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.539, B:-0.042, C:-2.453, D:-1.433\n",
      "\n",
      "Scoring question 561/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.247, B:-1.551, C:-2.279, D:-1.825\n",
      "\n",
      "Scoring question 581/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.581, B:-0.018, C:-1.696, D:-1.556\n",
      "\n",
      "Scoring question 601/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.027, B:-2.143, C:-4.641, D:-2.896\n",
      "\n",
      "Scoring question 621/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-2.924, B:-6.477, C:-2.898, D:-0.003\n",
      "\n",
      "Scoring question 641/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.636, B:-0.558, C:-0.322, D:-1.301\n",
      "\n",
      "Scoring question 661/1581...\n",
      "  -> predicted: D, gt: A, correct: False\n",
      "  -> scores: A:-0.765, B:-3.178, C:-1.081, D:-0.244\n",
      "\n",
      "Scoring question 681/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.726, B:-0.255, C:-1.303, D:-1.592\n",
      "\n",
      "Scoring question 701/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-6.445, B:-5.492, C:-9.352, D:-0.004\n",
      "\n",
      "Scoring question 721/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.344, B:-4.098, C:-0.897, D:-0.828\n",
      "\n",
      "Scoring question 741/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.349, B:-1.854, C:-2.766, D:-0.235\n",
      "\n",
      "Scoring question 761/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.139, B:-1.462, C:-0.906, D:-1.829\n",
      "\n",
      "Scoring question 781/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-2.131, B:-0.118, C:-2.797, D:-2.359\n",
      "\n",
      "Scoring question 801/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.435, B:-2.221, C:-0.753, D:-0.006\n",
      "\n",
      "Scoring question 821/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.239, B:-1.112, C:-0.837, D:-0.438\n",
      "\n",
      "Scoring question 841/1581...\n",
      "  -> predicted: C, gt: D, correct: False\n",
      "  -> scores: A:-0.912, B:-0.965, C:-0.078, D:-0.688\n",
      "\n",
      "Scoring question 861/1581...\n",
      "  -> predicted: A, gt: D, correct: False\n",
      "  -> scores: A:-0.145, B:-3.523, C:-1.230, D:-1.255\n",
      "\n",
      "Scoring question 881/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.068, B:-3.959, C:-10.242, D:-4.539\n",
      "\n",
      "Scoring question 901/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.549, B:-1.858, C:-2.527, D:-3.260\n",
      "\n",
      "Scoring question 921/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.047, B:-0.828, C:-1.465, D:-0.124\n",
      "\n",
      "Scoring question 941/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.187, B:-1.418, C:-3.131, D:-3.027\n",
      "\n",
      "Scoring question 961/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.948, B:-1.658, C:-0.183, D:-1.075\n",
      "\n",
      "Scoring question 981/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.786, B:-0.608, C:-0.550, D:-0.725\n",
      "\n",
      "Scoring question 1001/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.080, B:-0.172, C:-0.489, D:-0.648\n",
      "\n",
      "Scoring question 1021/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.087, B:-0.223, C:-0.216, D:-0.152\n",
      "\n",
      "Scoring question 1041/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.381, B:-1.321, C:-0.788, D:-0.210\n",
      "\n",
      "Scoring question 1061/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-2.367, B:-8.578, C:-0.005, D:-2.680\n",
      "\n",
      "Scoring question 1081/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-2.121, B:-5.551, C:-0.028, D:-1.189\n",
      "\n",
      "Scoring question 1101/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.632, B:-0.746, C:-0.542, D:-0.036\n",
      "\n",
      "Scoring question 1121/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-2.213, B:-0.747, C:-3.074, D:-2.943\n",
      "\n",
      "Scoring question 1141/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.067, B:-0.811, C:-0.612, D:-1.416\n",
      "\n",
      "Scoring question 1161/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.100, B:-0.291, C:-0.572, D:-0.803\n",
      "\n",
      "Scoring question 1181/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.433, B:-0.982, C:-0.715, D:-0.941\n",
      "\n",
      "Scoring question 1201/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-3.352, B:-0.054, C:-2.432, D:-3.363\n",
      "\n",
      "Scoring question 1221/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.931, B:-0.637, C:-0.245, D:-0.147\n",
      "\n",
      "Scoring question 1241/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.843, B:-1.913, C:-0.031, D:-1.783\n",
      "\n",
      "Scoring question 1261/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.319, B:-1.962, C:-0.471, D:-0.167\n",
      "\n",
      "Scoring question 1281/1581...\n",
      "  -> predicted: A, gt: D, correct: False\n",
      "  -> scores: A:-0.038, B:-0.548, C:-0.319, D:-0.214\n",
      "\n",
      "Scoring question 1301/1581...\n",
      "  -> predicted: C, gt: A, correct: False\n",
      "  -> scores: A:-0.532, B:-0.524, C:-0.331, D:-1.150\n",
      "\n",
      "Scoring question 1321/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.682, B:-0.820, C:-0.591, D:-0.147\n",
      "\n",
      "Scoring question 1341/1581...\n",
      "  -> predicted: A, gt: D, correct: False\n",
      "  -> scores: A:-0.131, B:-0.298, C:-0.181, D:-0.299\n",
      "\n",
      "Scoring question 1361/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.225, B:-1.125, C:-0.569, D:-0.542\n",
      "\n",
      "Scoring question 1381/1581...\n",
      "  -> predicted: D, gt: A, correct: False\n",
      "  -> scores: A:-0.621, B:-2.881, C:-0.753, D:-0.252\n",
      "\n",
      "Scoring question 1401/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.243, B:-3.191, C:-9.258, D:-3.840\n",
      "\n",
      "Scoring question 1421/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.934, B:-1.477, C:-1.823, D:-1.915\n",
      "\n",
      "Scoring question 1441/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.132, B:-0.059, C:-0.706, D:-0.604\n",
      "\n",
      "Scoring question 1461/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.016, B:-1.059, C:-2.490, D:-2.645\n",
      "\n",
      "Scoring question 1481/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.063, B:-1.185, C:-1.827, D:-2.969\n",
      "\n",
      "Scoring question 1501/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-3.932, B:-10.430, C:-4.191, D:-0.009\n",
      "\n",
      "Scoring question 1521/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.887, B:-3.518, C:-0.084, D:-1.502\n",
      "\n",
      "Scoring question 1541/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.216, B:-1.098, C:-0.563, D:-2.680\n",
      "\n",
      "Scoring question 1561/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.234, B:-0.646, C:-0.039, D:-0.882\n",
      "\n",
      "Scoring question 1581/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-1.685, B:-0.677, C:-2.078, D:-1.805\n",
      "================================================================================\n",
      "Sample scoring-based evaluations (first 10):\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_1.json | qa_index: 0\n",
      "Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
      "Options: A:Sergio Pérez | B:Lewis Hamilton | C:Max Verstappen | D:Charles Leclerc\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
      "Options:\n",
      "A: Sergio Pérez\n",
      "B: Lewis Hamilton\n",
      "C: Max Verstappen\n",
      "D: Charles Leclerc\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.3438\n",
      "  B: -0.9277\n",
      "  C: -0.3193\n",
      "  D: -1.2236\n",
      "\n",
      "Ground truth option: C\n",
      "Model chosen option: C\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_1.json | qa_index: 1\n",
      "Question: What difficulties did McLaren encounter during the US Grand Prix?\n",
      "Options: A:Tough questions over its strategy | B:Pirelli tire failures | C:Driver penalties | D:Performance issues with the car\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What difficulties did McLaren encounter during the US Grand Prix?\n",
      "Options:\n",
      "A: Tough questions over its strategy\n",
      "B: Pirelli tire failures\n",
      "C: Driver penalties\n",
      "D: Performance issues with the car\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.5645\n",
      "  B: -1.3730\n",
      "  C: -1.3828\n",
      "  D: -0.6577\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: A\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_1.json | qa_index: 2\n",
      "Question: What kind of race experience did fans encounter at the US GP?\n",
      "Options: A:An exciting battle for the lead | B:Another processional race | C:Multiple safety car periods | D:Frequent position changes\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What kind of race experience did fans encounter at the US GP?\n",
      "Options:\n",
      "A: An exciting battle for the lead\n",
      "B: Another processional race\n",
      "C: Multiple safety car periods\n",
      "D: Frequent position changes\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.2693\n",
      "  B: -0.2893\n",
      "  C: -1.0332\n",
      "  D: -0.7622\n",
      "\n",
      "Ground truth option: B\n",
      "Model chosen option: A\n",
      "Correct?: False\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_10.json | qa_index: 0\n",
      "Question: What is the usual structure of a Formula 1 qualifying session?\n",
      "Options: A:Three knockout rounds: Q1, Q2, and Q3. | B:Single lap time trial for all drivers. | C:A reverse grid format. | D:Two 30-minute sessions.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What is the usual structure of a Formula 1 qualifying session?\n",
      "Options:\n",
      "A: Three knockout rounds: Q1, Q2, and Q3.\n",
      "B: Single lap time trial for all drivers.\n",
      "C: A reverse grid format.\n",
      "D: Two 30-minute sessions.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.0504\n",
      "  B: -1.3535\n",
      "  C: -3.3789\n",
      "  D: -1.0029\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: A\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_10.json | qa_index: 1\n",
      "Question: Which city traditionally hosts the United States Grand Prix?\n",
      "Options: A:New York City, New York. | B:Los Angeles, California. | C:Austin, Texas. | D:Miami, Florida.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which city traditionally hosts the United States Grand Prix?\n",
      "Options:\n",
      "A: New York City, New York.\n",
      "B: Los Angeles, California.\n",
      "C: Austin, Texas.\n",
      "D: Miami, Florida.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -1.3496\n",
      "  B: -1.6133\n",
      "  C: -0.2402\n",
      "  D: -0.4446\n",
      "\n",
      "Ground truth option: C\n",
      "Model chosen option: C\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_10.json | qa_index: 2\n",
      "Question: What is the primary objective of the qualifying session in Formula 1?\n",
      "Options: A:To practice pit stop strategies. | B:To test car performance under race conditions. | C:To set the fastest lap for championship points. | D:To determine the starting grid for the race.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What is the primary objective of the qualifying session in Formula 1?\n",
      "Options:\n",
      "A: To practice pit stop strategies.\n",
      "B: To test car performance under race conditions.\n",
      "C: To set the fastest lap for championship points.\n",
      "D: To determine the starting grid for the race.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -3.3223\n",
      "  B: -1.9531\n",
      "  C: -0.6152\n",
      "  D: -0.0210\n",
      "\n",
      "Ground truth option: D\n",
      "Model chosen option: D\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_100.json | qa_index: 0\n",
      "Question: For which team does Oscar Piastri race in Formula 1?\n",
      "Options: A:McLaren | B:Ferrari | C:Red Bull Racing | D:Alpine\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: For which team does Oscar Piastri race in Formula 1?\n",
      "Options:\n",
      "A: McLaren\n",
      "B: Ferrari\n",
      "C: Red Bull Racing\n",
      "D: Alpine\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.0450\n",
      "  B: -4.1328\n",
      "  C: -2.6504\n",
      "  D: -0.7534\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: A\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_100.json | qa_index: 1\n",
      "Question: Which position did Oscar Piastri relinquish during the Monza race?\n",
      "Options: A:Third place | B:Second place | C:Fourth place | D:First place\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which position did Oscar Piastri relinquish during the Monza race?\n",
      "Options:\n",
      "A: Third place\n",
      "B: Second place\n",
      "C: Fourth place\n",
      "D: First place\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.5869\n",
      "  B: -0.8057\n",
      "  C: -0.5327\n",
      "  D: -1.0479\n",
      "\n",
      "Ground truth option: B\n",
      "Model chosen option: C\n",
      "Correct?: False\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_100.json | qa_index: 2\n",
      "Question: What characteristic is commonly linked to successful Formula 1 champions?\n",
      "Options: A:Teamwork | B:Ruthlessness | C:Caution | D:Consistency\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What characteristic is commonly linked to successful Formula 1 champions?\n",
      "Options:\n",
      "A: Teamwork\n",
      "B: Ruthlessness\n",
      "C: Caution\n",
      "D: Consistency\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -2.2832\n",
      "  B: -0.4355\n",
      "  C: -0.6133\n",
      "  D: -0.5664\n",
      "\n",
      "Ground truth option: B\n",
      "Model chosen option: B\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_101.json | qa_index: 0\n",
      "Question: What is the importance of team orders in Formula 1?\n",
      "Options: A:Team orders are instructions given by a team to its drivers to manage their race positions or strategies, often to maximize points for the team. | B:Team orders are penalties given to drivers for unsafe driving. | C:Team orders are the regulations governing car design. | D:Team orders are rules about tire usage during a race.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What is the importance of team orders in Formula 1?\n",
      "Options:\n",
      "A: Team orders are instructions given by a team to its drivers to manage their race positions or strategies, often to maximize points for the team.\n",
      "B: Team orders are penalties given to drivers for unsafe driving.\n",
      "C: Team orders are the regulations governing car design.\n",
      "D: Team orders are rules about tire usage during a race.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.1306\n",
      "  B: -1.3633\n",
      "  C: -1.5908\n",
      "  D: -1.3906\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: A\n",
      "Correct?: True\n",
      "================================================================================\n",
      "Total: 1581, Correct: 1143\n",
      "Accuracy: 72.30%\n",
      "Eval time (sec): 936.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Mistral LoRA evaluation on big_data_dataset_evalScripts using scoring (no generation) ===\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from peft import PeftModel\n",
    "\n",
    "BIG_EVAL_DATASET_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"big_data_dataset_evalScripts\" / \"dataset\"\n",
    "\n",
    "def load_big_eval_questions_for_scoring(input_dir: Path):\n",
    "    \"\"\"\n",
    "    Load eval questions from qa_*.json.\n",
    "\n",
    "    We use:\n",
    "      - question (or rephrased_question if available)\n",
    "      - options (dict A,B,C,D)\n",
    "      - ground_truth_correct_option (letter)\n",
    "    We IGNORE the dataset 'prompt' and build our own prompt that matches training style.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    qa_files = sorted(input_dir.glob(\"qa_*.json\"))\n",
    "    print(f\"Loading evaluation QA from {len(qa_files)} files in {input_dir}\")\n",
    "    for path in qa_files:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        qa_pairs = data.get(\"qa_pairs\", [])\n",
    "        try:\n",
    "            file_index = int(path.stem.split(\"_\")[1])\n",
    "        except Exception:\n",
    "            file_index = None\n",
    "        for idx, qa in enumerate(qa_pairs):\n",
    "            question = qa.get(\"rephrased_question\", qa[\"question\"])\n",
    "            options = qa[\"options\"]\n",
    "            gt = qa[\"ground_truth_correct_option\"]\n",
    "            examples.append(\n",
    "                {\n",
    "                    \"file\": path.name,\n",
    "                    \"file_index\": file_index,\n",
    "                    \"qa_index\": idx,\n",
    "                    \"question\": question,\n",
    "                    \"options\": options,\n",
    "                    \"ground_truth\": gt,\n",
    "                }\n",
    "            )\n",
    "    print(f\"Total evaluation questions: {len(examples)}\")\n",
    "    return examples\n",
    "\n",
    "def build_scoring_prompt(question: str, options: dict) -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt that matches the SFT training style:\n",
    "      - brief instruction\n",
    "      - question\n",
    "      - options\n",
    "      - 'Answer:' cue (we will append option text after this when scoring).\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"You are a knowledgeable Formula 1 expert.\\n\"\n",
    "        \"Answer the question briefly and accurately.\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        \"Options:\\n\"\n",
    "        f\"A: {options['A']}\\n\"\n",
    "        f\"B: {options['B']}\\n\"\n",
    "        f\"C: {options['C']}\\n\"\n",
    "        f\"D: {options['D']}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "def score_option_logprob(model, tokenizer, prompt: str, option_text: str, max_length: int = MAX_SEQ_LEN):\n",
    "    \"\"\"\n",
    "    Compute the average log-prob of the option_text tokens, conditioned on the prompt.\n",
    "\n",
    "    Steps:\n",
    "      - tokenize prompt\n",
    "      - tokenize answer (option_text)\n",
    "      - concat [prompt_ids + answer_ids]\n",
    "      - run model\n",
    "      - extract log-probs for each answer token\n",
    "      - return mean log-prob as the score\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize prompt and answer\n",
    "    prompt_enc = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    ans_enc = tokenizer(\n",
    "        \" \" + option_text,   # leading space for better tokenization\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "    prompt_ids = prompt_enc[\"input_ids\"].to(model.device)\n",
    "    ans_ids = ans_enc[\"input_ids\"].to(model.device)\n",
    "\n",
    "    # Concatenate\n",
    "    input_ids = torch.cat([prompt_ids, ans_ids], dim=1)  # [1, L_prompt + L_ans]\n",
    "    attention_mask = torch.ones_like(input_ids, device=model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [1, seq_len, vocab_size]\n",
    "\n",
    "    # Lengths\n",
    "    L_prompt = prompt_ids.shape[1]\n",
    "    L_ans = ans_ids.shape[1]\n",
    "\n",
    "    # We want log P(answer_tokens | prompt + previous answer_tokens)\n",
    "    # For token a_j, its probability is predicted at position (L_prompt - 1 + j)\n",
    "    # So slice logits[:, L_prompt-1 : L_prompt-1+L_ans, :]\n",
    "    logits_for_ans = logits[:, L_prompt - 1 : L_prompt - 1 + L_ans, :]  # [1, L_ans, V]\n",
    "    log_probs = F.log_softmax(logits_for_ans, dim=-1)  # [1, L_ans, V]\n",
    "\n",
    "    # Gather log-probs of actual answer tokens\n",
    "    ans_ids_only = ans_ids  # [1, L_ans]\n",
    "    token_logprobs = log_probs.gather(-1, ans_ids_only.unsqueeze(-1)).squeeze(-1)  # [1, L_ans]\n",
    "\n",
    "    # Average log-prob per token\n",
    "    avg_logprob = token_logprobs.mean().item()\n",
    "\n",
    "    return avg_logprob\n",
    "\n",
    "def run_big_mc_eval_scoring(model, tokenizer, eval_examples, sample_print=10):\n",
    "    \"\"\"\n",
    "    Multiple-choice eval using log-prob scoring, NOT generation.\n",
    "\n",
    "    For each question:\n",
    "      - Build training-style prompt with question + options\n",
    "      - For each (A,B,C,D), compute log-prob(score) of the option text\n",
    "      - Pick option with highest score\n",
    "\n",
    "    Prints progress lines like:\n",
    "    Scoring question 1/1581...\n",
    "      -> predicted: C, gt: C, correct: True\n",
    "      -> scores: A:-4.123, B:-3.985, C:-2.110, D:-3.450\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total = len(eval_examples)\n",
    "    correct = 0\n",
    "    details = []\n",
    "\n",
    "    # Ensure pad_token_id is set\n",
    "    if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    if model.config.pad_token_id is None and model.config.eos_token_id is not None:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for i, ex in enumerate(eval_examples):\n",
    "        q = ex[\"question\"]\n",
    "        options = ex[\"options\"]\n",
    "        gt = ex[\"ground_truth\"]\n",
    "\n",
    "        prompt = build_scoring_prompt(q, options)\n",
    "\n",
    "        # Compute scores for each option\n",
    "        scores = {}\n",
    "        for letter in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            opt_text = options[letter]\n",
    "            score = score_option_logprob(model, tokenizer, prompt, opt_text)\n",
    "            scores[letter] = score\n",
    "\n",
    "        # Pick best letter\n",
    "        best_letter = max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "        is_corr = best_letter == gt\n",
    "        if is_corr:\n",
    "            correct += 1\n",
    "\n",
    "        # PROGRESS + RESULT LOGGING (every 20 questions; change to \"if True\" for all)\n",
    "        if i % 20 == 0:\n",
    "            print(f\"\\nScoring question {i+1}/{total}...\")\n",
    "            print(f\"  -> predicted: {best_letter}, gt: {gt}, correct: {is_corr}\")\n",
    "            # nice compact score print\n",
    "            score_str = \", \".join([f\"{L}:{scores[L]:.3f}\" for L in [\"A\", \"B\", \"C\", \"D\"]])\n",
    "            print(f\"  -> scores: {score_str}\")\n",
    "\n",
    "        details.append(\n",
    "            {\n",
    "                \"file\": ex[\"file\"],\n",
    "                \"qa_index\": ex[\"qa_index\"],\n",
    "                \"question\": q,\n",
    "                \"options\": options,\n",
    "                \"ground_truth\": gt,\n",
    "                \"model_option\": best_letter,\n",
    "                \"is_correct\": is_corr,\n",
    "                \"scores\": scores,\n",
    "                \"prompt_used\": prompt,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    eval_time = time.perf_counter() - t0\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    # --- Print first N summaries in detail ---\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Sample scoring-based evaluations (first {sample_print}):\")\n",
    "    for sample in details[: min(sample_print, len(details))]:\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"File: {sample['file']} | qa_index: {sample['qa_index']}\")\n",
    "        print(\"Question:\", sample[\"question\"])\n",
    "        opts = sample[\"options\"]\n",
    "        print(f\"Options: A:{opts['A']} | B:{opts['B']} | C:{opts['C']} | D:{opts['D']}\")\n",
    "        print(\"\\nPROMPT USED FOR SCORING:\\n\")\n",
    "        print(sample[\"prompt_used\"])\n",
    "        print(\"\\nScores per option (avg log-prob):\")\n",
    "        for letter, s in sample[\"scores\"].items():\n",
    "            print(f\"  {letter}: {s:.4f}\")\n",
    "        print(\"\\nGround truth option:\", sample[\"ground_truth\"])\n",
    "        print(\"Model chosen option:\", sample[\"model_option\"])\n",
    "        print(\"Correct?:\", sample[\"is_correct\"])\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total: {total}, Correct: {correct}\")\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"Eval time (sec): {round(eval_time, 2)}\")\n",
    "\n",
    "    stats = {\n",
    "        \"total\": total,\n",
    "        \"parsed\": total,\n",
    "        \"skipped\": 0,\n",
    "        \"correct\": correct,\n",
    "    }\n",
    "    return acc, eval_time, details, stats\n",
    "\n",
    "# --- Mistral LoRA eval run (SCORING) ---\n",
    "\n",
    "mistral_cfg = next(m for m in MODELS if m[\"name\"] == \"mistral-7b\")\n",
    "MISTRAL_ID = mistral_cfg[\"id\"]\n",
    "MISTRAL_NAME = mistral_cfg[\"name\"]\n",
    "\n",
    "mistral_eval_tokenizer = create_tokenizer(MISTRAL_ID)\n",
    "mistral_lora_dir = RESULTS_DIR / \"mistral_lora\"\n",
    "\n",
    "big_eval_examples = load_big_eval_questions_for_scoring(BIG_EVAL_DATASET_DIR)\n",
    "\n",
    "# Optional: quickly inspect first 5 eval examples\n",
    "print(\"\\n=== First 5 eval examples (question + options + ground truth) ===\")\n",
    "for i in range(min(5, len(big_eval_examples))):\n",
    "    ex = big_eval_examples[i]\n",
    "    print(f\"\\n--- Eval example {i} from {ex['file']} (qa_index={ex['qa_index']}) ---\")\n",
    "    print(\"Question:\", ex[\"question\"])\n",
    "    print(\"Options:\", ex[\"options\"])\n",
    "    print(\"Ground truth:\", ex[\"ground_truth\"])\n",
    "\n",
    "mistral_eval_base = create_base_model(MISTRAL_ID)\n",
    "mistral_eval_model = PeftModel.from_pretrained(\n",
    "    mistral_eval_base,\n",
    "    str(mistral_lora_dir),\n",
    ")\n",
    "mistral_eval_model.eval()\n",
    "\n",
    "mistral_big_acc, mistral_big_eval_time, mistral_big_details, mistral_big_stats = run_big_mc_eval_scoring(\n",
    "    mistral_eval_model,\n",
    "    mistral_eval_tokenizer,\n",
    "    big_eval_examples,\n",
    "    sample_print=10,\n",
    ")\n",
    "\n",
    "mistral_big_results = {\n",
    "    \"accuracy\": mistral_big_acc,\n",
    "    \"eval_time_sec\": mistral_big_eval_time,\n",
    "    \"stats\": mistral_big_stats,\n",
    "    \"details\": mistral_big_details,\n",
    "    \"dataset_dir\": str(BIG_EVAL_DATASET_DIR),\n",
    "    \"machine_info\": MACHINE_INFO,\n",
    "}\n",
    "\n",
    "EVAL_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(EVAL_RESULTS_DIR / \"mistral_bigdata_eval_results_scoring.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mistral_big_results, f, indent=2)\n",
    "\n",
    "# Try to load training meta (if exists) so summary stays consistent\n",
    "try:\n",
    "    with open(mistral_lora_dir / \"mistral_train_meta.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        mistral_train_meta_loaded = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    mistral_train_meta_loaded = {\"train_time_sec\": None, \"final_train_loss\": None}\n",
    "\n",
    "summary_rows.append(\n",
    "    {\n",
    "        \"model_name\": MISTRAL_NAME,\n",
    "        \"train_time_sec\": mistral_train_meta_loaded.get(\"train_time_sec\"),\n",
    "        \"final_train_loss\": mistral_train_meta_loaded.get(\"final_train_loss\"),\n",
    "        \"final_mc_accuracy\": mistral_big_acc,\n",
    "        \"final_eval_time_sec\": mistral_big_eval_time,\n",
    "        \"best_epoch_mc_accuracy\": None,\n",
    "        \"device_type\": MACHINE_INFO.get(\"device_type\"),\n",
    "        \"gpu_name\": MACHINE_INFO.get(\"gpu_name\"),\n",
    "        \"gpu_memory_gb\": MACHINE_INFO.get(\"gpu_memory_gb\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "del mistral_eval_model\n",
    "del mistral_eval_base\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a0b1d",
   "metadata": {},
   "source": [
    "## Cell 9 - Seperated Train and Test (LLAMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a25c9",
   "metadata": {},
   "source": [
    "### LLAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd5e88",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e8454e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First 5 raw training examples from train_dataset (for LLaMA) ===\n",
      "\n",
      "--- Raw example 0 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: Which driver achieved a double win at the US Grand Prix in Austin?\\nAnswer: Max Verstappen', 'q_id': '1_0'}\n",
      "\n",
      "--- Raw example 1 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: What challenge did McLaren face during the US Grand Prix?\\nAnswer: Tough questions over its strategy', 'q_id': '1_1'}\n",
      "\n",
      "--- Raw example 2 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: What type of race experience did fans have during the US GP?\\nAnswer: Another processional race', 'q_id': '1_2'}\n",
      "\n",
      "--- Raw example 3 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: What is the typical format of a Formula 1 qualifying session?\\nAnswer: Three knockout rounds: Q1, Q2, and Q3.', 'q_id': '10_0'}\n",
      "\n",
      "--- Raw example 4 ---\n",
      "{'text': 'You are a knowledgeable Formula 1 expert.\\nAnswer the question briefly and accurately.\\n\\nQuestion: In which city is the United States Grand Prix traditionally held?\\nAnswer: Austin, Texas.', 'q_id': '10_1'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37c1f99ccf64fd5bdce1f9cf1287514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLaMA tokenized dataset size: 1536\n",
      "\n",
      "=== First 3 tokenized LLaMA training prompts (decoded) ===\n",
      "\n",
      "--- Tokenized example 0 ---\n",
      "<|begin_of_text|>You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which driver achieved a double win at the US Grand Prix in Austin?\n",
      "Answer: Max Verstappen<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_i\n",
      "\n",
      "--- Tokenized example 1 ---\n",
      "<|begin_of_text|>You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What challenge did McLaren face during the US Grand Prix?\n",
      "Answer: Tough questions over its strategy<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_i\n",
      "\n",
      "--- Tokenized example 2 ---\n",
      "<|begin_of_text|>You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What type of race experience did fans have during the US GP?\n",
      "Answer: Another processional race<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a70bd03bb8843308efb9626d3d20a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamiy\\AppData\\Local\\Temp\\ipykernel_73060\\2556828823.py:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  llama_trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "d:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\.venv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 1:21:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.493400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.033800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\.venv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLaMA training runtime (sec): 4927.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === LLaMA LoRA training (with debug prints) ===\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Sanity check: show the first 5 *raw* training examples before tokenization\n",
    "print(\"=== First 5 raw training examples from train_dataset (for LLaMA) ===\")\n",
    "for i in range(min(5, len(train_dataset))):\n",
    "    print(f\"\\n--- Raw example {i} ---\")\n",
    "    print(train_dataset[i])\n",
    "\n",
    "# ---------------- LLaMA config & tokenizer ----------------\n",
    "llama_cfg = next(m for m in MODELS if m[\"name\"] == \"llama-3.1-8b-instruct\")\n",
    "LLAMA_ID = llama_cfg[\"id\"]\n",
    "LLAMA_NAME = llama_cfg[\"name\"]\n",
    "\n",
    "llama_tokenizer = create_tokenizer(LLAMA_ID)\n",
    "\n",
    "# Tokenize SFT dataset for LLaMA\n",
    "llama_ds = train_dataset.map(\n",
    "    lambda examples: tokenize_sft_function(examples, llama_tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    ")\n",
    "print(\"\\nLLaMA tokenized dataset size:\", len(llama_ds))\n",
    "\n",
    "# Optional: decode the first 3 tokenized prompts to see what the model actually gets\n",
    "print(\"\\n=== First 3 tokenized LLaMA training prompts (decoded) ===\")\n",
    "for i in range(min(3, len(llama_ds))):\n",
    "    ids = llama_ds[i][\"input_ids\"]\n",
    "    text = llama_tokenizer.decode(ids, skip_special_tokens=False)\n",
    "    print(f\"\\n--- Tokenized example {i} ---\")\n",
    "    print(text[:1000])\n",
    "\n",
    "# ---------------- LLaMA base model + LoRA ----------------\n",
    "llama_base_model = create_base_model(LLAMA_ID)\n",
    "llama_lora_model = apply_lora(llama_base_model)\n",
    "\n",
    "if llama_tokenizer.pad_token_id is None and llama_tokenizer.eos_token_id is not None:\n",
    "    llama_tokenizer.pad_token_id = llama_tokenizer.eos_token_id\n",
    "if llama_lora_model.config.pad_token_id is None and llama_lora_model.config.eos_token_id is not None:\n",
    "    llama_lora_model.config.pad_token_id = llama_lora_model.config.eos_token_id\n",
    "\n",
    "llama_output_dir = RESULTS_DIR / \"llama_lora\"\n",
    "llama_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "llama_train_args = TrainingArguments(\n",
    "    output_dir=str(llama_output_dir),\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "llama_trainer = Trainer(\n",
    "    model=llama_lora_model,\n",
    "    args=llama_train_args,\n",
    "    train_dataset=llama_ds,\n",
    "    tokenizer=llama_tokenizer,\n",
    ")\n",
    "\n",
    "llama_train_start = time.perf_counter()\n",
    "llama_train_result = llama_trainer.train()\n",
    "llama_train_time = time.perf_counter() - llama_train_start\n",
    "\n",
    "print(\"\\nLLaMA training runtime (sec):\", round(llama_train_time, 2))\n",
    "\n",
    "llama_trainer.save_model()\n",
    "\n",
    "llama_log_history = llama_trainer.state.log_history\n",
    "llama_loss_entries = [e for e in llama_log_history if \"loss\" in e]\n",
    "llama_final_train_loss = llama_loss_entries[-1][\"loss\"] if llama_loss_entries else None\n",
    "\n",
    "with open(llama_output_dir / \"llama_train_log.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(llama_log_history, f, indent=2)\n",
    "\n",
    "llama_train_meta = {\n",
    "    \"model_name\": LLAMA_NAME,\n",
    "    \"train_time_sec\": llama_train_time,\n",
    "    \"final_train_loss\": llama_final_train_loss,\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"num_steps\": len(llama_loss_entries),\n",
    "    \"machine_info\": MACHINE_INFO,\n",
    "}\n",
    "with open(llama_output_dir / \"llama_train_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(llama_train_meta, f, indent=2)\n",
    "\n",
    "del llama_trainer\n",
    "del llama_lora_model\n",
    "del llama_base_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeecd9a",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0ee22",
   "metadata": {},
   "source": [
    "##### Using Dharmics' Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0620b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation QA from 527 files in D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\data\\processed\\big_data_dataset_evalScripts\\dataset\n",
      "Total evaluation questions: 1581\n",
      "\n",
      "=== First 5 eval examples (question + options + ground truth) for LLaMA ===\n",
      "\n",
      "--- Eval example 0 from qa_1.json (qa_index=0) ---\n",
      "Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
      "Options: {'A': 'Sergio Pérez', 'B': 'Lewis Hamilton', 'C': 'Max Verstappen', 'D': 'Charles Leclerc'}\n",
      "Ground truth: C\n",
      "\n",
      "--- Eval example 1 from qa_1.json (qa_index=1) ---\n",
      "Question: What difficulties did McLaren encounter during the US Grand Prix?\n",
      "Options: {'A': 'Tough questions over its strategy', 'B': 'Pirelli tire failures', 'C': 'Driver penalties', 'D': 'Performance issues with the car'}\n",
      "Ground truth: A\n",
      "\n",
      "--- Eval example 2 from qa_1.json (qa_index=2) ---\n",
      "Question: What kind of race experience did fans encounter at the US GP?\n",
      "Options: {'A': 'An exciting battle for the lead', 'B': 'Another processional race', 'C': 'Multiple safety car periods', 'D': 'Frequent position changes'}\n",
      "Ground truth: B\n",
      "\n",
      "--- Eval example 3 from qa_10.json (qa_index=0) ---\n",
      "Question: What is the usual structure of a Formula 1 qualifying session?\n",
      "Options: {'A': 'Three knockout rounds: Q1, Q2, and Q3.', 'B': 'Single lap time trial for all drivers.', 'C': 'A reverse grid format.', 'D': 'Two 30-minute sessions.'}\n",
      "Ground truth: A\n",
      "\n",
      "--- Eval example 4 from qa_10.json (qa_index=1) ---\n",
      "Question: Which city traditionally hosts the United States Grand Prix?\n",
      "Options: {'A': 'New York City, New York.', 'B': 'Los Angeles, California.', 'C': 'Austin, Texas.', 'D': 'Miami, Florida.'}\n",
      "Ground truth: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e37d128c7204c8881496ec1247689c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring question 1/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.173, B:-1.250, C:-0.250, D:-0.746\n",
      "\n",
      "Scoring question 21/1581...\n",
      "  -> predicted: B, gt: C, correct: False\n",
      "  -> scores: A:-0.837, B:-0.789, C:-1.581, D:-2.793\n",
      "\n",
      "Scoring question 41/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-1.478, B:-0.449, C:-1.170, D:-1.716\n",
      "\n",
      "Scoring question 61/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-3.768, B:-1.749, C:-1.527, D:-0.988\n",
      "\n",
      "Scoring question 81/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.473, B:-1.118, C:-0.481, D:-0.591\n",
      "\n",
      "Scoring question 101/1581...\n",
      "  -> predicted: B, gt: C, correct: False\n",
      "  -> scores: A:-0.431, B:-0.375, C:-0.532, D:-0.638\n",
      "\n",
      "Scoring question 121/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.660, B:-0.723, C:-0.238, D:-2.100\n",
      "\n",
      "Scoring question 141/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-1.732, B:-0.536, C:-2.436, D:-3.250\n",
      "\n",
      "Scoring question 161/1581...\n",
      "  -> predicted: A, gt: D, correct: False\n",
      "  -> scores: A:-1.000, B:-5.328, C:-4.141, D:-5.766\n",
      "\n",
      "Scoring question 181/1581...\n",
      "  -> predicted: B, gt: C, correct: False\n",
      "  -> scores: A:-1.563, B:-0.348, C:-0.591, D:-1.117\n",
      "\n",
      "Scoring question 201/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.837, B:-1.652, C:-0.579, D:-1.003\n",
      "\n",
      "Scoring question 221/1581...\n",
      "  -> predicted: C, gt: A, correct: False\n",
      "  -> scores: A:-2.217, B:-3.359, C:-0.809, D:-2.500\n",
      "\n",
      "Scoring question 241/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.324, B:-0.524, C:-1.021, D:-3.055\n",
      "\n",
      "Scoring question 261/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.985, B:-2.684, C:-2.400, D:-2.520\n",
      "\n",
      "Scoring question 281/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-3.113, B:-3.229, C:-4.715, D:-5.723\n",
      "\n",
      "Scoring question 301/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-2.330, B:-2.434, C:-0.469, D:-2.258\n",
      "\n",
      "Scoring question 321/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-1.323, B:-1.624, C:-2.387, D:-3.199\n",
      "\n",
      "Scoring question 341/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.406, B:-1.281, C:-1.084, D:-1.308\n",
      "\n",
      "Scoring question 361/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-1.551, B:-0.843, C:-2.891, D:-3.557\n",
      "\n",
      "Scoring question 381/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.699, B:-4.141, C:-2.348, D:-0.871\n",
      "\n",
      "Scoring question 401/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-2.209, B:-2.607, C:-7.520, D:-7.738\n",
      "\n",
      "Scoring question 421/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.915, B:-0.334, C:-1.158, D:-1.543\n",
      "\n",
      "Scoring question 441/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-10.680, B:-6.617, C:-0.710, D:-7.906\n",
      "\n",
      "Scoring question 461/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.642, B:-3.197, C:-1.975, D:-1.475\n",
      "\n",
      "Scoring question 481/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-0.894, B:-1.407, C:-0.581, D:-0.314\n",
      "\n",
      "Scoring question 501/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-8.766, B:-9.578, C:-11.367, D:-3.584\n",
      "\n",
      "Scoring question 521/1581...\n",
      "  -> predicted: A, gt: D, correct: False\n",
      "  -> scores: A:-0.702, B:-2.195, C:-1.215, D:-0.776\n",
      "\n",
      "Scoring question 541/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.951, B:-0.200, C:-2.100, D:-1.909\n",
      "\n",
      "Scoring question 561/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.697, B:-3.197, C:-2.619, D:-2.811\n",
      "\n",
      "Scoring question 581/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.899, B:-0.827, C:-2.842, D:-1.999\n",
      "\n",
      "Scoring question 601/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.217, B:-1.388, C:-3.973, D:-2.176\n",
      "\n",
      "Scoring question 621/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-4.215, B:-3.307, C:-1.938, D:-0.139\n",
      "\n",
      "Scoring question 641/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-0.666, B:-2.227, C:-0.561, D:-2.133\n",
      "\n",
      "Scoring question 661/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-1.130, B:-2.398, C:-1.931, D:-2.914\n",
      "\n",
      "Scoring question 681/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-1.562, B:-0.550, C:-3.826, D:-0.816\n",
      "\n",
      "Scoring question 701/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-4.953, B:-5.348, C:-5.691, D:-1.661\n",
      "\n",
      "Scoring question 721/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.903, B:-3.373, C:-2.107, D:-3.279\n",
      "\n",
      "Scoring question 741/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.907, B:-2.957, C:-2.213, D:-0.754\n",
      "\n",
      "Scoring question 761/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.035, B:-0.792, C:-0.628, D:-1.406\n",
      "\n",
      "Scoring question 781/1581...\n",
      "  -> predicted: C, gt: B, correct: False\n",
      "  -> scores: A:-5.148, B:-2.602, C:-2.350, D:-6.102\n",
      "\n",
      "Scoring question 801/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.515, B:-1.335, C:-0.688, D:-0.284\n",
      "\n",
      "Scoring question 821/1581...\n",
      "  -> predicted: D, gt: A, correct: False\n",
      "  -> scores: A:-1.013, B:-1.086, C:-1.124, D:-0.660\n",
      "\n",
      "Scoring question 841/1581...\n",
      "  -> predicted: C, gt: D, correct: False\n",
      "  -> scores: A:-0.759, B:-1.334, C:-0.636, D:-1.213\n",
      "\n",
      "Scoring question 861/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-3.230, B:-1.925, C:-0.853, D:-0.605\n",
      "\n",
      "Scoring question 881/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-1.455, B:-11.664, C:-10.633, D:-10.180\n",
      "\n",
      "Scoring question 901/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.555, B:-0.499, C:-1.923, D:-3.176\n",
      "\n",
      "Scoring question 921/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.277, B:-0.857, C:-0.536, D:-0.316\n",
      "\n",
      "Scoring question 941/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.623, B:-2.971, C:-3.992, D:-3.688\n",
      "\n",
      "Scoring question 961/1581...\n",
      "  -> predicted: B, gt: C, correct: False\n",
      "  -> scores: A:-2.092, B:-1.508, C:-2.648, D:-2.682\n",
      "\n",
      "Scoring question 981/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.665, B:-0.842, C:-0.995, D:-1.043\n",
      "\n",
      "Scoring question 1001/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.676, B:-0.593, C:-1.088, D:-1.152\n",
      "\n",
      "Scoring question 1021/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.317, B:-0.357, C:-0.405, D:-0.552\n",
      "\n",
      "Scoring question 1041/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-2.061, B:-1.852, C:-0.744, D:-0.713\n",
      "\n",
      "Scoring question 1061/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-5.340, B:-5.559, C:-0.291, D:-6.043\n",
      "\n",
      "Scoring question 1081/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-7.719, B:-3.986, C:-1.611, D:-1.730\n",
      "\n",
      "Scoring question 1101/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.255, B:-1.048, C:-0.993, D:-0.276\n",
      "\n",
      "Scoring question 1121/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-2.604, B:-3.172, C:-7.109, D:-8.008\n",
      "\n",
      "Scoring question 1141/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-4.094, B:-3.539, C:-1.610, D:-7.438\n",
      "\n",
      "Scoring question 1161/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.448, B:-0.698, C:-1.588, D:-1.578\n",
      "\n",
      "Scoring question 1181/1581...\n",
      "  -> predicted: B, gt: C, correct: False\n",
      "  -> scores: A:-1.735, B:-1.251, C:-1.371, D:-1.253\n",
      "\n",
      "Scoring question 1201/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-4.605, B:-0.856, C:-5.027, D:-6.387\n",
      "\n",
      "Scoring question 1221/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.883, B:-2.723, C:-1.143, D:-1.059\n",
      "\n",
      "Scoring question 1241/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.509, B:-3.191, C:-0.535, D:-3.203\n",
      "\n",
      "Scoring question 1261/1581...\n",
      "  -> predicted: C, gt: D, correct: False\n",
      "  -> scores: A:-0.536, B:-1.353, C:-0.265, D:-0.540\n",
      "\n",
      "Scoring question 1281/1581...\n",
      "  -> predicted: A, gt: D, correct: False\n",
      "  -> scores: A:-0.066, B:-0.647, C:-0.342, D:-0.198\n",
      "\n",
      "Scoring question 1301/1581...\n",
      "  -> predicted: C, gt: A, correct: False\n",
      "  -> scores: A:-1.570, B:-1.281, C:-0.651, D:-1.478\n",
      "\n",
      "Scoring question 1321/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-1.203, B:-1.023, C:-1.441, D:-0.474\n",
      "\n",
      "Scoring question 1341/1581...\n",
      "  -> predicted: C, gt: D, correct: False\n",
      "  -> scores: A:-0.586, B:-0.627, C:-0.412, D:-0.723\n",
      "\n",
      "Scoring question 1361/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-1.271, B:-1.363, C:-1.496, D:-1.982\n",
      "\n",
      "Scoring question 1381/1581...\n",
      "  -> predicted: C, gt: A, correct: False\n",
      "  -> scores: A:-3.336, B:-3.195, C:-0.865, D:-4.875\n",
      "\n",
      "Scoring question 1401/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-1.171, B:-8.219, C:-9.352, D:-10.742\n",
      "\n",
      "Scoring question 1421/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-4.980, B:-3.127, C:-1.521, D:-3.314\n",
      "\n",
      "Scoring question 1441/1581...\n",
      "  -> predicted: B, gt: B, correct: True\n",
      "  -> scores: A:-0.444, B:-0.244, C:-0.684, D:-1.025\n",
      "\n",
      "Scoring question 1461/1581...\n",
      "  -> predicted: A, gt: A, correct: True\n",
      "  -> scores: A:-0.009, B:-1.116, C:-1.614, D:-1.656\n",
      "\n",
      "Scoring question 1481/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-0.427, B:-0.974, C:-2.031, D:-5.008\n",
      "\n",
      "Scoring question 1501/1581...\n",
      "  -> predicted: D, gt: D, correct: True\n",
      "  -> scores: A:-10.969, B:-9.352, C:-8.219, D:-1.220\n",
      "\n",
      "Scoring question 1521/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-3.889, B:-1.882, C:-0.304, D:-3.053\n",
      "\n",
      "Scoring question 1541/1581...\n",
      "  -> predicted: A, gt: C, correct: False\n",
      "  -> scores: A:-0.972, B:-2.609, C:-1.195, D:-3.234\n",
      "\n",
      "Scoring question 1561/1581...\n",
      "  -> predicted: C, gt: C, correct: True\n",
      "  -> scores: A:-1.016, B:-0.578, C:-0.147, D:-0.831\n",
      "\n",
      "Scoring question 1581/1581...\n",
      "  -> predicted: A, gt: B, correct: False\n",
      "  -> scores: A:-2.504, B:-2.820, C:-2.943, D:-2.910\n",
      "================================================================================\n",
      "Sample scoring-based evaluations (first 10):\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_1.json | qa_index: 0\n",
      "Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
      "Options: A:Sergio Pérez | B:Lewis Hamilton | C:Max Verstappen | D:Charles Leclerc\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
      "Options:\n",
      "A: Sergio Pérez\n",
      "B: Lewis Hamilton\n",
      "C: Max Verstappen\n",
      "D: Charles Leclerc\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -1.1729\n",
      "  B: -1.2500\n",
      "  C: -0.2500\n",
      "  D: -0.7456\n",
      "\n",
      "Ground truth option: C\n",
      "Model chosen option: C\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_1.json | qa_index: 1\n",
      "Question: What difficulties did McLaren encounter during the US Grand Prix?\n",
      "Options: A:Tough questions over its strategy | B:Pirelli tire failures | C:Driver penalties | D:Performance issues with the car\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What difficulties did McLaren encounter during the US Grand Prix?\n",
      "Options:\n",
      "A: Tough questions over its strategy\n",
      "B: Pirelli tire failures\n",
      "C: Driver penalties\n",
      "D: Performance issues with the car\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.9443\n",
      "  B: -1.5947\n",
      "  C: -3.8594\n",
      "  D: -0.6221\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: D\n",
      "Correct?: False\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_1.json | qa_index: 2\n",
      "Question: What kind of race experience did fans encounter at the US GP?\n",
      "Options: A:An exciting battle for the lead | B:Another processional race | C:Multiple safety car periods | D:Frequent position changes\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What kind of race experience did fans encounter at the US GP?\n",
      "Options:\n",
      "A: An exciting battle for the lead\n",
      "B: Another processional race\n",
      "C: Multiple safety car periods\n",
      "D: Frequent position changes\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.5942\n",
      "  B: -0.3828\n",
      "  C: -0.9390\n",
      "  D: -1.1855\n",
      "\n",
      "Ground truth option: B\n",
      "Model chosen option: B\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_10.json | qa_index: 0\n",
      "Question: What is the usual structure of a Formula 1 qualifying session?\n",
      "Options: A:Three knockout rounds: Q1, Q2, and Q3. | B:Single lap time trial for all drivers. | C:A reverse grid format. | D:Two 30-minute sessions.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What is the usual structure of a Formula 1 qualifying session?\n",
      "Options:\n",
      "A: Three knockout rounds: Q1, Q2, and Q3.\n",
      "B: Single lap time trial for all drivers.\n",
      "C: A reverse grid format.\n",
      "D: Two 30-minute sessions.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.4883\n",
      "  B: -1.6562\n",
      "  C: -4.6680\n",
      "  D: -2.2305\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: A\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_10.json | qa_index: 1\n",
      "Question: Which city traditionally hosts the United States Grand Prix?\n",
      "Options: A:New York City, New York. | B:Los Angeles, California. | C:Austin, Texas. | D:Miami, Florida.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which city traditionally hosts the United States Grand Prix?\n",
      "Options:\n",
      "A: New York City, New York.\n",
      "B: Los Angeles, California.\n",
      "C: Austin, Texas.\n",
      "D: Miami, Florida.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -1.8184\n",
      "  B: -2.1914\n",
      "  C: -1.0205\n",
      "  D: -2.8770\n",
      "\n",
      "Ground truth option: C\n",
      "Model chosen option: C\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_10.json | qa_index: 2\n",
      "Question: What is the primary objective of the qualifying session in Formula 1?\n",
      "Options: A:To practice pit stop strategies. | B:To test car performance under race conditions. | C:To set the fastest lap for championship points. | D:To determine the starting grid for the race.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What is the primary objective of the qualifying session in Formula 1?\n",
      "Options:\n",
      "A: To practice pit stop strategies.\n",
      "B: To test car performance under race conditions.\n",
      "C: To set the fastest lap for championship points.\n",
      "D: To determine the starting grid for the race.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -3.0371\n",
      "  B: -2.1445\n",
      "  C: -1.1553\n",
      "  D: -1.1445\n",
      "\n",
      "Ground truth option: D\n",
      "Model chosen option: D\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_100.json | qa_index: 0\n",
      "Question: For which team does Oscar Piastri race in Formula 1?\n",
      "Options: A:McLaren | B:Ferrari | C:Red Bull Racing | D:Alpine\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: For which team does Oscar Piastri race in Formula 1?\n",
      "Options:\n",
      "A: McLaren\n",
      "B: Ferrari\n",
      "C: Red Bull Racing\n",
      "D: Alpine\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -3.9746\n",
      "  B: -8.3906\n",
      "  C: -3.5781\n",
      "  D: -8.5781\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: C\n",
      "Correct?: False\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_100.json | qa_index: 1\n",
      "Question: Which position did Oscar Piastri relinquish during the Monza race?\n",
      "Options: A:Third place | B:Second place | C:Fourth place | D:First place\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: Which position did Oscar Piastri relinquish during the Monza race?\n",
      "Options:\n",
      "A: Third place\n",
      "B: Second place\n",
      "C: Fourth place\n",
      "D: First place\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.6611\n",
      "  B: -0.9229\n",
      "  C: -1.2002\n",
      "  D: -1.4307\n",
      "\n",
      "Ground truth option: B\n",
      "Model chosen option: A\n",
      "Correct?: False\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_100.json | qa_index: 2\n",
      "Question: What characteristic is commonly linked to successful Formula 1 champions?\n",
      "Options: A:Teamwork | B:Ruthlessness | C:Caution | D:Consistency\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What characteristic is commonly linked to successful Formula 1 champions?\n",
      "Options:\n",
      "A: Teamwork\n",
      "B: Ruthlessness\n",
      "C: Caution\n",
      "D: Consistency\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -3.2402\n",
      "  B: -0.2402\n",
      "  C: -1.5684\n",
      "  D: -1.4199\n",
      "\n",
      "Ground truth option: B\n",
      "Model chosen option: B\n",
      "Correct?: True\n",
      "--------------------------------------------------------------------------------\n",
      "File: qa_101.json | qa_index: 0\n",
      "Question: What is the importance of team orders in Formula 1?\n",
      "Options: A:Team orders are instructions given by a team to its drivers to manage their race positions or strategies, often to maximize points for the team. | B:Team orders are penalties given to drivers for unsafe driving. | C:Team orders are the regulations governing car design. | D:Team orders are rules about tire usage during a race.\n",
      "\n",
      "PROMPT USED FOR SCORING:\n",
      "\n",
      "You are a knowledgeable Formula 1 expert.\n",
      "Answer the question briefly and accurately.\n",
      "\n",
      "Question: What is the importance of team orders in Formula 1?\n",
      "Options:\n",
      "A: Team orders are instructions given by a team to its drivers to manage their race positions or strategies, often to maximize points for the team.\n",
      "B: Team orders are penalties given to drivers for unsafe driving.\n",
      "C: Team orders are the regulations governing car design.\n",
      "D: Team orders are rules about tire usage during a race.\n",
      "Answer:\n",
      "\n",
      "Scores per option (avg log-prob):\n",
      "  A: -0.2343\n",
      "  B: -1.4727\n",
      "  C: -1.6055\n",
      "  D: -1.4941\n",
      "\n",
      "Ground truth option: A\n",
      "Model chosen option: A\n",
      "Correct?: True\n",
      "================================================================================\n",
      "Total: 1581, Correct: 1094\n",
      "Accuracy: 69.20%\n",
      "Eval time (sec): 890.62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === LLaMA LoRA evaluation on big_data_dataset_evalScripts using scoring (self-contained) ===\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from peft import PeftModel\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config\n",
    "# ---------------------------------------------------------------------\n",
    "BIG_EVAL_DATASET_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"big_data_dataset_evalScripts\" / \"dataset\"\n",
    "MAX_SEQ_LEN_LOCAL = MAX_SEQ_LEN if \"MAX_SEQ_LEN\" in globals() else 2048\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Helper functions (same logic as Mistral scoring cell)\n",
    "# ---------------------------------------------------------------------\n",
    "def load_big_eval_questions_for_scoring(input_dir: Path):\n",
    "    \"\"\"\n",
    "    Load eval questions from qa_*.json.\n",
    "\n",
    "    We use:\n",
    "      - question (or rephrased_question if available)\n",
    "      - options (dict A,B,C,D)\n",
    "      - ground_truth_correct_option (letter)\n",
    "    We IGNORE the dataset 'prompt' and build our own prompt that matches training style.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    qa_files = sorted(input_dir.glob(\"qa_*.json\"))\n",
    "    print(f\"Loading evaluation QA from {len(qa_files)} files in {input_dir}\")\n",
    "    for path in qa_files:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        qa_pairs = data.get(\"qa_pairs\", [])\n",
    "        try:\n",
    "            file_index = int(path.stem.split(\"_\")[1])\n",
    "        except Exception:\n",
    "            file_index = None\n",
    "        for idx, qa in enumerate(qa_pairs):\n",
    "            question = qa.get(\"rephrased_question\", qa[\"question\"])\n",
    "            options = qa[\"options\"]\n",
    "            gt = qa[\"ground_truth_correct_option\"]\n",
    "            examples.append(\n",
    "                {\n",
    "                    \"file\": path.name,\n",
    "                    \"file_index\": file_index,\n",
    "                    \"qa_index\": idx,\n",
    "                    \"question\": question,\n",
    "                    \"options\": options,\n",
    "                    \"ground_truth\": gt,\n",
    "                }\n",
    "            )\n",
    "    print(f\"Total evaluation questions: {len(examples)}\")\n",
    "    return examples\n",
    "\n",
    "\n",
    "def build_scoring_prompt(question: str, options: dict) -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt that matches the SFT training style:\n",
    "      - brief instruction\n",
    "      - question\n",
    "      - options\n",
    "      - 'Answer:' cue\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"You are a knowledgeable Formula 1 expert.\\n\"\n",
    "        \"Answer the question briefly and accurately.\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        \"Options:\\n\"\n",
    "        f\"A: {options['A']}\\n\"\n",
    "        f\"B: {options['B']}\\n\"\n",
    "        f\"C: {options['C']}\\n\"\n",
    "        f\"D: {options['D']}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "\n",
    "def score_option_logprob(model, tokenizer, prompt: str, option_text: str, max_length: int = MAX_SEQ_LEN_LOCAL):\n",
    "    \"\"\"\n",
    "    Compute the average log-prob of the option_text tokens, conditioned on the prompt.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize prompt and answer\n",
    "    prompt_enc = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    ans_enc = tokenizer(\n",
    "        \" \" + option_text,   # leading space for better tokenization\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "    prompt_ids = prompt_enc[\"input_ids\"].to(model.device)\n",
    "    ans_ids = ans_enc[\"input_ids\"].to(model.device)\n",
    "\n",
    "    # Concatenate\n",
    "    input_ids = torch.cat([prompt_ids, ans_ids], dim=1)  # [1, L_prompt + L_ans]\n",
    "    attention_mask = torch.ones_like(input_ids, device=model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [1, seq_len, vocab_size]\n",
    "\n",
    "    L_prompt = prompt_ids.shape[1]\n",
    "    L_ans = ans_ids.shape[1]\n",
    "\n",
    "    # Log P(answer_tokens | prompt + previous answer_tokens)\n",
    "    logits_for_ans = logits[:, L_prompt - 1 : L_prompt - 1 + L_ans, :]  # [1, L_ans, V]\n",
    "    log_probs = F.log_softmax(logits_for_ans, dim=-1)  # [1, L_ans, V]\n",
    "\n",
    "    token_logprobs = log_probs.gather(-1, ans_ids.unsqueeze(-1)).squeeze(-1)  # [1, L_ans]\n",
    "    avg_logprob = token_logprobs.mean().item()\n",
    "    return avg_logprob\n",
    "\n",
    "\n",
    "def run_big_mc_eval_scoring(model, tokenizer, eval_examples, sample_print=10):\n",
    "    \"\"\"\n",
    "    Multiple-choice eval using log-prob scoring, NOT generation.\n",
    "\n",
    "    For each question:\n",
    "      - Build training-style prompt with question + options\n",
    "      - For each (A,B,C,D), compute log-prob(score) of the option text\n",
    "      - Pick option with highest score\n",
    "\n",
    "    Prints lines like:\n",
    "    Scoring question 1/1581...\n",
    "      -> predicted: C, gt: C, correct: True\n",
    "      -> scores: A:-4.123, B:-3.985, C:-2.110, D:-3.450\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total = len(eval_examples)\n",
    "    correct = 0\n",
    "    details = []\n",
    "\n",
    "    # Ensure pad_token_id is set\n",
    "    if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    if model.config.pad_token_id is None and model.config.eos_token_id is not None:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for i, ex in enumerate(eval_examples):\n",
    "        q = ex[\"question\"]\n",
    "        options = ex[\"options\"]\n",
    "        gt = ex[\"ground_truth\"]\n",
    "\n",
    "        prompt = build_scoring_prompt(q, options)\n",
    "\n",
    "        # Compute scores for each option\n",
    "        scores = {}\n",
    "        for letter in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            opt_text = options[letter]\n",
    "            score = score_option_logprob(model, tokenizer, prompt, opt_text)\n",
    "            scores[letter] = score\n",
    "\n",
    "        # Pick best letter\n",
    "        best_letter = max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "        is_corr = best_letter == gt\n",
    "        if is_corr:\n",
    "            correct += 1\n",
    "\n",
    "        # Progress logging (every 20 questions)\n",
    "        if i % 20 == 0:\n",
    "            print(f\"\\nScoring question {i+1}/{total}...\")\n",
    "            print(f\"  -> predicted: {best_letter}, gt: {gt}, correct: {is_corr}\")\n",
    "            score_str = \", \".join([f\"{L}:{scores[L]:.3f}\" for L in [\"A\", \"B\", \"C\", \"D\"]])\n",
    "            print(f\"  -> scores: {score_str}\")\n",
    "\n",
    "        details.append(\n",
    "            {\n",
    "                \"file\": ex[\"file\"],\n",
    "                \"qa_index\": ex[\"qa_index\"],\n",
    "                \"question\": q,\n",
    "                \"options\": options,\n",
    "                \"ground_truth\": gt,\n",
    "                \"model_option\": best_letter,\n",
    "                \"is_correct\": is_corr,\n",
    "                \"scores\": scores,\n",
    "                \"prompt_used\": prompt,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    eval_time = time.perf_counter() - t0\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    # Print first N detailed samples\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Sample scoring-based evaluations (first {sample_print}):\")\n",
    "    for sample in details[: min(sample_print, len(details))]:\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"File: {sample['file']} | qa_index: {sample['qa_index']}\")\n",
    "        print(\"Question:\", sample[\"question\"])\n",
    "        opts = sample[\"options\"]\n",
    "        print(f\"Options: A:{opts['A']} | B:{opts['B']} | C:{opts['C']} | D:{opts['D']}\")\n",
    "        print(\"\\nPROMPT USED FOR SCORING:\\n\")\n",
    "        print(sample[\"prompt_used\"])\n",
    "        print(\"\\nScores per option (avg log-prob):\")\n",
    "        for letter, s in sample[\"scores\"].items():\n",
    "            print(f\"  {letter}: {s:.4f}\")\n",
    "        print(\"\\nGround truth option:\", sample[\"ground_truth\"])\n",
    "        print(\"Model chosen option:\", sample[\"model_option\"])\n",
    "        print(\"Correct?:\", sample[\"is_correct\"])\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total: {total}, Correct: {correct}\")\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"Eval time (sec): {round(eval_time, 2)}\")\n",
    "\n",
    "    stats = {\n",
    "        \"total\": total,\n",
    "        \"parsed\": total,\n",
    "        \"skipped\": 0,\n",
    "        \"correct\": correct,\n",
    "    }\n",
    "    return acc, eval_time, details, stats\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# LLaMA LoRA eval using the scoring approach above\n",
    "# ---------------------------------------------------------------------\n",
    "llama_cfg = next(m for m in MODELS if m[\"name\"] == \"llama-3.1-8b-instruct\")\n",
    "LLAMA_ID = llama_cfg[\"id\"]\n",
    "LLAMA_NAME = llama_cfg[\"name\"]\n",
    "\n",
    "llama_eval_tokenizer = create_tokenizer(LLAMA_ID)\n",
    "llama_lora_dir = RESULTS_DIR / \"llama_lora\"\n",
    "\n",
    "big_eval_examples_llama = load_big_eval_questions_for_scoring(BIG_EVAL_DATASET_DIR)\n",
    "\n",
    "print(\"\\n=== First 5 eval examples (question + options + ground truth) for LLaMA ===\")\n",
    "for i in range(min(5, len(big_eval_examples_llama))):\n",
    "    ex = big_eval_examples_llama[i]\n",
    "    print(f\"\\n--- Eval example {i} from {ex['file']} (qa_index={ex['qa_index']}) ---\")\n",
    "    print(\"Question:\", ex[\"question\"])\n",
    "    print(\"Options:\", ex[\"options\"])\n",
    "    print(\"Ground truth:\", ex[\"ground_truth\"])\n",
    "\n",
    "llama_eval_base = create_base_model(LLAMA_ID)\n",
    "llama_eval_model = PeftModel.from_pretrained(\n",
    "    llama_eval_base,\n",
    "    str(llama_lora_dir),\n",
    ")\n",
    "llama_eval_model.eval()\n",
    "\n",
    "llama_big_acc, llama_big_eval_time, llama_big_details, llama_big_stats = run_big_mc_eval_scoring(\n",
    "    llama_eval_model,\n",
    "    llama_eval_tokenizer,\n",
    "    big_eval_examples_llama,\n",
    "    sample_print=10,\n",
    ")\n",
    "\n",
    "llama_big_results = {\n",
    "    \"accuracy\": llama_big_acc,\n",
    "    \"eval_time_sec\": llama_big_eval_time,\n",
    "    \"stats\": llama_big_stats,\n",
    "    \"details\": llama_big_details,\n",
    "    \"dataset_dir\": str(BIG_EVAL_DATASET_DIR),\n",
    "    \"machine_info\": MACHINE_INFO,\n",
    "}\n",
    "\n",
    "EVAL_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(EVAL_RESULTS_DIR / \"llama_bigdata_eval_results_scoring.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(llama_big_results, f, indent=2)\n",
    "\n",
    "try:\n",
    "    with open(llama_lora_dir / \"llama_train_meta.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        llama_train_meta_loaded = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    llama_train_meta_loaded = {\"train_time_sec\": None, \"final_train_loss\": None}\n",
    "\n",
    "summary_rows.append(\n",
    "    {\n",
    "        \"model_name\": LLAMA_NAME,\n",
    "        \"train_time_sec\": llama_train_meta_loaded.get(\"train_time_sec\"),\n",
    "        \"final_train_loss\": llama_train_meta_loaded.get(\"final_train_loss\"),\n",
    "        \"final_mc_accuracy\": llama_big_acc,\n",
    "        \"final_eval_time_sec\": llama_big_eval_time,\n",
    "        \"best_epoch_mc_accuracy\": None,\n",
    "        \"device_type\": MACHINE_INFO.get(\"device_type\"),\n",
    "        \"gpu_name\": MACHINE_INFO.get(\"gpu_name\"),\n",
    "        \"gpu_memory_gb\": MACHINE_INFO.get(\"gpu_memory_gb\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "del llama_eval_model\n",
    "del llama_eval_base\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fd88d",
   "metadata": {},
   "source": [
    "## Cell 10 – Aggregate results into tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8796b2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-level results saved to: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\results\\LoRA Results\\Outputs\\epoch_results.csv\n",
      "Summary results saved to: D:\\Projects\\CS6220\\Final Project\\f1-conversational-ai-main\\results\\LoRA Results\\Outputs\\summary_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_time_sec</th>\n",
       "      <th>final_train_loss</th>\n",
       "      <th>final_mc_accuracy</th>\n",
       "      <th>final_eval_time_sec</th>\n",
       "      <th>device_type</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral-7b</td>\n",
       "      <td>4690.776854</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.722960</td>\n",
       "      <td>936.282031</td>\n",
       "      <td>cuda</td>\n",
       "      <td>NVIDIA GeForce RTX 4090 Laptop GPU</td>\n",
       "      <td>15.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>4927.683352</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.691967</td>\n",
       "      <td>890.619606</td>\n",
       "      <td>cuda</td>\n",
       "      <td>NVIDIA GeForce RTX 4090 Laptop GPU</td>\n",
       "      <td>15.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name  train_time_sec  final_train_loss  final_mc_accuracy  \\\n",
       "0             mistral-7b     4690.776854            0.0271           0.722960   \n",
       "1  llama-3.1-8b-instruct     4927.683352            0.0327           0.691967   \n",
       "\n",
       "   final_eval_time_sec device_type                            gpu_name  \\\n",
       "0           936.282031        cuda  NVIDIA GeForce RTX 4090 Laptop GPU   \n",
       "1           890.619606        cuda  NVIDIA GeForce RTX 4090 Laptop GPU   \n",
       "\n",
       "   gpu_memory_gb  \n",
       "0          15.99  \n",
       "1          15.99  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Rebuild epoch_results_df and summary_df for BOTH Mistral and LLaMA from saved files ===\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure RESULTS_DIR and EVAL_RESULTS_DIR are defined in this kernel.\n",
    "# If not, uncomment and set them:\n",
    "# RESULTS_DIR = Path(\"D:/Projects/CS6220/Final Project/f1-conversational-ai-main/results\")\n",
    "# EVAL_RESULTS_DIR = RESULTS_DIR / \"eval\"\n",
    "\n",
    "models_cfg = [\n",
    "    {\n",
    "        \"name\": \"mistral-7b\",\n",
    "        \"short\": \"mistral\",\n",
    "        \"dir\": \"mistral_lora\",\n",
    "        \"train_meta_file\": \"mistral_train_meta.json\",\n",
    "        \"train_log_file\": \"mistral_train_log.json\",\n",
    "        \"eval_file\": \"mistral_bigdata_eval_results_scoring.json\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"llama-3.1-8b-instruct\",\n",
    "        \"short\": \"llama\",\n",
    "        \"dir\": \"llama_lora\",\n",
    "        \"train_meta_file\": \"llama_train_meta.json\",\n",
    "        \"train_log_file\": \"llama_train_log.json\",\n",
    "        \"eval_file\": \"llama_bigdata_eval_results_scoring.json\",\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_rows = []\n",
    "epoch_rows = []\n",
    "\n",
    "for cfg in models_cfg:\n",
    "    model_results_dir = RESULTS_DIR / cfg[\"dir\"]\n",
    "\n",
    "    # ---------------- Load training meta ----------------\n",
    "    try:\n",
    "        with open(model_results_dir / cfg[\"train_meta_file\"], \"r\", encoding=\"utf-8\") as f:\n",
    "            train_meta = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARN] Training meta not found for {cfg['name']}\")\n",
    "        train_meta = {}\n",
    "\n",
    "    # ---------------- Load eval (scoring) results ----------------\n",
    "    try:\n",
    "        with open(EVAL_RESULTS_DIR / cfg[\"eval_file\"], \"r\", encoding=\"utf-8\") as f:\n",
    "            eval_results = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARN] Eval results not found for {cfg['name']}\")\n",
    "        eval_results = {}\n",
    "\n",
    "    # ---------------- Append summary row ----------------\n",
    "    summary_rows.append(\n",
    "        {\n",
    "            \"model_name\": cfg[\"name\"],\n",
    "            \"train_time_sec\": train_meta.get(\"train_time_sec\"),\n",
    "            \"final_train_loss\": train_meta.get(\"final_train_loss\"),\n",
    "            \"final_mc_accuracy\": eval_results.get(\"accuracy\"),\n",
    "            \"final_eval_time_sec\": eval_results.get(\"eval_time_sec\"),\n",
    "            # These may or may not be in train_meta; fall back to MACHINE_INFO if present:\n",
    "            \"device_type\": (train_meta.get(\"machine_info\", {}) or globals().get(\"MACHINE_INFO\", {})).get(\"device_type\"),\n",
    "            \"gpu_name\": (train_meta.get(\"machine_info\", {}) or globals().get(\"MACHINE_INFO\", {})).get(\"gpu_name\"),\n",
    "            \"gpu_memory_gb\": (train_meta.get(\"machine_info\", {}) or globals().get(\"MACHINE_INFO\", {})).get(\"gpu_memory_gb\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ---------------- Load per-step / per-epoch logs ----------------\n",
    "    try:\n",
    "        with open(model_results_dir / cfg[\"train_log_file\"], \"r\", encoding=\"utf-8\") as f:\n",
    "            log_history = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARN] Train log not found for {cfg['name']}\")\n",
    "        log_history = []\n",
    "\n",
    "    for entry in log_history:\n",
    "        # HuggingFace Trainer logs loss for training steps like:\n",
    "        # {\"loss\": ..., \"learning_rate\": ..., \"epoch\": ..., \"step\": ...}\n",
    "        if \"loss\" in entry:\n",
    "            epoch_rows.append(\n",
    "                {\n",
    "                    \"model_name\": cfg[\"name\"],\n",
    "                    \"step\": entry.get(\"step\"),\n",
    "                    \"epoch\": entry.get(\"epoch\"),\n",
    "                    \"loss\": entry.get(\"loss\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "# ---------------- Build DataFrames and save ----------------\n",
    "epoch_results_df = pd.DataFrame(epoch_rows)\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "epoch_results_path = RESULTS_DIR / \"epoch_results.csv\"\n",
    "summary_results_path = RESULTS_DIR / \"summary_results.csv\"\n",
    "\n",
    "epoch_results_df.to_csv(epoch_results_path, index=False)\n",
    "summary_df.to_csv(summary_results_path, index=False)\n",
    "\n",
    "print(\"Epoch-level results saved to:\", epoch_results_path)\n",
    "print(\"Summary results saved to:\", summary_results_path)\n",
    "\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334e5e7",
   "metadata": {},
   "source": [
    "## Cell 11 – Charts for accuracy and time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c42bac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Line plot: train loss per epoch for each model\n",
    "plt.figure()\n",
    "\n",
    "if \"epoch\" in epoch_results_df.columns and \"loss\" in epoch_results_df.columns:\n",
    "    for model_name, group in epoch_results_df.groupby(\"model_name\"):\n",
    "        # average loss per epoch for smoother curve\n",
    "        avg_per_epoch = (\n",
    "            group.dropna(subset=[\"epoch\", \"loss\"])\n",
    "                 .groupby(\"epoch\", as_index=False)[\"loss\"]\n",
    "                 .mean()\n",
    "                 .sort_values(\"epoch\")\n",
    "        )\n",
    "        if len(avg_per_epoch) == 0:\n",
    "            continue\n",
    "        plt.plot(\n",
    "            avg_per_epoch[\"epoch\"],\n",
    "            avg_per_epoch[\"loss\"],\n",
    "            marker=\"o\",\n",
    "            label=model_name,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Train loss\")\n",
    "    plt.title(\"Train loss per epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"epoch_results_df does not have 'epoch' and 'loss' columns; skipping loss-per-epoch plot.\")\n",
    "\n",
    "# 2) Bar: training time per model\n",
    "plt.figure()\n",
    "train_time_series = summary_df[\"train_time_sec\"].fillna(0)\n",
    "plt.bar(summary_df[\"model_name\"], train_time_series)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Training time (sec)\")\n",
    "plt.title(\"Training time per model\")\n",
    "plt.show()\n",
    "\n",
    "# 3) Bar: final MC accuracy per model\n",
    "plt.figure()\n",
    "final_acc_series = summary_df[\"final_mc_accuracy\"].fillna(0)\n",
    "plt.bar(summary_df[\"model_name\"], final_acc_series)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Final MC accuracy\")\n",
    "plt.title(\"Final MC accuracy per model\")\n",
    "plt.show()\n",
    "\n",
    "# 4) Bar: final evaluation time per model\n",
    "plt.figure()\n",
    "final_eval_time_series = summary_df[\"final_eval_time_sec\"].fillna(0)\n",
    "plt.bar(summary_df[\"model_name\"], final_eval_time_series)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Final evaluation time (sec)\")\n",
    "plt.title(\"Final MC evaluation time per model\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (f1-conversational-ai-main)",
   "language": "python",
   "name": "f1-conversational-ai-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
