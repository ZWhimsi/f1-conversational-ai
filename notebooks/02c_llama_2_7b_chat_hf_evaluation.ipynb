{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgHMIWwIrcfs"
      },
      "source": [
        "# Llama 2 7B Instruct F1 QA Evaluation\n",
        "\n",
        "This notebook evaluates Llama 2 7B Instruct on the F1 QA dataset with multiple choice questions.\n",
        "\n",
        "It loads 500 JSON files (1500 QA pairs total), formats them as multiple choice questions, and evaluates the model's accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AgpwsHaXrcfu"
      },
      "outputs": [],
      "source": [
        "# Install required packages with latest versions\n",
        "%pip install transformers>=4.40.0 torch>=2.0.0 accelerate>=0.20.0 huggingface_hub>=0.20.0 tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTJnrz34rcfu",
        "outputId": "57209cd1-d143-41f6-fc11-12d6da4a7193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google Drive mounted successfully!\n",
            "âœ… Hugging Face authenticated via environment variable\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"âœ… Google Drive mounted successfully!\")\n",
        "\n",
        "# Hugging Face Authentication for Llama models\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "# Check if HF token is available\n",
        "if userdata.get('HF_TOKEN'):\n",
        "    login(token=userdata.get('HF_TOKEN'))\n",
        "    print(\"âœ… Hugging Face authenticated via environment variable\")\n",
        "else:\n",
        "    print(\"âš ï¸  Hugging Face token not found in environment variables\")\n",
        "    print(\"   Please set your HF_TOKEN in Colab secrets or run:\")\n",
        "    print(\"   from huggingface_hub import login\")\n",
        "    print(\"   login()  # This will prompt for your token\")\n",
        "    print(\"   Or set HF_TOKEN in Colab secrets (recommended)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TNl1ytTgrcfv"
      },
      "outputs": [],
      "source": [
        "# Import utilities with latest transformers syntax\n",
        "import sys\n",
        "sys.path.append('/content')\n",
        "from f1_qa_utils import load_qa_dataset, format_multiple_choice, extract_answer_letter, extract_justification, parse_json_response\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from pathlib import Path\n",
        "import time\n",
        "import gc\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33bIvha9rcfv"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Set paths and model to evaluate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77nr2IzPrcfv",
        "outputId": "8d96f562-bb15-481b-f196-66e25fd00281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Configuration loaded:\n",
            "   Model: Llama-2-7b-chat-hf\n",
            "   Model ID: meta-llama/Llama-2-7b-chat-hf\n",
            "   Dataset: /content/drive/MyDrive/Data_Collection_Code/dataset\n",
            "   Results: /content/drive/MyDrive/CS6220_Project/results\n",
            "   ðŸ“ Note: Model will be loaded directly from Hugging Face Hub\n",
            "   âš ï¸  Note: Llama models require Hugging Face authentication\n"
          ]
        }
      ],
      "source": [
        "# Configuration for Llama 2 7B Instruct\n",
        "MODEL_ID = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "MODEL_NAME = \"Llama-2-7b-chat-hf\"\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Data_Collection_Code/dataset\"\n",
        "RESULTS_PATH = \"/content/drive/MyDrive/CS6220_Project/results\"\n",
        "\n",
        "# Create results directory if needed\n",
        "Path(RESULTS_PATH).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"âœ… Configuration loaded:\")\n",
        "print(f\"   Model: {MODEL_NAME}\")\n",
        "print(f\"   Model ID: {MODEL_ID}\")\n",
        "print(f\"   Dataset: {DATASET_PATH}\")\n",
        "print(f\"   Results: {RESULTS_PATH}\")\n",
        "print(f\"   ðŸ“ Note: Model will be loaded directly from Hugging Face Hub\")\n",
        "print(f\"   âš ï¸  Note: Llama models require Hugging Face authentication\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4O0Hx8Zrcfw"
      },
      "source": [
        "## Load QA Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osodVak7rcfx",
        "outputId": "8c00735f-6d26-410f-aa93-4f2ca629c338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 1500 QA pairs from /content/drive/MyDrive/Data_Collection_Code/dataset\n",
            "ðŸ“Š Dataset Statistics:\n",
            "   Total QA pairs: 1500\n",
            "   Expected: 1500 (500 files Ã— 3 QA pairs each)\n",
            "\n",
            "ðŸ“ Example QA pair:\n",
            "   Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
            "   Correct Answer: C\n",
            "   Options: {'A': 'Sergio PÃ©rez', 'B': 'Lewis Hamilton', 'C': 'Max Verstappen', 'D': 'Charles Leclerc'}\n",
            "\n",
            "ðŸ“ Example formatted prompt:\n",
            "   Prompt preview: You are an AI assistant specializing in Formula 1.\n",
            "\n",
            "    Question: Which driver secured a double victory at the US Grand Prix held in Austin?\n",
            "\n",
            "    A) Sergio PÃ©rez\n",
            "    B) Lewis Hamilton\n",
            "    C) Max Verst...\n"
          ]
        }
      ],
      "source": [
        "# Load all QA pairs\n",
        "qa_dataset = load_qa_dataset(DATASET_PATH)\n",
        "\n",
        "print(f\"ðŸ“Š Dataset Statistics:\")\n",
        "print(f\"   Total QA pairs: {len(qa_dataset)}\")\n",
        "print(f\"   Expected: 1500 (500 files Ã— 3 QA pairs each)\")\n",
        "\n",
        "# Show example\n",
        "if qa_dataset:\n",
        "    print(f\"\\nðŸ“ Example QA pair:\")\n",
        "    example = qa_dataset[0]\n",
        "    print(f\"   Question: {example['rephrased_question']}\")\n",
        "    print(f\"   Correct Answer: {example['ground_truth_correct_option']}\")\n",
        "    print(f\"   Options: {example['options']}\")\n",
        "\n",
        "    # Show example of formatted prompt\n",
        "    print(f\"\\nðŸ“ Example formatted prompt:\")\n",
        "    prompt = format_multiple_choice(\n",
        "        example['rephrased_question'],\n",
        "        example['options']\n",
        "    )\n",
        "    print(f\"   Prompt preview: {prompt[:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQJQd5BJrcfy"
      },
      "source": [
        "## Model Evaluator Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rvs7FV2ercf0"
      },
      "outputs": [],
      "source": [
        "class F1QAEvaluator:\n",
        "    \"\"\"Evaluator for F1 QA models with latest transformers syntax.\"\"\"\n",
        "\n",
        "    def __init__(self, model_id: str, model_name: str):\n",
        "        self.model_id = model_id\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load model and tokenizer directly from Hugging Face Hub.\"\"\"\n",
        "        try:\n",
        "            print(f\"ðŸ”„ Loading {self.model_name} from {self.model_id}...\")\n",
        "\n",
        "            # Check if we need to authenticate for Llama models\n",
        "            if \"llama\" in self.model_id.lower() or \"meta-llama\" in self.model_id:\n",
        "                try:\n",
        "                    from huggingface_hub import login\n",
        "                    # Try to login if not already authenticated\n",
        "                    login()\n",
        "                    print(\"âœ… Hugging Face authentication successful\")\n",
        "                except Exception as auth_error:\n",
        "                    print(f\"âŒ Authentication failed: {auth_error}\")\n",
        "                    print(\"   Please run: from huggingface_hub import login; login()\")\n",
        "                    return False\n",
        "\n",
        "            # Load tokenizer with latest syntax\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.model_id,\n",
        "                trust_remote_code=True,\n",
        "                use_fast=True\n",
        "            )\n",
        "\n",
        "            # Set padding token if not set\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            # Load model with latest syntax and optimizations\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_id,\n",
        "                trust_remote_code=True,\n",
        "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "                device_map=\"auto\" if self.device == \"cuda\" else None,\n",
        "                attn_implementation=\"eager\"  # Use eager attention for better compatibility\n",
        "            )\n",
        "\n",
        "            # Move to device if not using device_map\n",
        "            if self.device == \"cuda\" and not hasattr(self.model, 'hf_device_map'):\n",
        "                self.model = self.model.to(self.device)\n",
        "\n",
        "            print(f\"âœ… {self.model_name} loaded successfully on {self.device}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to load {self.model_name}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def generate_response(self, prompt: str, max_new_tokens: int = 5) -> str:\n",
        "        \"\"\"Generate response using latest transformers generation syntax.\"\"\"\n",
        "        try:\n",
        "            # Tokenize with proper attention mask handling\n",
        "            inputs = self.tokenizer(\n",
        "                prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=512,\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "            if self.device == \"cuda\":\n",
        "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            # Create generation config with latest syntax\n",
        "            generation_config = GenerationConfig(\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=True,\n",
        "                temperature=0.3,\n",
        "                top_p=0.9,\n",
        "                pad_token_id=self.tokenizer.eos_token_id,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                use_cache=True,  # Llama works well with cache enabled\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=False\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    inputs[\"input_ids\"],\n",
        "                    attention_mask=inputs[\"attention_mask\"],\n",
        "                    generation_config=generation_config\n",
        "                )\n",
        "\n",
        "            # Check if outputs is valid\n",
        "            if outputs is None or not hasattr(outputs, 'sequences'):\n",
        "                return \"\"\n",
        "\n",
        "            # Decode only the new tokens (excluding the input prompt)\n",
        "            input_length = inputs[\"input_ids\"].shape[1]\n",
        "            if len(outputs.sequences[0]) > input_length:\n",
        "                new_tokens = outputs.sequences[0][input_length:]\n",
        "                response = self.tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "            else:\n",
        "                # If no new tokens generated, return empty string\n",
        "                response = \"\"\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error generating response: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def evaluate_dataset(self, qa_dataset: List[Dict]) -> Dict:\n",
        "        \"\"\"Evaluate model on entire dataset.\"\"\"\n",
        "        results = {\n",
        "            'model_name': self.model_name,\n",
        "            'total_questions': len(qa_dataset),\n",
        "            'correct': 0,\n",
        "            'incorrect': 0,\n",
        "            'invalid': 0,\n",
        "            'accuracy': 0.0,\n",
        "            'details': []\n",
        "        }\n",
        "\n",
        "        print(f\"\\nðŸš€ Evaluating {self.model_name} on {len(qa_dataset)} questions...\")\n",
        "\n",
        "        for i, qa_pair in enumerate(tqdm(qa_dataset, desc=f\"Evaluating {self.model_name}\")):\n",
        "            question = qa_pair['rephrased_question']\n",
        "            correct_letter = qa_pair['ground_truth_correct_option']\n",
        "            options = qa_pair['options']\n",
        "\n",
        "            # Format as multiple choice\n",
        "            prompt = format_multiple_choice(question, options)\n",
        "\n",
        "            # Generate response\n",
        "            response = self.generate_response(prompt)\n",
        "\n",
        "            print(f\"RESPONSE IS: {response}\")\n",
        "\n",
        "\n",
        "            # Extract answer letter and justification\n",
        "            predicted_letter = extract_answer_letter(response)\n",
        "            #justification = extract_justification(response)\n",
        "\n",
        "            print(f\"EXTRACTED ANSWER: {predicted_letter}\")\n",
        "\n",
        "            # Check correctness\n",
        "            is_correct = predicted_letter == correct_letter\n",
        "            is_invalid = predicted_letter == \"\"\n",
        "\n",
        "            if is_correct:\n",
        "                results['correct'] += 1\n",
        "            elif is_invalid:\n",
        "                results['invalid'] += 1\n",
        "            else:\n",
        "                results['incorrect'] += 1\n",
        "\n",
        "            # Store details\n",
        "            results['details'].append({\n",
        "                'question': question,\n",
        "                'correct_letter': correct_letter,\n",
        "                'predicted_letter': predicted_letter,\n",
        "                'is_correct': is_correct,\n",
        "                'is_invalid': is_invalid,\n",
        "                'response': response,\n",
        "                #'justification': justification,\n",
        "                'prompt': prompt\n",
        "            })\n",
        "\n",
        "        # Calculate accuracy\n",
        "        valid_responses = results['total_questions'] - results['invalid']\n",
        "        if valid_responses > 0:\n",
        "            results['accuracy'] = results['correct'] / valid_responses\n",
        "\n",
        "        print(f\"âœ… {self.model_name} evaluation complete:\")\n",
        "        print(f\"   Correct: {results['correct']}\")\n",
        "        print(f\"   Incorrect: {results['incorrect']}\")\n",
        "        print(f\"   Invalid: {results['invalid']}\")\n",
        "        print(f\"   Accuracy: {results['accuracy']:.2%}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Clear model from memory.\"\"\"\n",
        "        del self.model\n",
        "        del self.tokenizer\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        print(f\"ðŸ§¹ Cleaned up {self.model_name} from memory\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbooSuC4rcf0"
      },
      "source": [
        "## Run Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "75e5e09f80a84172ac13ff4aef43f508",
            "c2a1e81138284c94993f71e09ac05a8a",
            "47bce37be40840f2b50615c500c77e6e",
            "7377db17a35c4fc8ab1f5c6d77bccdc0",
            "1b30fced8e4742c984e04f9d09214bcd",
            "4d70279f068c4045b594e6e94505c0ae",
            "f13461f5300e4a4a8cbce72684822d46",
            "b870df3efa0e48419e58e9ce4ee21d1e",
            "c18257606dfb4dc38ecb23a4a93bf1b6",
            "7e3e1f604aff4fa99464288d5dcdc101",
            "1cec25c78bfa43f3a92a5b162ea80346",
            "28f71162541a4075a206e890d87cba63",
            "d724032da63d4738844c3a5ccc6b11f7",
            "6cee68cc4e1a49fe9420862c99317ed5",
            "e4dc3a0b43b94f76a37a7b714ef09bc0",
            "a23ae6595bd44794a361462b33c0c4ee",
            "ebacc257241f45c9b0128a768ce733fb",
            "b8a959107c364a97b9f45bbea3073300",
            "a07b34dc53924d71a3c47022278a0548",
            "7e66adf4a2364f8eaccc8ebf916cb4e6",
            "848b4ef825a94f4f8c9f0bdaf9f5c53d",
            "1d93a204329a436b86cfe45ef3eee8dd",
            "5c23507f0cf244f78eb1a02abc209111",
            "1a1ae8939500423c85d7ddedd7b3d0ad",
            "8896cfff778845abac91ad4898db6f19",
            "10f5eb7ace6c4acb961c0d2a95616e72",
            "f4016791902d4033befb26184250e59f",
            "1375d74e242847489157cd802053187a",
            "f15f1d6f9ebc4a0eb620b63a42c3194b",
            "e3a98b0574d94af08fa0f3fb565cdd24",
            "6eb4d57f0b7541b8a685ec9f5ee753e5",
            "9efbe43843974dee9b5ae86746cd9a6b",
            "b532705318054a6e8e2c5197b22a3361",
            "04205715937840649eeffd59129725da",
            "192bd8a3142c419489f21c550e681b5e",
            "8f4caa1997754d53b6d52718fbd1b22b",
            "6754f3b661744fc1b7a73f58fa7225e7",
            "988843e9f1204942b7515f4df84ff312",
            "9f845ed39ba3451a8c3263e1d9b5aa5e",
            "4deaf6c5a4bb47dd88467d56130de371",
            "e4afb475802d483a977f69b61c71480a",
            "c6780ecca3f144bbbcda431fb26b1a53",
            "532e7d6b7f304d05a99ccb867519173a",
            "e38870016b31412abbec81556c37ceae",
            "90af86e4a85542178997881c90e37ec7",
            "461fb5bd1dbb40929cf4fc0980bdfc67",
            "5b90e14f65fb4e5fa8c5710c2239a6ff",
            "2d3b0845cf9f4530a9caf88f938bd700",
            "413612c126884fe791085594e59f3190",
            "57a81b19b6eb4adebee8cbcd9788639a",
            "b5b6d0c673f04f8ba63d68472c414dbb",
            "6265ffeb3b174ec49be1520b5dce7996",
            "995f4c0551e94e2dbc266a6ac4644abd",
            "e13a767a5e72467491fdde294f169c0d",
            "7d357267cf2249fc9099d013df871426",
            "08a0fabba50e442091f018a6b42288a7",
            "90a71b694ed94ccd9f5a3f86036b61e0",
            "72bd490b40ff438986650ff4b1b98b8a",
            "7399c7a70c5149c0b9606f3c5bcafcf8",
            "8a2c6500b16541c985388364d0bc8bb9",
            "1e913351b1f44724a226cdd6391e04bf",
            "ec47ae0ce8bd428b89f5a04f7b12fba8",
            "6ebf801d6d9b459ab5cc3a7de24f7366",
            "67c6d4cde3394a09ae30f81ff8b7daae",
            "0437bdcb8a584d8b9ce7389b5422ea3e",
            "be8ad2f57897450882c71bf4f23fb1c1",
            "1ba14ddffb8240008f199be1cf2fb8f3",
            "3c3498238a52443bbdbf25564931a027",
            "4973e1e4d6804a289fa7cd824f869cb2",
            "0f32d786068944d38cc4f61763086836",
            "390afcab394b40e7a359a2a77abe9ce1",
            "ba6f280cfb3548b890478ed71f067a75",
            "c9a168e3461b4a7cb282a0be53986e0d",
            "2823eb24cc2b47a29961b9daef98d76d",
            "5b57a31d37724b8ea6824068703e7ab5",
            "6fd043cb03294eca8b7e76616839ce65",
            "079bbff5c34a4519a726d37b0f370d26",
            "9e609d4b3b3142a6b89119c7d80e4754",
            "3aa333e040ce4a65a210e8ad2103b9b1",
            "68fcd9d825294a77ad947fc24162b9fb",
            "ede14ffce4a44406ae4f15cc5cb5af83",
            "8cdc677c8aca4bcc941739be2cfabe51",
            "874c1ed24b07415680cae84eea8b2a86",
            "eb1ace01a3bc41d8ba55f6ced4466023",
            "b9144af862af40c698b75865f12900e5",
            "68753538c1474a27a0a81102370b64d9",
            "759b898968a642df944e1363923a3078",
            "7748ad1a74324bfd94e6ec3132e18bfb",
            "ce0e11c371a3410789fa31a4e4f1e00d",
            "6aaee92760704311a4cfe9ba116a4783",
            "8033b50e2eec40c79c7f8a57b5ac4a97",
            "512cc7113b5b4173bdd7c1724ec25be2",
            "e64812ec9cd04ed793b90e7fef189b80",
            "0650154b070b4201b203672f6b50e848",
            "821342a171094ee28dfce5b0c49cee07",
            "483c680a8a824ca8b08b27a7e21c1a24",
            "7c93e22926164067ac0975abca6117f1",
            "0934f14ec1ae4f59a91768c43c8997bb",
            "cd85514446a94d039c2697344609905b",
            "6662dd5eab29415f8ec867c79eaa8583",
            "c27e15e91f904ddba7c869064ade47c5",
            "b41b2a7cc589408cbc805bb100b51eba",
            "bed208e1ca894551b5dc74feeee2c714",
            "82ba2f21b9154d809e2f5b815927f468",
            "377ea8a1c41c4ad3a825113a7bbabac7",
            "d1e9f098551d40fd961de9aef1e49fe0",
            "a1f15846823d49b3a2cc19a131981644",
            "c9202d8efd304b818c7df746ad57121f",
            "91d6d152b9234be88720b932e1c68706",
            "5e52a68e9c594e809942c86a2de1363d",
            "91986301efef4a13934d039b54d76097",
            "ee76d4371b1243aaa3ee35e743220d7e",
            "e7ed52d282c6489fa380fea729813165",
            "2f31740d77de4b20b6629269d3b32249",
            "35c12fa47e3a4e7d9082f50e6c043a3f",
            "1419ec50bd4e4f2dae5c7c583458e50f",
            "e1f4a454bfb04045b3a4b6c4ae5ab9b7",
            "af37fe3cb69b47149ac971271ca1c380",
            "4e82051d61884fcf8dff70c82a5a9a22",
            "5b639067deae4ee4b6ffd4454ad10959",
            "8bfe53aa8a834855a19cb1f068f004d2",
            "f25addb2b237476e9f9c389df57dc36b",
            "9a9b172246ed401789454a97a2de9832",
            "25567dd827a142728ec2f10e67e440bd",
            "4d2062de0e184a3bbb53c55162484c64",
            "1381642db5df453e8afc11a45ec53fd5",
            "d5abd9b3b33a4f7e85145689d77f061e",
            "ee1706b143064101bc04541528e683f6",
            "5ee7b5447d1b422bbb9984571e2f7c66",
            "3a8a6c503f5947bca5d8f4e8a9a4c550",
            "bdfad133c7bb4a768332c23f6d1d5829",
            "6519f4b20f364be58c9b2832c3131432",
            "a51e67d367af47b99935f57f5e810be8",
            "ce88677e09d548719cbfb1741945f566",
            "dce3152da95540be99636090201f40a2",
            "fceb82c2c40b40658226368ee5ee7822",
            "f92749144b5c4de4ae631ca9ea57fa6d",
            "c8e70430574f4b38a012d2cc371a4a4f"
          ]
        },
        "id": "qY0S6zpprcf1",
        "outputId": "0902792d-c861-4749-ae5d-68bcaa7f6bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ¤– Evaluating Model: Llama-2-7b-chat-hf\n",
            "============================================================\n",
            "ðŸ”„ Loading Llama-2-7b-chat-hf from meta-llama/Llama-2-7b-chat-hf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75e5e09f80a84172ac13ff4aef43f508"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Hugging Face authentication successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8a959107c364a97b9f45bbea3073300"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f15f1d6f9ebc4a0eb620b63a42c3194b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4deaf6c5a4bb47dd88467d56130de371"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b6d0c673f04f8ba63d68472c414dbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec47ae0ce8bd428b89f5a04f7b12fba8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9a168e3461b4a7cb282a0be53986e0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb1ace01a3bc41d8ba55f6ced4466023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "821342a171094ee28dfce5b0c49cee07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1e9f098551d40fd961de9aef1e49fe0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1f4a454bfb04045b3a4b6c4ae5ab9b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee1706b143064101bc04541528e683f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Llama-2-7b-chat-hf loaded successfully on cuda\n",
            "\n",
            "ðŸš€ Evaluating Llama-2-7b-chat-hf on 1500 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   0%|          | 1/1500 [00:01<42:53,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   0%|          | 3/1500 [00:02<13:46,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   0%|          | 5/1500 [00:02<08:11,  3.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   0%|          | 6/1500 [00:02<07:06,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   1%|          | 8/1500 [00:03<05:59,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 9/1500 [00:03<05:41,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 10/1500 [00:03<05:34,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 11/1500 [00:03<05:26,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 12/1500 [00:03<05:19,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 13/1500 [00:04<05:14,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   1%|          | 15/1500 [00:04<05:00,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 16/1500 [00:04<05:01,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 17/1500 [00:04<05:02,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|          | 18/1500 [00:05<05:04,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|â–         | 19/1500 [00:05<05:05,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|â–         | 20/1500 [00:05<05:05,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   1%|â–         | 21/1500 [00:05<05:08,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   2%|â–         | 23/1500 [00:06<05:59,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D) Interlagos\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   2%|â–         | 25/1500 [00:06<05:29,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 26/1500 [00:06<05:04,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 27/1500 [00:07<05:02,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 28/1500 [00:07<05:01,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 29/1500 [00:07<05:00,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   2%|â–         | 31/1500 [00:07<04:46,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 32/1500 [00:08<04:52,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 33/1500 [00:08<04:53,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 34/1500 [00:08<04:54,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   2%|â–         | 36/1500 [00:08<04:41,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   2%|â–         | 37/1500 [00:09<04:31,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 38/1500 [00:09<04:40,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 40/1500 [00:09<04:34,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 41/1500 [00:09<04:40,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 43/1500 [00:10<04:36,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 44/1500 [00:10<04:39,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 45/1500 [00:10<04:46,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 46/1500 [00:10<04:51,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 47/1500 [00:11<05:00,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 49/1500 [00:11<04:57,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 50/1500 [00:11<04:58,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   3%|â–Ž         | 51/1500 [00:11<04:56,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   4%|â–Ž         | 53/1500 [00:12<04:41,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   4%|â–Ž         | 54/1500 [00:12<04:43,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   4%|â–Ž         | 55/1500 [00:12<04:48,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   4%|â–Ž         | 56/1500 [00:12<04:54,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   4%|â–         | 57/1500 [00:13<04:56,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   4%|â–         | 59/1500 [00:13<04:39,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   4%|â–         | 60/1500 [00:13<04:37,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   4%|â–         | 62/1500 [00:14<04:30,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   4%|â–         | 64/1500 [00:14<04:27,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   4%|â–         | 65/1500 [00:14<04:34,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   4%|â–         | 67/1500 [00:15<04:29,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   5%|â–         | 68/1500 [00:15<04:35,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   5%|â–         | 70/1500 [00:15<04:27,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   5%|â–         | 71/1500 [00:15<04:33,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   5%|â–         | 72/1500 [00:16<04:43,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   5%|â–         | 73/1500 [00:16<04:45,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   5%|â–Œ         | 75/1500 [00:16<04:33,  5.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   5%|â–Œ         | 77/1500 [00:16<04:23,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   5%|â–Œ         | 78/1500 [00:17<04:19,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   5%|â–Œ         | 80/1500 [00:17<04:22,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   5%|â–Œ         | 82/1500 [00:17<04:16,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 83/1500 [00:18<04:28,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 84/1500 [00:18<04:35,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 85/1500 [00:18<04:41,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 86/1500 [00:18<04:46,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 88/1500 [00:19<04:40,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 89/1500 [00:19<04:45,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 91/1500 [00:19<04:36,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   6%|â–Œ         | 93/1500 [00:20<04:28,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   6%|â–‹         | 94/1500 [00:20<04:21,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   6%|â–‹         | 96/1500 [00:20<04:19,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   6%|â–‹         | 97/1500 [00:20<04:25,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   7%|â–‹         | 98/1500 [00:21<04:31,  5.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   7%|â–‹         | 100/1500 [00:21<04:26,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   7%|â–‹         | 101/1500 [00:21<04:17,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   7%|â–‹         | 103/1500 [00:21<04:17,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   7%|â–‹         | 105/1500 [00:22<04:19,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   7%|â–‹         | 107/1500 [00:22<04:09,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   7%|â–‹         | 108/1500 [00:22<04:17,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   7%|â–‹         | 109/1500 [00:23<04:26,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   7%|â–‹         | 110/1500 [00:23<04:31,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   7%|â–‹         | 111/1500 [00:23<04:37,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   7%|â–‹         | 112/1500 [00:23<04:38,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 113/1500 [00:23<04:41,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 114/1500 [00:24<04:44,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 115/1500 [00:24<04:45,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 116/1500 [00:24<06:05,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D) Red Flag F\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 117/1500 [00:24<05:45,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   8%|â–Š         | 119/1500 [00:25<05:02,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   8%|â–Š         | 121/1500 [00:25<04:40,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 122/1500 [00:25<04:40,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 123/1500 [00:26<04:42,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   8%|â–Š         | 124/1500 [00:26<04:41,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   8%|â–Š         | 126/1500 [00:26<04:30,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   9%|â–Š         | 128/1500 [00:27<04:12,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–Š         | 129/1500 [00:27<04:21,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   9%|â–Š         | 131/1500 [00:27<04:28,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 132/1500 [00:27<04:34,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 133/1500 [00:28<04:39,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 134/1500 [00:28<04:38,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 135/1500 [00:28<04:38,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 136/1500 [00:28<04:44,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 137/1500 [00:28<04:46,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 138/1500 [00:29<04:45,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 139/1500 [00:29<04:43,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:   9%|â–‰         | 140/1500 [00:29<04:43,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:   9%|â–‰         | 142/1500 [00:29<04:34,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–‰         | 143/1500 [00:30<04:41,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–‰         | 144/1500 [00:30<04:44,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–‰         | 145/1500 [00:30<04:44,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–‰         | 146/1500 [00:30<04:51,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–‰         | 147/1500 [00:31<04:54,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–‰         | 148/1500 [00:31<04:52,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–‰         | 149/1500 [00:31<04:49,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–ˆ         | 150/1500 [00:31<04:51,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  10%|â–ˆ         | 152/1500 [00:32<05:25,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D) Christian Horner\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  10%|â–ˆ         | 154/1500 [00:32<04:50,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  10%|â–ˆ         | 155/1500 [00:32<04:57,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  10%|â–ˆ         | 157/1500 [00:33<04:33,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 158/1500 [00:33<04:31,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 159/1500 [00:33<04:33,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 160/1500 [00:33<04:34,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 161/1500 [00:34<04:33,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 162/1500 [00:34<04:34,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 163/1500 [00:34<04:34,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 164/1500 [00:34<04:36,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 165/1500 [00:34<04:35,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 167/1500 [00:35<04:22,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆ         | 168/1500 [00:35<04:12,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆâ–        | 169/1500 [00:35<04:22,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆâ–        | 170/1500 [00:35<04:25,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆâ–        | 171/1500 [00:36<04:27,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  11%|â–ˆâ–        | 172/1500 [00:36<04:31,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 173/1500 [00:36<04:31,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 174/1500 [00:36<04:36,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 176/1500 [00:37<04:22,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 177/1500 [00:37<04:25,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 178/1500 [00:37<04:28,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 179/1500 [00:37<04:31,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 181/1500 [00:38<04:29,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 182/1500 [00:38<04:29,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 183/1500 [00:38<04:31,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 184/1500 [00:38<04:31,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 185/1500 [00:38<04:32,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 186/1500 [00:39<04:33,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  12%|â–ˆâ–        | 187/1500 [00:39<04:32,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 188/1500 [00:39<04:30,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 189/1500 [00:39<04:30,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 190/1500 [00:40<04:31,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 191/1500 [00:40<04:34,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 192/1500 [00:40<04:31,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 193/1500 [00:40<04:31,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 194/1500 [00:40<04:33,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 195/1500 [00:41<04:32,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 197/1500 [00:41<04:17,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 199/1500 [00:41<04:10,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 200/1500 [00:42<04:15,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  13%|â–ˆâ–Ž        | 202/1500 [00:42<04:08,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–Ž        | 203/1500 [00:42<04:13,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–Ž        | 204/1500 [00:42<04:17,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–Ž        | 205/1500 [00:43<04:25,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–Ž        | 206/1500 [00:43<04:29,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 207/1500 [00:43<04:30,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 208/1500 [00:43<04:29,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 209/1500 [00:43<04:28,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 210/1500 [00:44<04:33,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 211/1500 [00:44<04:34,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 212/1500 [00:44<04:34,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 214/1500 [00:44<04:19,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 215/1500 [00:45<04:23,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 216/1500 [00:45<04:27,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  14%|â–ˆâ–        | 217/1500 [00:45<04:29,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–        | 219/1500 [00:45<04:18,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–        | 221/1500 [00:46<04:03,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–        | 222/1500 [00:46<04:11,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–        | 223/1500 [00:46<04:14,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–        | 224/1500 [00:46<04:17,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–Œ        | 225/1500 [00:47<04:20,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–Œ        | 227/1500 [00:47<04:11,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–Œ        | 228/1500 [00:47<04:13,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–Œ        | 229/1500 [00:47<04:20,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–Œ        | 230/1500 [00:48<04:19,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–Œ        | 231/1500 [00:48<04:23,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  15%|â–ˆâ–Œ        | 232/1500 [00:48<04:22,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 234/1500 [00:48<04:09,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 235/1500 [00:49<04:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 236/1500 [00:49<04:06,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 237/1500 [00:49<04:10,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 238/1500 [00:49<04:11,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 239/1500 [00:49<04:14,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 240/1500 [00:50<04:15,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 241/1500 [00:50<04:20,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 242/1500 [00:50<04:23,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–Œ        | 243/1500 [00:50<04:26,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–‹        | 244/1500 [00:51<04:24,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–‹        | 245/1500 [00:51<04:22,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–‹        | 246/1500 [00:51<04:23,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  16%|â–ˆâ–‹        | 247/1500 [00:51<04:23,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 248/1500 [00:51<04:22,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 250/1500 [00:52<04:09,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 251/1500 [00:52<03:58,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 252/1500 [00:52<04:06,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 253/1500 [00:52<04:13,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 254/1500 [00:53<04:14,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 255/1500 [00:53<04:16,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 257/1500 [00:53<04:04,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 258/1500 [00:53<04:08,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 259/1500 [00:54<04:10,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  17%|â–ˆâ–‹        | 261/1500 [00:54<04:00,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 263/1500 [00:54<03:57,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 264/1500 [00:55<04:07,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 266/1500 [00:55<04:00,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 268/1500 [00:55<03:54,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 269/1500 [00:56<04:01,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 270/1500 [00:56<04:05,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 272/1500 [00:56<03:58,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 274/1500 [00:56<03:46,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 275/1500 [00:57<03:57,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 276/1500 [00:57<04:03,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  18%|â–ˆâ–Š        | 277/1500 [00:57<04:12,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–Š        | 278/1500 [00:57<04:12,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–Š        | 279/1500 [00:58<04:14,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–Š        | 280/1500 [00:58<04:14,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 282/1500 [00:58<04:04,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 283/1500 [00:58<04:10,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 284/1500 [00:59<04:12,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 285/1500 [00:59<04:14,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 286/1500 [00:59<04:14,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 287/1500 [00:59<04:12,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 288/1500 [00:59<04:13,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 289/1500 [01:00<04:13,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 290/1500 [01:00<04:12,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 291/1500 [01:00<04:14,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  19%|â–ˆâ–‰        | 292/1500 [01:00<04:11,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–‰        | 293/1500 [01:00<04:12,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–‰        | 294/1500 [01:01<04:11,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–‰        | 295/1500 [01:01<04:14,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–‰        | 296/1500 [01:01<04:11,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–‰        | 298/1500 [01:01<03:58,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–ˆ        | 300/1500 [01:02<03:42,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–ˆ        | 302/1500 [01:02<03:46,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–ˆ        | 303/1500 [01:02<03:56,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–ˆ        | 304/1500 [01:03<04:00,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–ˆ        | 306/1500 [01:03<03:54,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  20%|â–ˆâ–ˆ        | 307/1500 [01:03<03:59,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 308/1500 [01:03<04:02,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 309/1500 [01:04<04:01,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 310/1500 [01:04<04:04,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 312/1500 [01:04<03:55,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 313/1500 [01:04<04:03,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 314/1500 [01:05<04:07,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 315/1500 [01:05<04:09,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 317/1500 [01:05<03:54,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆ        | 318/1500 [01:05<03:45,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆâ–       | 319/1500 [01:06<03:52,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆâ–       | 320/1500 [01:06<03:56,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  21%|â–ˆâ–ˆâ–       | 321/1500 [01:06<03:58,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 323/1500 [01:06<03:48,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 324/1500 [01:07<03:41,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 325/1500 [01:07<03:48,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 326/1500 [01:07<03:52,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 327/1500 [01:07<03:56,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 328/1500 [01:07<03:58,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 329/1500 [01:08<04:01,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 330/1500 [01:08<04:03,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 331/1500 [01:08<04:06,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 332/1500 [01:08<04:06,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 334/1500 [01:09<03:53,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 335/1500 [01:09<03:44,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 336/1500 [01:09<03:51,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  22%|â–ˆâ–ˆâ–       | 337/1500 [01:09<03:56,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 339/1500 [01:10<03:52,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 341/1500 [01:10<03:48,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 342/1500 [01:10<03:56,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 343/1500 [01:11<03:59,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 344/1500 [01:11<04:05,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 345/1500 [01:11<04:05,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 346/1500 [01:11<04:07,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 347/1500 [01:11<04:08,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 349/1500 [01:12<03:57,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 350/1500 [01:12<03:49,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 351/1500 [01:12<03:50,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  23%|â–ˆâ–ˆâ–Ž       | 352/1500 [01:12<03:58,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–Ž       | 354/1500 [01:13<03:46,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–Ž       | 355/1500 [01:13<03:38,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–Ž       | 356/1500 [01:13<03:44,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 357/1500 [01:13<03:48,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 358/1500 [01:14<03:50,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 359/1500 [01:14<03:52,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 361/1500 [01:14<03:48,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 362/1500 [01:14<03:51,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 363/1500 [01:15<03:54,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 364/1500 [01:15<03:54,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 365/1500 [01:15<03:56,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 366/1500 [01:15<03:56,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  24%|â–ˆâ–ˆâ–       | 367/1500 [01:15<04:00,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–       | 368/1500 [01:16<03:58,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–       | 369/1500 [01:16<03:59,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–       | 371/1500 [01:16<03:45,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–       | 372/1500 [01:16<03:49,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–       | 373/1500 [01:17<03:50,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–       | 374/1500 [01:17<03:52,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–Œ       | 375/1500 [01:17<03:54,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–Œ       | 376/1500 [01:17<03:56,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–Œ       | 377/1500 [01:18<03:57,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–Œ       | 378/1500 [01:18<03:58,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–Œ       | 379/1500 [01:18<03:57,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  25%|â–ˆâ–ˆâ–Œ       | 381/1500 [01:18<03:43,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 383/1500 [01:19<03:38,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 384/1500 [01:19<03:44,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 385/1500 [01:19<03:47,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 386/1500 [01:19<03:48,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 387/1500 [01:20<03:53,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 388/1500 [01:20<03:52,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 389/1500 [01:20<03:53,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 390/1500 [01:20<03:52,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 391/1500 [01:20<03:51,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 392/1500 [01:21<03:55,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–Œ       | 393/1500 [01:21<03:55,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–‹       | 394/1500 [01:21<03:54,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–‹       | 395/1500 [01:21<03:54,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  26%|â–ˆâ–ˆâ–‹       | 396/1500 [01:21<03:52,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 398/1500 [01:22<03:41,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 399/1500 [01:22<03:46,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 400/1500 [01:22<03:49,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 401/1500 [01:23<03:52,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 402/1500 [01:23<03:54,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 404/1500 [01:23<03:45,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 405/1500 [01:23<03:50,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 407/1500 [01:24<03:42,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 408/1500 [01:24<03:47,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 409/1500 [01:24<03:47,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 410/1500 [01:24<03:51,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  27%|â–ˆâ–ˆâ–‹       | 411/1500 [01:25<03:58,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 413/1500 [01:25<03:49,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 414/1500 [01:25<03:55,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 415/1500 [01:26<03:53,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 416/1500 [01:26<03:54,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 417/1500 [01:26<03:53,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 419/1500 [01:26<03:37,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 420/1500 [01:27<03:41,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 421/1500 [01:27<03:44,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 422/1500 [01:27<03:46,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 424/1500 [01:27<03:36,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 426/1500 [01:28<03:31,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  28%|â–ˆâ–ˆâ–Š       | 427/1500 [01:28<03:35,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–Š       | 428/1500 [01:28<03:39,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–Š       | 429/1500 [01:28<03:46,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–Š       | 430/1500 [01:29<03:46,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–Š       | 431/1500 [01:29<03:46,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 432/1500 [01:29<03:47,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 433/1500 [01:29<03:48,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 435/1500 [01:30<03:37,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 437/1500 [01:30<03:21,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 438/1500 [01:30<03:27,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 439/1500 [01:30<03:32,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 440/1500 [01:31<03:38,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 441/1500 [01:31<03:41,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  29%|â–ˆâ–ˆâ–‰       | 442/1500 [01:31<03:41,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–‰       | 443/1500 [01:31<03:41,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–‰       | 444/1500 [01:31<03:41,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–‰       | 445/1500 [01:32<03:43,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–‰       | 446/1500 [01:32<03:46,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–‰       | 447/1500 [01:32<03:45,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–‰       | 448/1500 [01:32<03:45,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–‰       | 449/1500 [01:33<03:44,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–ˆ       | 450/1500 [01:33<03:45,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–ˆ       | 451/1500 [01:33<03:46,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–ˆ       | 452/1500 [01:33<03:45,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–ˆ       | 453/1500 [01:33<03:47,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–ˆ       | 454/1500 [01:34<03:45,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–ˆ       | 455/1500 [01:34<03:45,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  30%|â–ˆâ–ˆâ–ˆ       | 456/1500 [01:34<03:45,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 458/1500 [01:34<03:31,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 459/1500 [01:35<03:35,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 460/1500 [01:35<03:38,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 461/1500 [01:35<03:45,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 462/1500 [01:35<03:45,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 463/1500 [01:36<03:44,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 464/1500 [01:36<03:42,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 465/1500 [01:36<03:51,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 466/1500 [01:36<03:48,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 467/1500 [01:36<03:47,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆ       | 468/1500 [01:37<03:47,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆâ–      | 469/1500 [01:37<03:44,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆâ–      | 470/1500 [01:37<03:44,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆâ–      | 471/1500 [01:37<03:46,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  31%|â–ˆâ–ˆâ–ˆâ–      | 472/1500 [01:38<03:49,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 473/1500 [01:38<03:48,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 475/1500 [01:38<03:37,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 476/1500 [01:38<03:35,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 477/1500 [01:39<03:36,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 479/1500 [01:39<03:28,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 480/1500 [01:39<03:31,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 481/1500 [01:39<03:35,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 482/1500 [01:40<03:38,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 483/1500 [01:40<03:43,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 485/1500 [01:40<03:28,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 486/1500 [01:40<03:18,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  32%|â–ˆâ–ˆâ–ˆâ–      | 487/1500 [01:41<03:23,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 488/1500 [01:41<03:25,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 489/1500 [01:41<03:29,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 490/1500 [01:41<03:32,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 492/1500 [01:42<03:21,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 493/1500 [01:42<03:25,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 495/1500 [01:42<03:20,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 496/1500 [01:43<03:13,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 497/1500 [01:43<03:20,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 498/1500 [01:43<03:24,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 499/1500 [01:43<03:26,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 500/1500 [01:43<03:33,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 501/1500 [01:44<03:36,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 502/1500 [01:44<03:37,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 503/1500 [01:44<03:38,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 505/1500 [01:44<03:27,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 506/1500 [01:45<03:28,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 508/1500 [01:45<03:19,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 509/1500 [01:45<03:23,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 511/1500 [01:46<03:16,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 512/1500 [01:46<03:20,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 513/1500 [01:46<03:25,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 514/1500 [01:46<03:26,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 515/1500 [01:47<03:26,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  34%|â–ˆâ–ˆâ–ˆâ–      | 517/1500 [01:47<03:18,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–      | 518/1500 [01:47<03:23,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–      | 519/1500 [01:47<03:25,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–      | 520/1500 [01:48<03:29,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–      | 521/1500 [01:48<03:32,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–      | 522/1500 [01:48<03:32,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–      | 524/1500 [01:48<03:25,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 525/1500 [01:49<03:27,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 526/1500 [01:49<03:28,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 527/1500 [01:49<03:29,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 528/1500 [01:49<03:34,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 530/1500 [01:50<03:19,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 531/1500 [01:50<03:24,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 532/1500 [01:50<03:28,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 533/1500 [01:50<03:30,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 534/1500 [01:51<03:31,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 535/1500 [01:51<03:29,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 537/1500 [01:51<03:20,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 538/1500 [01:51<03:11,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 540/1500 [01:52<03:09,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 542/1500 [01:52<03:05,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 543/1500 [01:52<03:13,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 544/1500 [01:53<03:15,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 546/1500 [01:53<03:11,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 547/1500 [01:53<03:14,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 548/1500 [01:53<03:17,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 549/1500 [01:54<03:19,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 550/1500 [01:54<03:22,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 551/1500 [01:54<03:22,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 552/1500 [01:54<03:23,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 553/1500 [01:55<03:22,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 554/1500 [01:55<03:23,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 555/1500 [01:55<03:23,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 556/1500 [01:55<03:25,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 557/1500 [01:55<03:24,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 558/1500 [01:56<03:24,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 559/1500 [01:56<03:24,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 560/1500 [01:56<03:24,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 561/1500 [01:56<03:22,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 563/1500 [01:57<03:11,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 565/1500 [01:57<03:08,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 566/1500 [01:57<03:11,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 567/1500 [01:57<03:14,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 568/1500 [01:58<03:15,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 569/1500 [01:58<03:16,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 570/1500 [01:58<03:17,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 572/1500 [01:59<03:07,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 573/1500 [01:59<03:11,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 574/1500 [01:59<03:15,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 575/1500 [01:59<03:18,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 576/1500 [01:59<03:16,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 578/1500 [02:00<03:09,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 579/1500 [02:00<03:12,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 580/1500 [02:00<03:14,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 581/1500 [02:00<03:16,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 582/1500 [02:01<03:17,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 583/1500 [02:01<03:16,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 584/1500 [02:01<03:20,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 585/1500 [02:01<03:19,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 587/1500 [02:02<03:10,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 589/1500 [02:02<03:06,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 591/1500 [02:03<02:58,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 592/1500 [02:03<03:06,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 593/1500 [02:03<03:10,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 594/1500 [02:03<03:11,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 595/1500 [02:03<03:14,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 596/1500 [02:04<03:15,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 597/1500 [02:04<03:16,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 598/1500 [02:04<03:20,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 599/1500 [02:04<03:27,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 600/1500 [02:05<03:25,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 602/1500 [02:05<03:08,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 603/1500 [02:05<03:10,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 604/1500 [02:05<03:15,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 605/1500 [02:06<03:17,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 606/1500 [02:06<03:19,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 607/1500 [02:06<03:16,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 609/1500 [02:06<03:03,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 611/1500 [02:07<02:59,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 612/1500 [02:07<03:07,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 613/1500 [02:07<03:11,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 614/1500 [02:08<03:12,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 615/1500 [02:08<03:12,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 616/1500 [02:08<03:15,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 618/1500 [02:08<03:08,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 619/1500 [02:09<03:12,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 620/1500 [02:09<03:10,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 621/1500 [02:09<03:11,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 622/1500 [02:09<03:11,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 623/1500 [02:09<03:08,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 625/1500 [02:10<02:59,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 627/1500 [02:10<02:48,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 629/1500 [02:11<02:47,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 630/1500 [02:11<02:52,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 631/1500 [02:11<02:58,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 632/1500 [02:11<03:01,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 633/1500 [02:12<03:04,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 634/1500 [02:12<03:06,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 635/1500 [02:12<03:06,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 636/1500 [02:12<03:08,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 637/1500 [02:12<03:06,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 638/1500 [02:13<03:05,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 639/1500 [02:13<03:05,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 640/1500 [02:13<03:54,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D) Christian Horner\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 641/1500 [02:13<03:40,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 642/1500 [02:14<03:30,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 644/1500 [02:14<03:08,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 645/1500 [02:14<02:57,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 646/1500 [02:14<02:58,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 647/1500 [02:15<02:59,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 648/1500 [02:15<03:02,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 649/1500 [02:15<03:04,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 650/1500 [02:15<03:06,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 651/1500 [02:16<03:09,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 652/1500 [02:16<03:10,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 653/1500 [02:16<03:08,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 654/1500 [02:16<03:08,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 655/1500 [02:16<03:06,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 657/1500 [02:17<04:19,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 658/1500 [02:18<03:59,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 659/1500 [02:18<03:43,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 660/1500 [02:18<03:32,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 661/1500 [02:18<03:25,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 662/1500 [02:18<03:18,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 663/1500 [02:19<03:12,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 664/1500 [02:19<03:08,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 665/1500 [02:19<03:05,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 666/1500 [02:19<03:06,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 667/1500 [02:20<03:07,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 668/1500 [02:20<03:03,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 669/1500 [02:20<03:02,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 671/1500 [02:20<02:51,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 672/1500 [02:21<02:55,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 674/1500 [02:21<02:47,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 675/1500 [02:21<02:42,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 676/1500 [02:22<03:34,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D) Christian Horner\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 678/1500 [02:22<03:07,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 679/1500 [02:22<03:06,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 680/1500 [02:22<03:04,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 681/1500 [02:23<03:03,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 682/1500 [02:23<03:01,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 684/1500 [02:23<02:50,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 685/1500 [02:23<02:52,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 686/1500 [02:24<02:52,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 687/1500 [02:24<02:54,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 688/1500 [02:24<02:57,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 690/1500 [02:25<02:48,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 691/1500 [02:25<02:49,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 693/1500 [02:25<02:44,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 694/1500 [02:25<02:47,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 695/1500 [02:26<02:49,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 696/1500 [02:26<02:52,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 697/1500 [02:26<02:52,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 699/1500 [02:26<02:44,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 701/1500 [02:27<02:39,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 702/1500 [02:27<02:43,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 703/1500 [02:27<02:46,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 704/1500 [02:27<02:49,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 705/1500 [02:28<02:53,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 706/1500 [02:28<02:54,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 707/1500 [02:28<02:52,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 708/1500 [02:28<02:54,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 709/1500 [02:29<02:54,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 710/1500 [02:29<02:54,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 711/1500 [02:29<02:54,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 712/1500 [02:29<02:53,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 713/1500 [02:29<02:53,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 714/1500 [02:30<02:53,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 715/1500 [02:30<02:52,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 716/1500 [02:30<02:52,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 717/1500 [02:30<02:51,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 718/1500 [02:31<02:53,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 719/1500 [02:31<02:57,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 720/1500 [02:31<02:55,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 721/1500 [02:31<02:52,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 722/1500 [02:31<02:51,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 724/1500 [02:32<02:41,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 725/1500 [02:32<02:44,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 726/1500 [02:32<02:46,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 727/1500 [02:33<02:47,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 728/1500 [02:33<02:46,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 730/1500 [02:33<02:38,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 732/1500 [02:34<02:33,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 733/1500 [02:34<02:40,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 734/1500 [02:34<02:42,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 735/1500 [02:34<02:43,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 736/1500 [02:34<02:43,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 737/1500 [02:35<02:42,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 738/1500 [02:35<02:44,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 739/1500 [02:35<02:44,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 740/1500 [02:35<02:46,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 741/1500 [02:36<02:45,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 743/1500 [02:36<02:35,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 744/1500 [02:36<02:37,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 745/1500 [02:36<02:38,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 746/1500 [02:37<02:41,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 747/1500 [02:37<02:44,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 748/1500 [02:37<02:42,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 749/1500 [02:37<02:42,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 750/1500 [02:37<02:41,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 751/1500 [02:38<02:40,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 752/1500 [02:38<02:42,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 753/1500 [02:38<02:41,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 754/1500 [02:38<02:41,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 755/1500 [02:39<02:41,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 757/1500 [02:39<02:32,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 758/1500 [02:39<02:36,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 759/1500 [02:39<02:37,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 760/1500 [02:40<02:39,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 761/1500 [02:40<02:41,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 762/1500 [02:40<02:39,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 764/1500 [02:40<02:31,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 765/1500 [02:41<02:25,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 766/1500 [02:41<02:28,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 767/1500 [02:41<02:35,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 768/1500 [02:41<02:36,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 769/1500 [02:41<02:38,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 770/1500 [02:42<02:38,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 772/1500 [02:42<02:30,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 773/1500 [02:42<02:34,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 775/1500 [02:43<02:29,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 776/1500 [02:43<02:25,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 777/1500 [02:43<02:28,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 778/1500 [02:43<02:33,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 779/1500 [02:44<02:38,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 780/1500 [02:44<02:43,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 781/1500 [02:44<02:41,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 782/1500 [02:44<02:40,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 784/1500 [02:45<02:30,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 786/1500 [02:45<02:19,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 787/1500 [02:45<02:22,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 788/1500 [02:45<02:26,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 789/1500 [02:46<02:29,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 790/1500 [02:46<02:32,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 791/1500 [02:46<02:34,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 792/1500 [02:46<02:38,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 793/1500 [02:47<02:38,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 794/1500 [02:47<02:37,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 795/1500 [02:47<02:35,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 796/1500 [02:47<02:34,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 797/1500 [02:47<02:33,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 798/1500 [02:48<02:34,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 800/1500 [02:48<02:24,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 801/1500 [02:48<02:26,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 802/1500 [02:49<02:27,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 803/1500 [02:49<02:30,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 804/1500 [02:49<02:33,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 806/1500 [02:49<02:24,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 807/1500 [02:50<02:27,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 809/1500 [02:50<02:21,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 811/1500 [02:50<02:18,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 812/1500 [02:51<02:21,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 813/1500 [02:51<02:23,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 814/1500 [02:51<02:26,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 815/1500 [02:51<02:29,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 816/1500 [02:52<02:28,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 817/1500 [02:52<02:29,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 818/1500 [02:52<02:27,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 819/1500 [02:52<02:27,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 820/1500 [02:52<02:26,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 822/1500 [02:53<02:19,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 823/1500 [02:53<02:21,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 824/1500 [02:53<02:22,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 825/1500 [02:53<02:25,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 826/1500 [02:54<02:26,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 827/1500 [02:54<02:25,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 828/1500 [02:54<02:33,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 829/1500 [02:54<02:33,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 830/1500 [02:55<02:32,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 831/1500 [02:55<02:30,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 833/1500 [02:55<02:23,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 834/1500 [02:55<02:25,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 835/1500 [02:56<02:25,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 836/1500 [02:56<02:25,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 837/1500 [02:56<02:25,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 838/1500 [02:56<02:27,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 839/1500 [02:57<02:26,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 840/1500 [02:57<02:29,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 841/1500 [02:57<02:28,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 842/1500 [02:57<02:29,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 843/1500 [02:57<02:28,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 845/1500 [02:58<02:17,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 846/1500 [02:58<02:11,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 848/1500 [02:58<02:10,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 850/1500 [02:59<02:09,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 852/1500 [02:59<02:09,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 853/1500 [02:59<02:12,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 854/1500 [03:00<02:15,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 855/1500 [03:00<02:16,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 856/1500 [03:00<02:20,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 857/1500 [03:00<02:22,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 858/1500 [03:01<02:23,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 860/1500 [03:01<02:13,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 861/1500 [03:01<02:15,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 863/1500 [03:02<02:10,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 865/1500 [03:02<02:03,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 866/1500 [03:02<02:07,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 867/1500 [03:02<02:11,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 868/1500 [03:03<02:13,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 869/1500 [03:03<02:14,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 871/1500 [03:03<02:09,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 872/1500 [03:03<02:10,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 874/1500 [03:04<02:06,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 875/1500 [03:04<02:12,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 876/1500 [03:04<02:15,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 877/1500 [03:05<02:14,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 878/1500 [03:05<02:13,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 879/1500 [03:05<02:14,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 880/1500 [03:05<02:14,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 881/1500 [03:05<02:14,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 883/1500 [03:06<02:07,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 884/1500 [03:06<02:10,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 885/1500 [03:06<02:12,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 887/1500 [03:07<02:06,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 888/1500 [03:07<02:09,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 889/1500 [03:07<02:09,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 890/1500 [03:07<02:13,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 891/1500 [03:08<02:13,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 892/1500 [03:08<02:13,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 893/1500 [03:08<02:13,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 895/1500 [03:08<02:07,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 896/1500 [03:09<02:03,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 897/1500 [03:09<02:08,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 899/1500 [03:09<02:03,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 900/1500 [03:09<02:07,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 902/1500 [03:10<02:05,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 903/1500 [03:10<02:06,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 905/1500 [03:11<02:04,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 906/1500 [03:11<01:59,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 907/1500 [03:11<02:04,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 909/1500 [03:11<02:02,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 910/1500 [03:12<02:04,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 912/1500 [03:12<01:59,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 913/1500 [03:12<01:55,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 914/1500 [03:12<01:59,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 915/1500 [03:13<02:03,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 917/1500 [03:13<01:57,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 918/1500 [03:13<02:01,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 919/1500 [03:13<02:03,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 920/1500 [03:14<02:06,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 921/1500 [03:14<02:05,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 922/1500 [03:14<02:05,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 923/1500 [03:14<02:05,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 924/1500 [03:15<02:05,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 925/1500 [03:15<02:05,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 926/1500 [03:15<02:04,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 928/1500 [03:15<01:58,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 929/1500 [03:16<01:59,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 930/1500 [03:16<02:02,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 931/1500 [03:16<02:02,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 932/1500 [03:16<02:02,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 933/1500 [03:16<02:02,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 934/1500 [03:17<02:02,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 935/1500 [03:17<02:03,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 936/1500 [03:17<02:03,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 937/1500 [03:17<02:03,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 938/1500 [03:18<02:03,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 939/1500 [03:18<02:03,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 940/1500 [03:18<02:02,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 941/1500 [03:18<02:01,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 942/1500 [03:18<02:02,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 943/1500 [03:19<02:01,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 944/1500 [03:19<02:00,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 945/1500 [03:19<02:02,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 946/1500 [03:19<02:02,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 947/1500 [03:20<02:01,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 948/1500 [03:20<02:01,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 949/1500 [03:20<02:01,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 950/1500 [03:20<02:01,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 951/1500 [03:20<02:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 952/1500 [03:21<02:04,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 954/1500 [03:21<01:56,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 955/1500 [03:21<01:57,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 956/1500 [03:22<01:58,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 957/1500 [03:22<02:01,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 958/1500 [03:22<02:02,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 959/1500 [03:22<02:01,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 961/1500 [03:23<01:53,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 962/1500 [03:23<01:49,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 963/1500 [03:23<01:53,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 964/1500 [03:23<01:57,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 965/1500 [03:24<01:57,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 966/1500 [03:24<01:59,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 967/1500 [03:24<01:58,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 969/1500 [03:24<01:52,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 970/1500 [03:25<01:46,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 972/1500 [03:25<01:46,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 973/1500 [03:25<01:43,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 974/1500 [03:25<01:46,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 975/1500 [03:26<01:50,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 976/1500 [03:26<01:51,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 977/1500 [03:26<01:52,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 978/1500 [03:26<01:52,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 979/1500 [03:26<01:54,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 980/1500 [03:27<01:54,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 981/1500 [03:27<01:53,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 982/1500 [03:27<01:53,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 984/1500 [03:28<01:47,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 985/1500 [03:28<01:51,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 986/1500 [03:28<01:53,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 987/1500 [03:28<01:53,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 989/1500 [03:29<01:46,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 991/1500 [03:29<01:44,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 993/1500 [03:29<01:42,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 994/1500 [03:30<01:44,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 995/1500 [03:30<01:47,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 996/1500 [03:30<01:49,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 997/1500 [03:30<01:48,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 999/1500 [03:31<01:43,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1000/1500 [03:31<01:45,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1001/1500 [03:31<01:46,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1002/1500 [03:31<01:47,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1003/1500 [03:32<01:47,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1004/1500 [03:32<01:48,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1006/1500 [03:32<01:42,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1007/1500 [03:32<01:44,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1009/1500 [03:33<01:41,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1010/1500 [03:33<01:37,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1011/1500 [03:33<01:40,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1013/1500 [03:34<01:40,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1014/1500 [03:34<01:41,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1015/1500 [03:34<01:44,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1017/1500 [03:35<01:40,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1019/1500 [03:35<01:39,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1021/1500 [03:35<01:38,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1022/1500 [03:36<01:41,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1023/1500 [03:36<01:42,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1024/1500 [03:36<01:43,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1025/1500 [03:36<01:44,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1027/1500 [03:37<01:41,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1028/1500 [03:37<01:37,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1029/1500 [03:37<01:40,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1030/1500 [03:37<01:42,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1031/1500 [03:38<01:43,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1032/1500 [03:38<01:43,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1033/1500 [03:38<01:43,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1034/1500 [03:38<01:44,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1035/1500 [03:38<01:43,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1036/1500 [03:39<01:42,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1037/1500 [03:39<01:42,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1038/1500 [03:39<01:42,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1039/1500 [03:39<01:41,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1040/1500 [03:40<01:40,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1041/1500 [03:40<01:40,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1042/1500 [03:40<01:40,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1043/1500 [03:40<01:42,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1044/1500 [03:40<01:41,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1045/1500 [03:41<01:39,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1046/1500 [03:41<01:41,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1047/1500 [03:41<01:40,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1048/1500 [03:41<01:39,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1049/1500 [03:42<01:39,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1050/1500 [03:42<01:38,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1051/1500 [03:42<01:40,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1052/1500 [03:42<01:39,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1054/1500 [03:43<01:34,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1055/1500 [03:43<01:34,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1056/1500 [03:43<01:35,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1058/1500 [03:43<01:31,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1060/1500 [03:44<01:25,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1061/1500 [03:44<01:29,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1062/1500 [03:44<01:31,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1063/1500 [03:45<01:32,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1064/1500 [03:45<01:32,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1065/1500 [03:45<01:33,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1066/1500 [03:45<01:34,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1067/1500 [03:45<01:35,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1068/1500 [03:46<01:35,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1069/1500 [03:46<01:35,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1070/1500 [03:46<01:35,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1072/1500 [03:46<01:30,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1073/1500 [03:47<01:26,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1075/1500 [03:47<01:25,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1077/1500 [03:47<01:26,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1079/1500 [03:48<01:25,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1080/1500 [03:48<01:27,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1081/1500 [03:48<01:32,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1082/1500 [03:49<01:32,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1083/1500 [03:49<01:33,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1084/1500 [03:49<01:34,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1085/1500 [03:49<01:33,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1086/1500 [03:50<01:34,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1087/1500 [03:50<01:33,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1088/1500 [03:50<01:32,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1089/1500 [03:50<01:32,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1090/1500 [03:50<01:31,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1091/1500 [03:51<01:31,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1092/1500 [03:51<01:31,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1093/1500 [03:51<01:30,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1094/1500 [03:51<01:29,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1095/1500 [03:52<01:29,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1096/1500 [03:52<01:29,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1097/1500 [03:52<01:28,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1098/1500 [03:52<01:28,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1099/1500 [03:52<01:28,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1101/1500 [03:53<01:23,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1102/1500 [03:53<01:19,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1103/1500 [03:53<01:22,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1104/1500 [03:53<01:25,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1105/1500 [03:54<01:25,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1106/1500 [03:54<01:25,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1107/1500 [03:54<01:26,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1108/1500 [03:54<01:26,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1110/1500 [03:55<01:21,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1111/1500 [03:55<01:23,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1112/1500 [03:55<01:25,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1113/1500 [03:55<01:25,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1114/1500 [03:56<01:26,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1115/1500 [03:56<01:25,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1116/1500 [03:56<01:26,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1117/1500 [03:56<01:25,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1119/1500 [03:57<01:21,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1120/1500 [03:57<01:21,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1121/1500 [03:57<01:21,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1122/1500 [03:57<01:22,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1123/1500 [03:58<01:23,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1124/1500 [03:58<01:23,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1125/1500 [03:58<01:23,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1126/1500 [03:58<01:23,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1127/1500 [03:59<01:22,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1128/1500 [03:59<01:21,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1129/1500 [03:59<01:21,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1130/1500 [03:59<01:21,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1132/1500 [04:00<01:16,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1134/1500 [04:00<01:14,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1135/1500 [04:00<01:16,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1136/1500 [04:00<01:17,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1137/1500 [04:01<01:18,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1138/1500 [04:01<01:20,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1139/1500 [04:01<01:20,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1140/1500 [04:01<01:21,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1141/1500 [04:02<01:22,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1142/1500 [04:02<01:21,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1143/1500 [04:02<01:23,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1144/1500 [04:02<01:22,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1145/1500 [04:02<01:21,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1146/1500 [04:03<01:20,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1147/1500 [04:03<01:19,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1148/1500 [04:03<01:21,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1149/1500 [04:03<01:20,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1150/1500 [04:04<01:21,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1151/1500 [04:04<01:20,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1152/1500 [04:04<01:18,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1154/1500 [04:04<01:13,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1155/1500 [04:05<01:14,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1156/1500 [04:05<01:14,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1158/1500 [04:05<01:10,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1159/1500 [04:06<01:12,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1160/1500 [04:06<01:13,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1161/1500 [04:06<01:13,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1162/1500 [04:06<01:14,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1163/1500 [04:06<01:14,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1164/1500 [04:07<01:14,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1165/1500 [04:07<01:15,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1166/1500 [04:07<01:15,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1167/1500 [04:07<01:16,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1168/1500 [04:08<01:16,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1169/1500 [04:08<01:16,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1170/1500 [04:08<01:15,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1171/1500 [04:08<01:15,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1172/1500 [04:09<01:14,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1173/1500 [04:09<01:14,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1174/1500 [04:09<01:13,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1175/1500 [04:09<01:13,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1176/1500 [04:09<01:12,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1177/1500 [04:10<01:12,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1178/1500 [04:10<01:12,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1179/1500 [04:10<01:11,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1180/1500 [04:10<01:11,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1181/1500 [04:11<01:10,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1182/1500 [04:11<01:10,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1183/1500 [04:11<01:11,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1184/1500 [04:11<01:12,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1185/1500 [04:11<01:11,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1186/1500 [04:12<01:11,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1187/1500 [04:12<01:10,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1188/1500 [04:12<01:10,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1189/1500 [04:12<01:09,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1190/1500 [04:13<01:09,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1191/1500 [04:13<01:09,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1192/1500 [04:13<01:09,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1193/1500 [04:13<01:07,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1194/1500 [04:13<01:08,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1195/1500 [04:14<01:07,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1196/1500 [04:14<01:09,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1197/1500 [04:14<01:09,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1198/1500 [04:14<01:08,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1199/1500 [04:15<01:09,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1200/1500 [04:15<01:08,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1201/1500 [04:15<01:09,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1202/1500 [04:15<01:09,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1204/1500 [04:16<01:04,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1206/1500 [04:16<01:02,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1207/1500 [04:16<01:03,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1209/1500 [04:17<01:01,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1211/1500 [04:17<00:58,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1212/1500 [04:17<00:59,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1214/1500 [04:18<00:58,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1215/1500 [04:18<01:00,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1216/1500 [04:18<01:00,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1217/1500 [04:18<01:01,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1218/1500 [04:19<01:02,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1219/1500 [04:19<01:02,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1220/1500 [04:19<01:01,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1221/1500 [04:19<01:02,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1222/1500 [04:20<01:01,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1223/1500 [04:20<01:01,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1224/1500 [04:20<01:01,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1226/1500 [04:20<00:57,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1227/1500 [04:21<00:54,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1228/1500 [04:21<00:56,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1229/1500 [04:21<00:57,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1230/1500 [04:21<00:58,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1231/1500 [04:22<00:58,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1232/1500 [04:22<00:58,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1234/1500 [04:22<00:55,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1235/1500 [04:22<00:56,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1236/1500 [04:23<00:56,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1237/1500 [04:23<00:56,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1238/1500 [04:23<00:57,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1239/1500 [04:23<00:56,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1240/1500 [04:23<00:57,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1241/1500 [04:24<00:58,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1242/1500 [04:24<00:57,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1243/1500 [04:24<00:57,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1244/1500 [04:24<00:55,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1245/1500 [04:25<00:56,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1246/1500 [04:25<00:56,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1247/1500 [04:25<00:56,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1248/1500 [04:25<00:57,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1249/1500 [04:25<00:57,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1250/1500 [04:26<00:57,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1251/1500 [04:26<00:56,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1252/1500 [04:26<00:55,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1253/1500 [04:26<00:54,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1254/1500 [04:27<00:55,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1255/1500 [04:27<00:54,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1256/1500 [04:27<00:54,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1257/1500 [04:27<00:54,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1259/1500 [04:28<00:51,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1260/1500 [04:28<00:52,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1261/1500 [04:28<00:53,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1262/1500 [04:28<00:55,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1263/1500 [04:29<00:53,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1264/1500 [04:29<00:54,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1265/1500 [04:29<00:53,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1266/1500 [04:29<00:53,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1267/1500 [04:30<00:54,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1268/1500 [04:30<00:53,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1269/1500 [04:30<00:54,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1270/1500 [04:30<00:54,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1271/1500 [04:31<00:54,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1272/1500 [04:31<00:53,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1273/1500 [04:31<00:52,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1274/1500 [04:31<00:51,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1276/1500 [04:32<00:48,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1277/1500 [04:32<00:48,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1279/1500 [04:32<00:45,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1280/1500 [04:32<00:44,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1281/1500 [04:33<00:45,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1283/1500 [04:33<00:44,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1285/1500 [04:33<00:43,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1286/1500 [04:34<00:45,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1288/1500 [04:34<00:43,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1289/1500 [04:34<00:45,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1290/1500 [04:35<00:45,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1291/1500 [04:35<00:45,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1292/1500 [04:35<00:46,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1293/1500 [04:35<00:46,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1294/1500 [04:35<00:45,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1295/1500 [04:36<00:45,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1297/1500 [04:36<00:42,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1299/1500 [04:36<00:41,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1301/1500 [04:37<00:40,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1302/1500 [04:37<00:39,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1303/1500 [04:37<00:40,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1305/1500 [04:38<00:39,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1306/1500 [04:38<00:40,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1307/1500 [04:38<00:41,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1308/1500 [04:38<00:41,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1310/1500 [04:39<00:39,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1311/1500 [04:39<00:40,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1312/1500 [04:39<00:40,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1314/1500 [04:40<00:38,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1315/1500 [04:40<00:39,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1317/1500 [04:40<00:37,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1318/1500 [04:40<00:36,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1319/1500 [04:41<00:37,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1321/1500 [04:41<00:37,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1322/1500 [04:41<00:35,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1323/1500 [04:41<00:36,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1324/1500 [04:42<00:38,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1325/1500 [04:42<00:39,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1326/1500 [04:42<00:39,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1327/1500 [04:42<00:39,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1328/1500 [04:43<00:39,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1329/1500 [04:43<00:39,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1330/1500 [04:43<00:38,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1331/1500 [04:43<00:40,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1332/1500 [04:44<00:40,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1333/1500 [04:44<00:39,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1334/1500 [04:44<00:38,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1335/1500 [04:44<00:37,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1336/1500 [04:45<00:37,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1337/1500 [04:45<00:36,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1338/1500 [04:45<00:36,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1339/1500 [04:45<00:36,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1340/1500 [04:45<00:35,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1341/1500 [04:46<00:36,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1343/1500 [04:46<00:33,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1345/1500 [04:46<00:32,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1346/1500 [04:47<00:33,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1347/1500 [04:47<00:33,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1348/1500 [04:47<00:33,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1349/1500 [04:47<00:33,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1351/1500 [04:48<00:31,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1352/1500 [04:48<00:31,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1353/1500 [04:48<00:32,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1354/1500 [04:48<00:32,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1356/1500 [04:49<00:30,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1357/1500 [04:49<00:30,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1358/1500 [04:49<00:30,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1359/1500 [04:50<00:30,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1361/1500 [04:50<00:28,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1362/1500 [04:50<00:29,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1363/1500 [04:50<00:29,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1364/1500 [04:51<00:29,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1365/1500 [04:51<00:29,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1366/1500 [04:51<00:29,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1367/1500 [04:51<00:29,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1369/1500 [04:52<00:27,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1370/1500 [04:52<00:27,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1371/1500 [04:52<00:28,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1373/1500 [04:53<00:26,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1375/1500 [04:53<00:25,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1376/1500 [04:53<00:25,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1377/1500 [04:53<00:26,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1378/1500 [04:54<00:26,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1379/1500 [04:54<00:26,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1380/1500 [04:54<00:26,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1381/1500 [04:54<00:26,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1382/1500 [04:55<00:26,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1383/1500 [04:55<00:26,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1384/1500 [04:55<00:26,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1385/1500 [04:55<00:26,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1386/1500 [04:55<00:26,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1387/1500 [04:56<00:25,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1388/1500 [04:56<00:25,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1389/1500 [04:56<00:25,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1390/1500 [04:56<00:25,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1391/1500 [04:57<00:25,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1393/1500 [04:57<00:24,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1394/1500 [04:57<00:23,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1395/1500 [04:57<00:23,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1396/1500 [04:58<00:23,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1397/1500 [04:58<00:23,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1399/1500 [04:58<00:21,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1400/1500 [04:59<00:21,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1401/1500 [04:59<00:21,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1402/1500 [04:59<00:21,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1403/1500 [04:59<00:21,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1404/1500 [04:59<00:21,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1406/1500 [05:00<00:19,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1407/1500 [05:00<00:19,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1409/1500 [05:00<00:18,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1410/1500 [05:01<00:19,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1411/1500 [05:01<00:19,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1413/1500 [05:01<00:18,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1414/1500 [05:02<00:18,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1415/1500 [05:02<00:18,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1417/1500 [05:02<00:17,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1418/1500 [05:02<00:17,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1419/1500 [05:03<00:17,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1420/1500 [05:03<00:17,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1422/1500 [05:03<00:16,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1423/1500 [05:04<00:16,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1424/1500 [05:04<00:16,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1425/1500 [05:04<00:16,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1427/1500 [05:04<00:15,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1428/1500 [05:05<00:15,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1429/1500 [05:05<00:15,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1430/1500 [05:05<00:15,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1432/1500 [05:05<00:14,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1434/1500 [05:06<00:13,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1435/1500 [05:06<00:13,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1436/1500 [05:06<00:13,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1437/1500 [05:07<00:13,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1438/1500 [05:07<00:13,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1439/1500 [05:07<00:13,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1440/1500 [05:07<00:13,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1441/1500 [05:07<00:13,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1442/1500 [05:08<00:12,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1443/1500 [05:08<00:12,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1444/1500 [05:08<00:12,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1446/1500 [05:09<00:11,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1448/1500 [05:09<00:10,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1449/1500 [05:09<00:11,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1450/1500 [05:09<00:11,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1451/1500 [05:10<00:10,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1453/1500 [05:10<00:10,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1454/1500 [05:10<00:09,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1455/1500 [05:10<00:10,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1456/1500 [05:11<00:10,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1457/1500 [05:11<00:10,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1458/1500 [05:11<00:09,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1459/1500 [05:11<00:09,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1460/1500 [05:12<00:09,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1462/1500 [05:12<00:08,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1463/1500 [05:12<00:08,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1465/1500 [05:13<00:07,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1466/1500 [05:13<00:07,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1468/1500 [05:13<00:06,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1469/1500 [05:14<00:06,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1471/1500 [05:14<00:05,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1472/1500 [05:14<00:05,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1473/1500 [05:14<00:05,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1474/1500 [05:15<00:05,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1475/1500 [05:15<00:05,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1476/1500 [05:15<00:05,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1477/1500 [05:15<00:05,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1478/1500 [05:16<00:04,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1480/1500 [05:16<00:04,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1481/1500 [05:16<00:04,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: A\n",
            "EXTRACTED ANSWER: A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1483/1500 [05:17<00:03,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1485/1500 [05:17<00:02,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1486/1500 [05:17<00:02,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1488/1500 [05:18<00:02,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1489/1500 [05:18<00:02,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1490/1500 [05:18<00:02,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1491/1500 [05:18<00:01,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1493/1500 [05:19<00:01,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1494/1500 [05:19<00:01,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1495/1500 [05:19<00:01,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1496/1500 [05:19<00:00,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: D\n",
            "EXTRACTED ANSWER: D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1497/1500 [05:20<00:00,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Llama-2-7b-chat-hf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1498/1500 [05:20<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: B\n",
            "EXTRACTED ANSWER: B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Llama-2-7b-chat-hf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [05:20<00:00,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "RESPONSE IS: C\n",
            "EXTRACTED ANSWER: C\n",
            "âœ… Llama-2-7b-chat-hf evaluation complete:\n",
            "   Correct: 667\n",
            "   Incorrect: 833\n",
            "   Invalid: 0\n",
            "   Accuracy: 44.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§¹ Cleaned up Llama-2-7b-chat-hf from memory\n",
            "\n",
            "ðŸ’¾ Results saved to: /content/drive/MyDrive/CS6220_Project/results/llama_3_1_8b_instruct_evaluation_results_1763314085.json\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š LLAMA 3.1 8B INSTRUCT EVALUATION SUMMARY\n",
            "============================================================\n",
            "   Accuracy: 44.47%\n",
            "   Correct: 667/1500\n",
            "   Incorrect: 833\n",
            "   Invalid: 0\n",
            "\n",
            "ðŸ’¾ Full results saved to: /content/drive/MyDrive/CS6220_Project/results/llama_3_1_8b_instruct_evaluation_results_1763314085.json\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Llama 3.1 8B Instruct\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"ðŸ¤– Evaluating Model: {MODEL_NAME}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "evaluator = F1QAEvaluator(MODEL_ID, MODEL_NAME)\n",
        "\n",
        "if evaluator.load_model():\n",
        "    results = evaluator.evaluate_dataset(qa_dataset)\n",
        "    evaluator.cleanup()\n",
        "\n",
        "    # Save results to JSON\n",
        "    output_file = Path(RESULTS_PATH) / f\"llama_3_1_8b_instruct_evaluation_results_{int(time.time())}.json\"\n",
        "\n",
        "    results_summary = {\n",
        "        'metadata': {\n",
        "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'model_name': MODEL_NAME,\n",
        "            'model_id': MODEL_ID,\n",
        "            'total_qa_pairs': len(qa_dataset),\n",
        "            'device': evaluator.device\n",
        "        },\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\nðŸ’¾ Results saved to: {output_file}\")\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ðŸ“Š LLAMA 3.1 8B INSTRUCT EVALUATION SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"   Accuracy: {results['accuracy']:.2%}\")\n",
        "    print(f\"   Correct: {results['correct']}/{results['total_questions']}\")\n",
        "    print(f\"   Incorrect: {results['incorrect']}\")\n",
        "    print(f\"   Invalid: {results['invalid']}\")\n",
        "    print(f\"\\nðŸ’¾ Full results saved to: {output_file}\")\n",
        "\n",
        "else:\n",
        "    print(f\"âŒ Failed to load {MODEL_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GMttFVfrcf1"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75e5e09f80a84172ac13ff4aef43f508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2a1e81138284c94993f71e09ac05a8a",
              "IPY_MODEL_47bce37be40840f2b50615c500c77e6e",
              "IPY_MODEL_7377db17a35c4fc8ab1f5c6d77bccdc0",
              "IPY_MODEL_1b30fced8e4742c984e04f9d09214bcd",
              "IPY_MODEL_4d70279f068c4045b594e6e94505c0ae"
            ],
            "layout": "IPY_MODEL_f13461f5300e4a4a8cbce72684822d46"
          }
        },
        "c2a1e81138284c94993f71e09ac05a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b870df3efa0e48419e58e9ce4ee21d1e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c18257606dfb4dc38ecb23a4a93bf1b6",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "47bce37be40840f2b50615c500c77e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7e3e1f604aff4fa99464288d5dcdc101",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1cec25c78bfa43f3a92a5b162ea80346",
            "value": ""
          }
        },
        "7377db17a35c4fc8ab1f5c6d77bccdc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_28f71162541a4075a206e890d87cba63",
            "style": "IPY_MODEL_d724032da63d4738844c3a5ccc6b11f7",
            "value": true
          }
        },
        "1b30fced8e4742c984e04f9d09214bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_6cee68cc4e1a49fe9420862c99317ed5",
            "style": "IPY_MODEL_e4dc3a0b43b94f76a37a7b714ef09bc0",
            "tooltip": ""
          }
        },
        "4d70279f068c4045b594e6e94505c0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a23ae6595bd44794a361462b33c0c4ee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ebacc257241f45c9b0128a768ce733fb",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f13461f5300e4a4a8cbce72684822d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b870df3efa0e48419e58e9ce4ee21d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18257606dfb4dc38ecb23a4a93bf1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e3e1f604aff4fa99464288d5dcdc101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cec25c78bfa43f3a92a5b162ea80346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f71162541a4075a206e890d87cba63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d724032da63d4738844c3a5ccc6b11f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cee68cc4e1a49fe9420862c99317ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4dc3a0b43b94f76a37a7b714ef09bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a23ae6595bd44794a361462b33c0c4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebacc257241f45c9b0128a768ce733fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8a959107c364a97b9f45bbea3073300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a07b34dc53924d71a3c47022278a0548",
              "IPY_MODEL_7e66adf4a2364f8eaccc8ebf916cb4e6",
              "IPY_MODEL_848b4ef825a94f4f8c9f0bdaf9f5c53d"
            ],
            "layout": "IPY_MODEL_1d93a204329a436b86cfe45ef3eee8dd"
          }
        },
        "a07b34dc53924d71a3c47022278a0548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c23507f0cf244f78eb1a02abc209111",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a1ae8939500423c85d7ddedd7b3d0ad",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "7e66adf4a2364f8eaccc8ebf916cb4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8896cfff778845abac91ad4898db6f19",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10f5eb7ace6c4acb961c0d2a95616e72",
            "value": 1618
          }
        },
        "848b4ef825a94f4f8c9f0bdaf9f5c53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4016791902d4033befb26184250e59f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1375d74e242847489157cd802053187a",
            "value": "â€‡1.62k/1.62kâ€‡[00:00&lt;00:00,â€‡54.7kB/s]"
          }
        },
        "1d93a204329a436b86cfe45ef3eee8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c23507f0cf244f78eb1a02abc209111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a1ae8939500423c85d7ddedd7b3d0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8896cfff778845abac91ad4898db6f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f5eb7ace6c4acb961c0d2a95616e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4016791902d4033befb26184250e59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1375d74e242847489157cd802053187a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f15f1d6f9ebc4a0eb620b63a42c3194b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3a98b0574d94af08fa0f3fb565cdd24",
              "IPY_MODEL_6eb4d57f0b7541b8a685ec9f5ee753e5",
              "IPY_MODEL_9efbe43843974dee9b5ae86746cd9a6b"
            ],
            "layout": "IPY_MODEL_b532705318054a6e8e2c5197b22a3361"
          }
        },
        "e3a98b0574d94af08fa0f3fb565cdd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04205715937840649eeffd59129725da",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_192bd8a3142c419489f21c550e681b5e",
            "value": "tokenizer.model:â€‡100%"
          }
        },
        "6eb4d57f0b7541b8a685ec9f5ee753e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4caa1997754d53b6d52718fbd1b22b",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6754f3b661744fc1b7a73f58fa7225e7",
            "value": 499723
          }
        },
        "9efbe43843974dee9b5ae86746cd9a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_988843e9f1204942b7515f4df84ff312",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9f845ed39ba3451a8c3263e1d9b5aa5e",
            "value": "â€‡500k/500kâ€‡[00:00&lt;00:00,â€‡918kB/s]"
          }
        },
        "b532705318054a6e8e2c5197b22a3361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04205715937840649eeffd59129725da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192bd8a3142c419489f21c550e681b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f4caa1997754d53b6d52718fbd1b22b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6754f3b661744fc1b7a73f58fa7225e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "988843e9f1204942b7515f4df84ff312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f845ed39ba3451a8c3263e1d9b5aa5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4deaf6c5a4bb47dd88467d56130de371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4afb475802d483a977f69b61c71480a",
              "IPY_MODEL_c6780ecca3f144bbbcda431fb26b1a53",
              "IPY_MODEL_532e7d6b7f304d05a99ccb867519173a"
            ],
            "layout": "IPY_MODEL_e38870016b31412abbec81556c37ceae"
          }
        },
        "e4afb475802d483a977f69b61c71480a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90af86e4a85542178997881c90e37ec7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_461fb5bd1dbb40929cf4fc0980bdfc67",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "c6780ecca3f144bbbcda431fb26b1a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b90e14f65fb4e5fa8c5710c2239a6ff",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d3b0845cf9f4530a9caf88f938bd700",
            "value": 1842767
          }
        },
        "532e7d6b7f304d05a99ccb867519173a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413612c126884fe791085594e59f3190",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_57a81b19b6eb4adebee8cbcd9788639a",
            "value": "â€‡1.84M/1.84Mâ€‡[00:00&lt;00:00,â€‡18.7MB/s]"
          }
        },
        "e38870016b31412abbec81556c37ceae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90af86e4a85542178997881c90e37ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "461fb5bd1dbb40929cf4fc0980bdfc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b90e14f65fb4e5fa8c5710c2239a6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3b0845cf9f4530a9caf88f938bd700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "413612c126884fe791085594e59f3190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a81b19b6eb4adebee8cbcd9788639a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b6d0c673f04f8ba63d68472c414dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6265ffeb3b174ec49be1520b5dce7996",
              "IPY_MODEL_995f4c0551e94e2dbc266a6ac4644abd",
              "IPY_MODEL_e13a767a5e72467491fdde294f169c0d"
            ],
            "layout": "IPY_MODEL_7d357267cf2249fc9099d013df871426"
          }
        },
        "6265ffeb3b174ec49be1520b5dce7996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08a0fabba50e442091f018a6b42288a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_90a71b694ed94ccd9f5a3f86036b61e0",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "995f4c0551e94e2dbc266a6ac4644abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72bd490b40ff438986650ff4b1b98b8a",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7399c7a70c5149c0b9606f3c5bcafcf8",
            "value": 414
          }
        },
        "e13a767a5e72467491fdde294f169c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a2c6500b16541c985388364d0bc8bb9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1e913351b1f44724a226cdd6391e04bf",
            "value": "â€‡414/414â€‡[00:00&lt;00:00,â€‡13.2kB/s]"
          }
        },
        "7d357267cf2249fc9099d013df871426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a0fabba50e442091f018a6b42288a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a71b694ed94ccd9f5a3f86036b61e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72bd490b40ff438986650ff4b1b98b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7399c7a70c5149c0b9606f3c5bcafcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a2c6500b16541c985388364d0bc8bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e913351b1f44724a226cdd6391e04bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec47ae0ce8bd428b89f5a04f7b12fba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ebf801d6d9b459ab5cc3a7de24f7366",
              "IPY_MODEL_67c6d4cde3394a09ae30f81ff8b7daae",
              "IPY_MODEL_0437bdcb8a584d8b9ce7389b5422ea3e"
            ],
            "layout": "IPY_MODEL_be8ad2f57897450882c71bf4f23fb1c1"
          }
        },
        "6ebf801d6d9b459ab5cc3a7de24f7366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba14ddffb8240008f199be1cf2fb8f3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3c3498238a52443bbdbf25564931a027",
            "value": "config.json:â€‡100%"
          }
        },
        "67c6d4cde3394a09ae30f81ff8b7daae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4973e1e4d6804a289fa7cd824f869cb2",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f32d786068944d38cc4f61763086836",
            "value": 614
          }
        },
        "0437bdcb8a584d8b9ce7389b5422ea3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390afcab394b40e7a359a2a77abe9ce1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ba6f280cfb3548b890478ed71f067a75",
            "value": "â€‡614/614â€‡[00:00&lt;00:00,â€‡18.2kB/s]"
          }
        },
        "be8ad2f57897450882c71bf4f23fb1c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba14ddffb8240008f199be1cf2fb8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3498238a52443bbdbf25564931a027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4973e1e4d6804a289fa7cd824f869cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f32d786068944d38cc4f61763086836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "390afcab394b40e7a359a2a77abe9ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6f280cfb3548b890478ed71f067a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9a168e3461b4a7cb282a0be53986e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2823eb24cc2b47a29961b9daef98d76d",
              "IPY_MODEL_5b57a31d37724b8ea6824068703e7ab5",
              "IPY_MODEL_6fd043cb03294eca8b7e76616839ce65"
            ],
            "layout": "IPY_MODEL_079bbff5c34a4519a726d37b0f370d26"
          }
        },
        "2823eb24cc2b47a29961b9daef98d76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e609d4b3b3142a6b89119c7d80e4754",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3aa333e040ce4a65a210e8ad2103b9b1",
            "value": "model.safetensors.index.json:â€‡100%"
          }
        },
        "5b57a31d37724b8ea6824068703e7ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68fcd9d825294a77ad947fc24162b9fb",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ede14ffce4a44406ae4f15cc5cb5af83",
            "value": 26788
          }
        },
        "6fd043cb03294eca8b7e76616839ce65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cdc677c8aca4bcc941739be2cfabe51",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_874c1ed24b07415680cae84eea8b2a86",
            "value": "â€‡26.8k/26.8kâ€‡[00:00&lt;00:00,â€‡791kB/s]"
          }
        },
        "079bbff5c34a4519a726d37b0f370d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e609d4b3b3142a6b89119c7d80e4754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa333e040ce4a65a210e8ad2103b9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68fcd9d825294a77ad947fc24162b9fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede14ffce4a44406ae4f15cc5cb5af83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cdc677c8aca4bcc941739be2cfabe51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874c1ed24b07415680cae84eea8b2a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb1ace01a3bc41d8ba55f6ced4466023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9144af862af40c698b75865f12900e5",
              "IPY_MODEL_68753538c1474a27a0a81102370b64d9",
              "IPY_MODEL_759b898968a642df944e1363923a3078"
            ],
            "layout": "IPY_MODEL_7748ad1a74324bfd94e6ec3132e18bfb"
          }
        },
        "b9144af862af40c698b75865f12900e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce0e11c371a3410789fa31a4e4f1e00d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6aaee92760704311a4cfe9ba116a4783",
            "value": "Fetchingâ€‡2â€‡files:â€‡100%"
          }
        },
        "68753538c1474a27a0a81102370b64d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8033b50e2eec40c79c7f8a57b5ac4a97",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_512cc7113b5b4173bdd7c1724ec25be2",
            "value": 2
          }
        },
        "759b898968a642df944e1363923a3078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e64812ec9cd04ed793b90e7fef189b80",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0650154b070b4201b203672f6b50e848",
            "value": "â€‡2/2â€‡[02:48&lt;00:00,â€‡168.78s/it]"
          }
        },
        "7748ad1a74324bfd94e6ec3132e18bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0e11c371a3410789fa31a4e4f1e00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aaee92760704311a4cfe9ba116a4783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8033b50e2eec40c79c7f8a57b5ac4a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "512cc7113b5b4173bdd7c1724ec25be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e64812ec9cd04ed793b90e7fef189b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0650154b070b4201b203672f6b50e848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "821342a171094ee28dfce5b0c49cee07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_483c680a8a824ca8b08b27a7e21c1a24",
              "IPY_MODEL_7c93e22926164067ac0975abca6117f1",
              "IPY_MODEL_0934f14ec1ae4f59a91768c43c8997bb"
            ],
            "layout": "IPY_MODEL_cd85514446a94d039c2697344609905b"
          }
        },
        "483c680a8a824ca8b08b27a7e21c1a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6662dd5eab29415f8ec867c79eaa8583",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c27e15e91f904ddba7c869064ade47c5",
            "value": "model-00002-of-00002.safetensors:â€‡100%"
          }
        },
        "7c93e22926164067ac0975abca6117f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b41b2a7cc589408cbc805bb100b51eba",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bed208e1ca894551b5dc74feeee2c714",
            "value": 3500296424
          }
        },
        "0934f14ec1ae4f59a91768c43c8997bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82ba2f21b9154d809e2f5b815927f468",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_377ea8a1c41c4ad3a825113a7bbabac7",
            "value": "â€‡3.50G/3.50Gâ€‡[02:05&lt;00:00,â€‡20.5MB/s]"
          }
        },
        "cd85514446a94d039c2697344609905b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6662dd5eab29415f8ec867c79eaa8583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27e15e91f904ddba7c869064ade47c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b41b2a7cc589408cbc805bb100b51eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed208e1ca894551b5dc74feeee2c714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82ba2f21b9154d809e2f5b815927f468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377ea8a1c41c4ad3a825113a7bbabac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1e9f098551d40fd961de9aef1e49fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1f15846823d49b3a2cc19a131981644",
              "IPY_MODEL_c9202d8efd304b818c7df746ad57121f",
              "IPY_MODEL_91d6d152b9234be88720b932e1c68706"
            ],
            "layout": "IPY_MODEL_5e52a68e9c594e809942c86a2de1363d"
          }
        },
        "a1f15846823d49b3a2cc19a131981644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91986301efef4a13934d039b54d76097",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee76d4371b1243aaa3ee35e743220d7e",
            "value": "model-00001-of-00002.safetensors:â€‡100%"
          }
        },
        "c9202d8efd304b818c7df746ad57121f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ed52d282c6489fa380fea729813165",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f31740d77de4b20b6629269d3b32249",
            "value": 9976576152
          }
        },
        "91d6d152b9234be88720b932e1c68706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c12fa47e3a4e7d9082f50e6c043a3f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1419ec50bd4e4f2dae5c7c583458e50f",
            "value": "â€‡9.98G/9.98Gâ€‡[02:48&lt;00:00,â€‡246MB/s]"
          }
        },
        "5e52a68e9c594e809942c86a2de1363d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91986301efef4a13934d039b54d76097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee76d4371b1243aaa3ee35e743220d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7ed52d282c6489fa380fea729813165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f31740d77de4b20b6629269d3b32249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35c12fa47e3a4e7d9082f50e6c043a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1419ec50bd4e4f2dae5c7c583458e50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1f4a454bfb04045b3a4b6c4ae5ab9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af37fe3cb69b47149ac971271ca1c380",
              "IPY_MODEL_4e82051d61884fcf8dff70c82a5a9a22",
              "IPY_MODEL_5b639067deae4ee4b6ffd4454ad10959"
            ],
            "layout": "IPY_MODEL_8bfe53aa8a834855a19cb1f068f004d2"
          }
        },
        "af37fe3cb69b47149ac971271ca1c380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25addb2b237476e9f9c389df57dc36b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9a9b172246ed401789454a97a2de9832",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "4e82051d61884fcf8dff70c82a5a9a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25567dd827a142728ec2f10e67e440bd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d2062de0e184a3bbb53c55162484c64",
            "value": 2
          }
        },
        "5b639067deae4ee4b6ffd4454ad10959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1381642db5df453e8afc11a45ec53fd5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d5abd9b3b33a4f7e85145689d77f061e",
            "value": "â€‡2/2â€‡[00:54&lt;00:00,â€‡24.96s/it]"
          }
        },
        "8bfe53aa8a834855a19cb1f068f004d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f25addb2b237476e9f9c389df57dc36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9b172246ed401789454a97a2de9832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25567dd827a142728ec2f10e67e440bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d2062de0e184a3bbb53c55162484c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1381642db5df453e8afc11a45ec53fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5abd9b3b33a4f7e85145689d77f061e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee1706b143064101bc04541528e683f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ee7b5447d1b422bbb9984571e2f7c66",
              "IPY_MODEL_3a8a6c503f5947bca5d8f4e8a9a4c550",
              "IPY_MODEL_bdfad133c7bb4a768332c23f6d1d5829"
            ],
            "layout": "IPY_MODEL_6519f4b20f364be58c9b2832c3131432"
          }
        },
        "5ee7b5447d1b422bbb9984571e2f7c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a51e67d367af47b99935f57f5e810be8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ce88677e09d548719cbfb1741945f566",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "3a8a6c503f5947bca5d8f4e8a9a4c550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce3152da95540be99636090201f40a2",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fceb82c2c40b40658226368ee5ee7822",
            "value": 188
          }
        },
        "bdfad133c7bb4a768332c23f6d1d5829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f92749144b5c4de4ae631ca9ea57fa6d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c8e70430574f4b38a012d2cc371a4a4f",
            "value": "â€‡188/188â€‡[00:00&lt;00:00,â€‡19.2kB/s]"
          }
        },
        "6519f4b20f364be58c9b2832c3131432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51e67d367af47b99935f57f5e810be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce88677e09d548719cbfb1741945f566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce3152da95540be99636090201f40a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fceb82c2c40b40658226368ee5ee7822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f92749144b5c4de4ae631ca9ea57fa6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e70430574f4b38a012d2cc371a4a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}